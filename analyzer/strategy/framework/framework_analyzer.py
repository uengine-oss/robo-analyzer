"""Framework ì½”ë“œ ë¶„ì„ ì „ëµ - Java, Kotlin ë“±

AST ê¸°ë°˜ Java ì½”ë“œ ë¶„ì„ â†’ Neo4j í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨ ê·¸ë˜í”„ ìƒì„±.

ë¶„ì„ íë¦„ (2ë‹¨ê³„ + ì´ì¤‘ ë³‘ë ¬):
1. [Phase 1] ëª¨ë“  íŒŒì¼ AST ê·¸ë˜í”„ ìƒì„± (ë³‘ë ¬)
   - ì •ì  ë…¸ë“œ ìƒì„±: CLASS, INTERFACE, METHOD, FIELD
   - ì •ì  ê´€ê³„ ìƒì„±: HAS_METHOD, HAS_FIELD, CONTAINS
   
2. [Phase 2] ëª¨ë“  íŒŒì¼ LLM ë¶„ì„ (íŒŒì¼ ë³‘ë ¬ + ì²­í¬ ë³‘ë ¬)
   - ì½”ë“œ ìš”ì•½ ë° ë¶„ì„
   - CALLS ê´€ê³„ ìƒì„± (MATCHë¡œ ê¸°ì¡´ ë…¸ë“œ ì¡°íšŒ)
   - DEPENDENCY ê´€ê³„ ìƒì„±
   
3. [Phase 3] User Story ë¬¸ì„œ ìƒì„± (BaseStreamingAnalyzer ê³µí†µ)

íŒŒì¼ ìƒíƒœ ê´€ë¦¬:
- Phase1 ì‹¤íŒ¨ íŒŒì¼ì€ Phase2 ìŠ¤í‚µ (í† í° ì ˆê°)
- íŒŒì¼ë³„ SUCCESS/FAILED/SKIPPED ìƒíƒœ ì¶”ì 
"""

import asyncio
import json
import logging
import os
from typing import Any, AsyncGenerator, Optional, List

import aiofiles

from analyzer.neo4j_client import Neo4jClient
from analyzer.strategy.base_analyzer import BaseStreamingAnalyzer, AnalysisStats
from analyzer.strategy.base.file_context import FileStatus, FileAnalysisContext
from analyzer.strategy.framework.ast_processor import FrameworkAstProcessor
from config.settings import settings
from util.exception import AnalysisError
from util.stream_utils import (
    emit_data,
    emit_message,
    format_graph_result,
)
from util.utility_tool import (
    escape_for_cypher,
    generate_user_story_document,
    log_process,
)


class FrameworkAnalyzer(BaseStreamingAnalyzer):
    """Java/Framework ì½”ë“œ ë¶„ì„ ì „ëµ
    
    2ë‹¨ê³„ ë¶„ì„ + ì´ì¤‘ ë³‘ë ¬ ì²˜ë¦¬:
    - Phase 1: ëª¨ë“  íŒŒì¼ AST ê·¸ë˜í”„ ìƒì„± (ë³‘ë ¬)
    - Phase 2: ëª¨ë“  íŒŒì¼ LLM ë¶„ì„ (ë³‘ë ¬) - Phase1 ì‹¤íŒ¨ íŒŒì¼ ì œì™¸
    - Phase 3: User Story ë¬¸ì„œ ìƒì„± (ë¶€ëª¨ í´ë˜ìŠ¤ ê³µí†µ)
    
    íŒŒì´í”„ë¼ì¸ íŠ¹ì„±:
    - ë³‘ë ¬ ì²˜ë¦¬: íŒŒì¼ ë‹¨ìœ„ë¡œ ë™ì‹œ ë¶„ì„
    - ë™ì‹œì„± ë³´í˜¸: Cypher ì¿¼ë¦¬ ë½ ì‚¬ìš©
    - í”„ë¡œì„¸ì„œ ì¬ì‚¬ìš©: Phase 1ì—ì„œ ìƒì„±í•œ í”„ë¡œì„¸ì„œë¥¼ Phase 2ì—ì„œ ì¬ì‚¬ìš©
    - í† í° ì ˆê°: Phase1 ì‹¤íŒ¨ íŒŒì¼ì€ Phase2 ìŠ¤í‚µ
    """

    # =========================================================================
    # ì „ëµ ë©”íƒ€ë°ì´í„° (BaseStreamingAnalyzer êµ¬í˜„)
    # =========================================================================
    
    @property
    def strategy_name(self) -> str:
        return "í”„ë ˆì„ì›Œí¬"
    
    @property
    def strategy_emoji(self) -> str:
        return "ğŸš€"
    
    @property
    def file_type_description(self) -> str:
        return "Java/Kotlin íŒŒì¼"

    def __init__(self):
        self._cypher_lock = asyncio.Lock()  # Cypher ì¿¼ë¦¬ ë™ì‹œì„± ë³´í˜¸
        self._file_semaphore: Optional[asyncio.Semaphore] = None

    # =========================================================================
    # ë©”ì¸ íŒŒì´í”„ë¼ì¸ (BaseStreamingAnalyzer êµ¬í˜„)
    # =========================================================================

    async def run_pipeline(
        self,
        file_names: list[tuple[str, str]],
        client: Neo4jClient,
        orchestrator: Any,
        stats: AnalysisStats,
    ) -> AsyncGenerator[bytes, None]:
        """Framework ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        íë¦„:
        1. íŒŒì¼ ë¡œë“œ (ë³‘ë ¬)
        2. Phase 1: AST ê·¸ë˜í”„ ìƒì„± (ë³‘ë ¬)
        3. Phase 2: LLM ë¶„ì„ (ë³‘ë ¬) - Phase1 ì‹¤íŒ¨ íŒŒì¼ ì œì™¸ (í† í° ì ˆê°)
        
        Note: User Story PhaseëŠ” ë¶€ëª¨ í´ë˜ìŠ¤ì—ì„œ ì²˜ë¦¬
        """
        total_files = len(file_names)
        self._file_semaphore = asyncio.Semaphore(settings.concurrency.file_concurrency)

        yield emit_message(f"âš¡ ë³‘ë ¬ ì²˜ë¦¬: íŒŒì¼ {settings.concurrency.file_concurrency}ê°œ ë™ì‹œ")

        # ========== íŒŒì¼ ë¡œë“œ ==========
        yield emit_message("")
        yield self.emit_separator()
        yield self.emit_phase_header(1, "ğŸ—ï¸ AST êµ¬ì¡° ê·¸ë˜í”„ ìƒì„±", f"{total_files}ê°œ íŒŒì¼ ë³‘ë ¬")
        yield self.emit_separator()

        contexts = await self._load_all_files(file_names, orchestrator)
        yield emit_message(f"   âœ“ {len(contexts)}ê°œ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")

        # ========== Phase 1: AST ê·¸ë˜í”„ ìƒì„± (ë³‘ë ¬) ==========
        async for chunk in self._run_phase1(contexts, client, orchestrator, stats):
            yield chunk

        # Phase 1 ê²°ê³¼ ìš”ì•½
        ph1_ok_count = sum(1 for c in contexts if c.status == FileStatus.PH1_OK)
        ph1_fail_count = sum(1 for c in contexts if c.status == FileStatus.PH1_FAIL)
        
        yield emit_message("")
        yield self.emit_phase_complete(1, f"{stats.static_nodes_created}ê°œ ë…¸ë“œ ìƒì„±")
        if ph1_fail_count > 0:
            yield self.emit_warning(f"Phase 1 ì‹¤íŒ¨: {ph1_fail_count}ê°œ íŒŒì¼ â†’ Phase 2 ìŠ¤í‚µ (í† í° ì ˆê°)")

        # ========== Phase 2: LLM ë¶„ì„ (ë³‘ë ¬) - Phase1 ì„±ê³µ íŒŒì¼ë§Œ ==========
        ph2_targets = [c for c in contexts if c.status == FileStatus.PH1_OK]
        
        yield emit_message("")
        yield self.emit_separator()
        yield self.emit_phase_header(2, "ğŸ¤– AI ë¶„ì„", f"{len(ph2_targets)}ê°œ íŒŒì¼ ë³‘ë ¬")
        yield self.emit_separator()
        
        if ph1_fail_count > 0:
            yield emit_message(f"   â„¹ï¸ {ph1_fail_count}ê°œ íŒŒì¼ì€ Phase 1 ì‹¤íŒ¨ë¡œ ìŠ¤í‚µë¨ (í† í° ì ˆê°)")

        async for chunk in self._run_phase2(ph2_targets, client, orchestrator, stats):
            yield chunk

        yield emit_message("")
        yield self.emit_phase_complete(2, f"{stats.llm_batches_executed}ê°œ ë¶„ì„ ì™„ë£Œ")

    # =========================================================================
    # User Story ë¬¸ì„œ ìƒì„± (BaseStreamingAnalyzer êµ¬í˜„)
    # =========================================================================

    async def build_user_story_doc(
        self,
        client: Neo4jClient,
        orchestrator: Any,
    ) -> Optional[str]:
        """ë¶„ì„ëœ í´ë˜ìŠ¤ì—ì„œ User Story ë¬¸ì„œ ìƒì„±"""
        query = f"""
            MATCH (n)
            WHERE (n:CLASS OR n:INTERFACE)
              AND n.user_id = '{escape_for_cypher(orchestrator.user_id)}'
              AND n.project_name = '{escape_for_cypher(orchestrator.project_name)}'
              AND n.summary IS NOT NULL
            OPTIONAL MATCH (n)-[:HAS_USER_STORY]->(us:UserStory)
            OPTIONAL MATCH (us)-[:HAS_AC]->(ac:AcceptanceCriteria)
            WITH n, us, collect(DISTINCT {{
                id: ac.id,
                title: ac.title,
                given: ac.given,
                when: ac.when,
                then: ac.then
            }}) AS acceptance_criteria
            WITH n, collect(DISTINCT {{
                id: us.id,
                role: us.role,
                goal: us.goal,
                benefit: us.benefit,
                acceptance_criteria: acceptance_criteria
            }}) AS user_stories
            RETURN n.class_name AS name, 
                   n.summary AS summary,
                   user_stories AS user_stories, 
                   labels(n)[0] AS type
            ORDER BY n.file_name, n.startLine
        """
        
        async with self._cypher_lock:
            results = await client.execute_queries([query])
        
        if not results or not results[0]:
            log_process(
                "ANALYZE", "USER_STORY",
                "User Story ìƒì„± ìŠ¤í‚µ: ë¶„ì„ëœ í´ë˜ìŠ¤/ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤",
                logging.INFO
            )
            return None
        
        filtered = [
            r for r in results[0]
            if r.get("summary") or (r.get("user_stories") and len(r["user_stories"]) > 0)
        ]
        
        if not filtered:
            return None
        
        log_process("ANALYZE", "USER_STORY", f"User Story ìƒì„± | ëŒ€ìƒ={len(filtered)}ê°œ í´ë˜ìŠ¤")
        return generate_user_story_document(
            results=filtered,
            source_name=orchestrator.project_name,
            source_type="Java í´ë˜ìŠ¤/ì¸í„°í˜ì´ìŠ¤",
        )

    # =========================================================================
    # íŒŒì¼ ë¡œë“œ
    # =========================================================================

    async def _load_all_files(
        self,
        file_names: list[tuple[str, str]],
        orchestrator: Any,
    ) -> List[FileAnalysisContext]:
        """ëª¨ë“  íŒŒì¼ì˜ ASTì™€ ì†ŒìŠ¤ì½”ë“œë¥¼ ë³‘ë ¬ë¡œ ë¡œë“œí•©ë‹ˆë‹¤."""
        
        async def load_single(directory: str, file_name: str) -> FileAnalysisContext:
            src_path = os.path.join(orchestrator.dirs["src"], directory, file_name)
            base_name = os.path.splitext(file_name)[0]
            ast_path = os.path.join(orchestrator.dirs["analysis"], directory, f"{base_name}.json")

            async with aiofiles.open(ast_path, "r", encoding="utf-8") as ast_file, \
                       aiofiles.open(src_path, "r", encoding="utf-8") as src_file:
                ast_content, source_lines = await asyncio.gather(
                    ast_file.read(),
                    src_file.readlines(),
                )
                return FileAnalysisContext(
                    directory=directory,
                    file_name=file_name,
                    ast_data=json.loads(ast_content),
                    source_lines=source_lines,
                )

        tasks = [load_single(d, f) for d, f in file_names]
        return await asyncio.gather(*tasks)

    # =========================================================================
    # Phase 1: AST ê·¸ë˜í”„ ìƒì„±
    # =========================================================================

    async def _run_phase1(
        self,
        contexts: List[FileAnalysisContext],
        client: Neo4jClient,
        orchestrator: Any,
        stats: AnalysisStats,
    ) -> AsyncGenerator[bytes, None]:
        """Phase 1: ëª¨ë“  íŒŒì¼ì˜ AST ê·¸ë˜í”„ë¥¼ ë³‘ë ¬ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        íŒŒì¼ë³„ ìƒíƒœ ê¸°ë¡:
        - ì„±ê³µ: PH1_OK â†’ Phase 2 ì§„í–‰
        - ì‹¤íŒ¨: PH1_FAIL â†’ Phase 2 ìŠ¤í‚µ (í† í° ì ˆê°)
        """
        
        completed = 0
        total = len(contexts)
        results_queue: asyncio.Queue = asyncio.Queue()

        async def process_file(ctx: FileAnalysisContext):
            async with self._file_semaphore:
                try:
                    processor = FrameworkAstProcessor(
                        antlr_data=ctx.ast_data,
                        file_content="".join(ctx.source_lines),
                        directory=ctx.directory,
                        file_name=ctx.file_name,
                        user_id=orchestrator.user_id,
                        api_key=orchestrator.api_key,
                        locale=orchestrator.locale,
                        project_name=orchestrator.project_name,
                        last_line=len(ctx.source_lines),
                    )
                    ctx.processor = processor
                    
                    # ì •ì  ê·¸ë˜í”„ ìƒì„±
                    queries = processor.build_static_graph_queries()
                    
                    if queries:
                        # Cypher ì¿¼ë¦¬ ì‹¤í–‰ (ë½ ì‚¬ìš©)
                        async with self._cypher_lock:
                            graph = await client.run_graph_query(queries)
                        
                        node_count = len(graph.get("Nodes", []))
                        rel_count = len(graph.get("Relationships", []))
                        
                        ctx.status = FileStatus.PH1_OK
                        await results_queue.put({
                            "type": "success",
                            "file": ctx.file_name,
                            "graph": graph,
                            "node_count": node_count,
                            "rel_count": rel_count,
                        })
                    else:
                        ctx.status = FileStatus.PH1_OK
                        await results_queue.put({
                            "type": "success",
                            "file": ctx.file_name,
                            "graph": {"Nodes": [], "Relationships": []},
                            "node_count": 0,
                            "rel_count": 0,
                        })
                        
                except Exception as e:
                    log_process("ANALYZE", "ERROR", f"Phase 1 ì˜¤ë¥˜ ({ctx.file_name}): {e}", logging.ERROR, e)
                    ctx.status = FileStatus.PH1_FAIL
                    ctx.error_message = str(e)[:100]
                    await results_queue.put({
                        "type": "error",
                        "file": ctx.file_name,
                        "message": str(e),
                    })
                    raise  # ì¦‰ì‹œ ì¤‘ë‹¨ - ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš© ì•ˆí•¨

        # ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘
        tasks = [asyncio.create_task(process_file(ctx)) for ctx in contexts]

        # ê²°ê³¼ ìˆ˜ì‹  ë° ìŠ¤íŠ¸ë¦¬ë°
        while completed < total:
            result = await asyncio.wait_for(results_queue.get(), timeout=300.0)
            completed += 1
            stats.files_completed = completed
            
            if result["type"] == "error":
                yield emit_message(f"   âŒ [{completed}/{total}] {result['file']}: {result['message'][:50]}")
                stats.mark_file_failed(result['file'], "Phase1 ì‹¤íŒ¨")
            else:
                stats.add_graph_result(result["graph"], is_static=True)
                
                graph = result["graph"]
                graph_msg = format_graph_result(graph)
                
                yield emit_message(f"   âœ“ [{completed}/{total}] {result['file']}")
                if graph_msg:
                    for line in graph_msg.split("\n")[:3]:  # ìµœëŒ€ 3ì¤„
                        yield emit_message(f"      {line}")
                
                yield emit_data(
                    graph=graph,
                    line_number=0,
                    analysis_progress=int(completed / total * 50),
                    current_file=result["file"],
                )

        # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        await asyncio.gather(*tasks, return_exceptions=True)

    # =========================================================================
    # Phase 2: LLM ë¶„ì„
    # =========================================================================

    async def _run_phase2(
        self,
        contexts: List[FileAnalysisContext],
        client: Neo4jClient,
        orchestrator: Any,
        stats: AnalysisStats,
    ) -> AsyncGenerator[bytes, None]:
        """Phase 2: Phase1 ì„±ê³µ íŒŒì¼ì˜ LLM ë¶„ì„ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Phase1 ì‹¤íŒ¨ íŒŒì¼ì€ ì´ë¯¸ í•„í„°ë§ë˜ì–´ ì „ë‹¬ë˜ì§€ ì•ŠìŒ (í† í° ì ˆê°).
        """
        
        if not contexts:
            yield emit_message("   â„¹ï¸ ë¶„ì„ ëŒ€ìƒ íŒŒì¼ ì—†ìŒ")
            return
        
        completed = 0
        total = len(contexts)
        results_queue: asyncio.Queue = asyncio.Queue()

        async def analyze_file(ctx: FileAnalysisContext):
            async with self._file_semaphore:
                try:
                    if not ctx.processor:
                        raise AnalysisError(f"Phase 1ì—ì„œ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨: {ctx.file_name}")
                    
                    # LLM ë¶„ì„ ì‹¤í–‰ (íŠœí”Œ ë°˜í™˜: queries, failed_batch_count, failed_details)
                    analysis_queries, failed_batch_count, failed_details = await ctx.processor.run_llm_analysis()
                    
                    if analysis_queries:
                        # Cypher ì¿¼ë¦¬ ì‹¤í–‰ (ë½ ì‚¬ìš©)
                        async with self._cypher_lock:
                            graph = await client.run_graph_query(analysis_queries)
                        
                        ctx.status = FileStatus.PH2_OK
                        await results_queue.put({
                            "type": "success",
                            "file": ctx.file_name,
                            "graph": graph,
                            "query_count": len(analysis_queries),
                            "failed_batches": failed_batch_count,
                            "failed_details": failed_details,  # ìƒì„¸ ì •ë³´ ì¶”ê°€
                        })
                    else:
                        ctx.status = FileStatus.PH2_OK
                        await results_queue.put({
                            "type": "success",
                            "file": ctx.file_name,
                            "graph": {"Nodes": [], "Relationships": []},
                            "query_count": 0,
                            "failed_batches": failed_batch_count,
                        })
                    
                    # ë°°ì¹˜ ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ì¤‘ë‹¨ - ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš© ì•ˆí•¨
                    if failed_batch_count > 0:
                        raise AnalysisError(f"{ctx.file_name}: {failed_batch_count}ê°œ ë°°ì¹˜ ì‹¤íŒ¨")
                        
                except Exception as e:
                    log_process("ANALYZE", "ERROR", f"Phase 2 ì˜¤ë¥˜ ({ctx.file_name}): {e}", logging.ERROR, e)
                    ctx.status = FileStatus.PH2_FAIL
                    ctx.error_message = str(e)[:100]
                    await results_queue.put({
                        "type": "error",
                        "file": ctx.file_name,
                        "message": str(e),
                    })
                    raise  # ì¦‰ì‹œ ì¤‘ë‹¨ - ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš© ì•ˆí•¨

        # ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘
        tasks = [asyncio.create_task(analyze_file(ctx)) for ctx in contexts]

        # ê²°ê³¼ ìˆ˜ì‹  ë° ìŠ¤íŠ¸ë¦¬ë°
        while completed < total:
            result = await asyncio.wait_for(results_queue.get(), timeout=600.0)
            result_type = result.get("type", "")
            
            # warningì€ ì¹´ìš´íŠ¸í•˜ì§€ ì•ŠìŒ (ì¶”ê°€ ì •ë³´ì¼ ë¿)
            if result_type == "warning":
                yield emit_message(f"   âš ï¸ {result['file']}: {result['message']}")
                continue
            
            completed += 1
            
            if result_type == "error":
                yield emit_message(f"   âŒ [{completed}/{total}] {result['file']}: {result['message'][:50]}")
                stats.mark_file_failed(result['file'], "Phase2 ì‹¤íŒ¨")
            else:
                stats.llm_batches_executed += 1
                graph = result["graph"]
                stats.add_graph_result(graph, is_static=False)
                
                # ë°°ì¹˜ ì‹¤íŒ¨ ì •ë³´ í‘œì‹œ
                failed_batches = result.get("failed_batches", 0)
                failed_details = result.get("failed_details", [])
                fail_info = f" (ë°°ì¹˜ {failed_batches}ê°œ ì‹¤íŒ¨)" if failed_batches > 0 else ""
                
                graph_msg = format_graph_result(graph)
                yield emit_message(f"   âœ“ [{completed}/{total}] {result['file']} (ì¿¼ë¦¬ {result['query_count']}ê°œ){fail_info}")
                if graph_msg:
                    for line in graph_msg.split("\n")[:3]:
                        yield emit_message(f"      {line}")
                
                # ì‹¤íŒ¨ ìƒì„¸ ì •ë³´ ì¶œë ¥ (ìµœëŒ€ 3ê°œ)
                if failed_details:
                    stats.llm_batches_failed += len(failed_details)
                    for detail in failed_details[:3]:
                        yield emit_message(f"      âš ï¸ ë°°ì¹˜ #{detail['batch_id']} ({detail['node_ranges']}): {detail['error'][:50]}")
                
                yield emit_data(
                    graph=graph,
                    line_number=0,
                    analysis_progress=50 + int(completed / total * 50),
                    current_file=result["file"],
                )

        # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        await asyncio.gather(*tasks, return_exceptions=True)

