"""ë²¡í„°ë¼ì´ì§• Phase (Phase 4) - DBMS

dbms_analyzer.pyì—ì„œ ë¶„ë¦¬ëœ Phase 4 ë¡œì§ì…ë‹ˆë‹¤.
ëª¨ë“  ë¡œì§ì€ 100% ë³´ì¡´ë˜ë©°, ìœ„ì¹˜ë§Œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

import asyncio
import logging
import time
from typing import Any, AsyncGenerator

from analyzer.neo4j_client import Neo4jClient
from analyzer.strategy.base_analyzer import AnalysisStats
from client.embedding_client import EmbeddingClient
from config.settings import settings
from util.stream_event import (
    emit_message,
    emit_phase_event,
)
from util.text_utils import log_process


async def run_vectorize_phase(
    analyzer: Any,
    client: Neo4jClient,
    orchestrator: Any,
    stats: AnalysisStats,
) -> AsyncGenerator[bytes, None]:
    """Phase 4: í…Œì´ë¸”/ì»¬ëŸ¼ ë²¡í„°ë¼ì´ì§• (ë°°ì¹˜ ìµœì í™”)
    
    Neo4jì— ì €ì¥ëœ í…Œì´ë¸”/ì»¬ëŸ¼ì˜ descriptionì„ ê¸°ë°˜ìœ¼ë¡œ ì„ë² ë”© ìƒì„±
    ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
    
    Args:
        analyzer: DbmsAnalyzer ì¸ìŠ¤í„´ìŠ¤ (ê³µìœ  ìƒíƒœ ì ‘ê·¼ìš©)
        client: Neo4j í´ë¼ì´ì–¸íŠ¸
        orchestrator: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
        stats: ë¶„ì„ í†µê³„
    """
    from openai import AsyncOpenAI
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    api_key = orchestrator.api_key or settings.openai_api_key
    if not api_key:
        yield emit_message("   âš ï¸ OpenAI API í‚¤ê°€ ì—†ì–´ ë²¡í„°ë¼ì´ì§•ì„ ê±´ë„ˆëœë‹ˆë‹¤")
        return
    
    openai_client = AsyncOpenAI(api_key=api_key)
    embedding_client = EmbeddingClient(openai_client)
    
    # ===========================================
    # í…Œì´ë¸” ë²¡í„°ë¼ì´ì§• (ë°°ì¹˜ ì²˜ë¦¬)
    # ===========================================
    yield emit_message("   ğŸ“Š [Phase 4-1] í…Œì´ë¸” ë²¡í„°ë¼ì´ì§• ì‹œì‘...")
    yield emit_phase_event(
        phase_num=4,
        phase_name="ë²¡í„°ë¼ì´ì§•",
        status="in_progress",
        progress=0,
        details={"step": "table_vectorizing"}
    )
    
    # descriptionê³¼ analyzed_descriptionì„ í•©ì³ì„œ ì„ë² ë”© ìƒì„± (ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ)
    table_query = """
    MATCH (__cy_t__:Table)
    WHERE (__cy_t__.vector IS NULL OR size(__cy_t__.vector) = 0)
      AND (__cy_t__.description IS NOT NULL OR __cy_t__.analyzed_description IS NOT NULL)
    RETURN elementId(__cy_t__) AS tid, 
           __cy_t__.name AS name,
           __cy_t__.schema AS schema,
           trim(
             coalesce(__cy_t__.description, '') + 
             CASE WHEN __cy_t__.analyzed_description IS NOT NULL AND __cy_t__.analyzed_description <> '' 
                  THEN ' | AI ë¶„ì„: ' + __cy_t__.analyzed_description 
                  ELSE '' 
             END
           ) AS description
    ORDER BY __cy_t__.schema, __cy_t__.name
    """
    
    try:
        async with analyzer._cypher_lock:
            result = await client.execute_queries([table_query])
        
        tables = result[0] if result and result[0] else []
        total_tables = len(tables)
        
        if total_tables == 0:
            yield emit_message("      â„¹ï¸ ë²¡í„°í™”í•  í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            yield emit_message(f"      ğŸ“‹ ë²¡í„°í™” ëŒ€ìƒ: {total_tables}ê°œ í…Œì´ë¸”")
            
            # í…Œì´ë¸”ë„ ë°°ì¹˜ë¡œ ì²˜ë¦¬ (50ê°œì”©)
            batch_size = 50
            for batch_idx in range(0, total_tables, batch_size):
                batch = tables[batch_idx:batch_idx + batch_size]
                batch_num = batch_idx // batch_size + 1
                total_batches = (total_tables + batch_size - 1) // batch_size
                
                # ìœ íš¨í•œ í…Œì´ë¸”ë§Œ í•„í„°ë§
                valid_items = []
                texts = []
                for item in batch:
                    description = item.get("description", "") or ""
                    if not description:
                        continue
                    text = embedding_client.format_table_text(
                        table_name=item.get("name", ""),
                        description=description
                    )
                    texts.append(text)
                    valid_items.append(item)
                
                if not texts:
                    continue
                
                # ë°°ì¹˜ ì§„í–‰ ìƒí™© í‘œì‹œ
                batch_progress = int(batch_idx / total_tables * 25)  # 0-25% ë²”ìœ„
                log_process("VECTORIZE", "TABLE", f"ë°°ì¹˜ #{batch_num}/{total_batches} í…Œì´ë¸” {len(valid_items)}ê°œ ì„ë² ë”© ìƒì„± ì‹œì‘", logging.INFO)
                yield emit_message(f"      ğŸ”„ [{batch_num}/{total_batches}] í…Œì´ë¸” {len(valid_items)}ê°œ ì„ë² ë”© ìƒì„± ì¤‘...")
                yield emit_phase_event(
                    phase_num=4,
                    phase_name="ë²¡í„°ë¼ì´ì§•",
                    status="in_progress",
                    progress=batch_progress,
                    details={"step": "table_embedding", "batch": batch_num, "total_batches": total_batches}
                )
                
                # ë°°ì¹˜ ì„ë² ë”© API í˜¸ì¶œ (ì‹œê°„ ì¸¡ì •)
                embed_start = time.time()
                vectors = await embedding_client.embed_batch(texts)
                embed_time = time.time() - embed_start
                log_process("VECTORIZE", "API", f"ì„ë² ë”© API ì‘ë‹µ: {len(vectors)}ê°œ, {embed_time:.2f}ì´ˆ", logging.INFO)
                
                # UNWIND ë°°ì¹˜ ì €ì¥ìš© ë°ì´í„° ìƒì„±
                vector_updates = []
                for item, vector in zip(valid_items, vectors):
                    if vector:
                        vector_updates.append({
                            "tid": item['tid'],
                            "vector": vector
                        })
                        stats.tables_vectorized += 1
                
                # UNWINDë¡œ í•œë²ˆì— ì €ì¥
                if vector_updates:
                    update_query = """
                    UNWIND $items AS item
                    MATCH (__cy_t__) WHERE elementId(__cy_t__) = item.tid
                    SET __cy_t__.vector = item.vector
                    RETURN __cy_t__
                    """
                    async with analyzer._cypher_lock:
                        await client.execute_with_params(update_query, {"items": vector_updates})
                    
                    yield emit_message(f"      âœ“ [{batch_num}/{total_batches}] {len(vector_updates)}ê°œ í…Œì´ë¸” ë²¡í„° ì €ì¥ ì™„ë£Œ")
            
            yield emit_message(f"   âœ… í…Œì´ë¸” ë²¡í„°ë¼ì´ì§• ì™„ë£Œ: {stats.tables_vectorized}ê°œ í…Œì´ë¸”")
        
    except Exception as e:
        error_msg = f"í…Œì´ë¸” ë²¡í„°ë¼ì´ì§• ì‹¤íŒ¨: {str(e)}"
        yield emit_message(f"   âŒ {error_msg}")
        raise RuntimeError(error_msg) from e
    
    # ===========================================
    # ì»¬ëŸ¼ ë²¡í„°ë¼ì´ì§• (ë°°ì¹˜ ì²˜ë¦¬)
    # ===========================================
    yield emit_message("   ğŸ“Š [Phase 4-2] ì»¬ëŸ¼ ë²¡í„°ë¼ì´ì§• ì‹œì‘...")
    yield emit_phase_event(
        phase_num=4,
        phase_name="ë²¡í„°ë¼ì´ì§•",
        status="in_progress",
        progress=25,
        details={"step": "column_vectorizing"}
    )
    
    # descriptionê³¼ analyzed_descriptionì„ í•©ì³ì„œ ì„ë² ë”© ìƒì„± (ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ)
    column_query = """
    MATCH (__cy_t__:Table)-[:HAS_COLUMN]->(__cy_c__:Column)
    WHERE (__cy_c__.vector IS NULL OR size(__cy_c__.vector) = 0)
      AND (__cy_c__.description IS NOT NULL OR __cy_c__.analyzed_description IS NOT NULL)
    RETURN elementId(__cy_c__) AS cid,
           __cy_c__.name AS column_name,
           __cy_t__.name AS table_name,
           coalesce(__cy_c__.dtype, '') AS dtype,
           trim(
             coalesce(__cy_c__.description, '') + 
             CASE WHEN __cy_c__.analyzed_description IS NOT NULL AND __cy_c__.analyzed_description <> '' 
                  THEN ' | AI ë¶„ì„: ' + __cy_c__.analyzed_description 
                  ELSE '' 
             END
           ) AS description
    ORDER BY __cy_t__.schema, __cy_t__.name, __cy_c__.name
    """
    
    try:
        async with analyzer._cypher_lock:
            result = await client.execute_queries([column_query])
        
        columns = result[0] if result and result[0] else []
        total_columns = len(columns)
        
        if total_columns == 0:
            yield emit_message("      â„¹ï¸ ë²¡í„°í™”í•  ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            yield emit_message(f"      ğŸ“‹ ë²¡í„°í™” ëŒ€ìƒ: {total_columns}ê°œ ì»¬ëŸ¼")
        
            # ë°°ì¹˜ ì²˜ë¦¬ (50ê°œì”©)
            batch_size = 50
            for i in range(0, total_columns, batch_size):
                batch = columns[i:i + batch_size]
                batch_num = i // batch_size + 1
                total_batches = (total_columns + batch_size - 1) // batch_size
                texts = []
                
                for item in batch:
                    text = embedding_client.format_column_text(
                        column_name=item.get("column_name", ""),
                        table_name=item.get("table_name", ""),
                        dtype=item.get("dtype", ""),
                        description=item.get("description", "")
                    )
                    texts.append(text)
                
                # ë°°ì¹˜ ì§„í–‰ ìƒí™© í‘œì‹œ
                batch_progress = 25 + int(i / total_columns * 75)  # 25-100% ë²”ìœ„
                log_process("VECTORIZE", "COLUMN", f"ë°°ì¹˜ #{batch_num}/{total_batches} ì»¬ëŸ¼ {len(texts)}ê°œ ì„ë² ë”© ìƒì„± ì‹œì‘", logging.INFO)
                yield emit_message(f"      ğŸ”„ [{batch_num}/{total_batches}] ì»¬ëŸ¼ {len(texts)}ê°œ ì„ë² ë”© ìƒì„± ì¤‘...")
                yield emit_phase_event(
                    phase_num=4,
                    phase_name="ë²¡í„°ë¼ì´ì§•",
                    status="in_progress",
                    progress=batch_progress,
                    details={"step": "column_embedding", "batch": batch_num, "total_batches": total_batches, "done": i, "total": total_columns}
                )
                
                # ë°°ì¹˜ ì„ë² ë”© API í˜¸ì¶œ (ì‹œê°„ ì¸¡ì •)
                embed_start = time.time()
                vectors = await embedding_client.embed_batch(texts)
                embed_time = time.time() - embed_start
                log_process("VECTORIZE", "API", f"ì„ë² ë”© API ì‘ë‹µ: {len(vectors)}ê°œ, {embed_time:.2f}ì´ˆ", logging.INFO)
                
                # UNWIND ë°°ì¹˜ ì €ì¥ìš© ë°ì´í„° ìƒì„±
                vector_updates = []
                for item, vector in zip(batch, vectors):
                    if vector:
                        vector_updates.append({
                            "cid": item['cid'],
                            "vector": vector
                        })
                        stats.columns_vectorized += 1
                
                # UNWINDë¡œ í•œë²ˆì— ì €ì¥
                if vector_updates:
                    update_query = """
                    UNWIND $items AS item
                    MATCH (__cy_c__) WHERE elementId(__cy_c__) = item.cid
                    SET __cy_c__.vector = item.vector
                    RETURN __cy_c__
                    """
                    async with analyzer._cypher_lock:
                        await client.execute_with_params(update_query, {"items": vector_updates})
                    
                    yield emit_message(f"      âœ“ [{batch_num}/{total_batches}] {len(vector_updates)}ê°œ ì»¬ëŸ¼ ë²¡í„° ì €ì¥ ì™„ë£Œ")
            
            yield emit_message(f"   âœ… ì»¬ëŸ¼ ë²¡í„°ë¼ì´ì§• ì™„ë£Œ: {stats.columns_vectorized}ê°œ ì»¬ëŸ¼")
            yield emit_phase_event(
                phase_num=4,
                phase_name="ë²¡í„°ë¼ì´ì§•",
                status="completed",
                progress=100,
                details={"tables_vectorized": stats.tables_vectorized, "columns_vectorized": stats.columns_vectorized}
            )
        
    except Exception as e:
        error_msg = f"ì»¬ëŸ¼ ë²¡í„°ë¼ì´ì§• ì‹¤íŒ¨: {str(e)}"
        yield emit_message(f"   âŒ {error_msg}")
        raise RuntimeError(error_msg) from e

