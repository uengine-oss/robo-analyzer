"""ë¦¬ë‹ˆì§€ ë¶„ì„ Phase (Phase 5) - DBMS

dbms_analyzer.pyì—ì„œ ë¶„ë¦¬ëœ Phase 5 ë¡œì§ì…ë‹ˆë‹¤.
ëª¨ë“  ë¡œì§ì€ 100% ë³´ì¡´ë˜ë©°, ìœ„ì¹˜ë§Œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

import logging
import os
from typing import Any, AsyncGenerator, List

import aiofiles

from analyzer.neo4j_client import Neo4jClient
from analyzer.strategy.base_analyzer import AnalysisStats
from analyzer.lineage_analyzer import LineageAnalyzer, LineageInfo
from util.stream_event import emit_message, emit_phase_event
from util.text_utils import log_process


async def run_lineage_phase(
    analyzer: Any,
    client: Neo4jClient,
    orchestrator: Any,
    stats: AnalysisStats,
) -> AsyncGenerator[bytes, None]:
    """ETL íŒ¨í„´ ê°ì§€ ë° ë°ì´í„° ë¦¬ë‹ˆì§€ ê´€ê³„ ìƒì„±
    
    Stored Procedureê°€ ETL ì—­í• ì„ í•˜ëŠ”ì§€ ë¶„ì„í•˜ê³ ,
    Source í…Œì´ë¸” â†’ ETL â†’ Target í…Œì´ë¸” ê°„ ë°ì´í„° íë¦„ ê´€ê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        analyzer: DbmsAnalyzer ì¸ìŠ¤í„´ìŠ¤ (ê³µìœ  ìƒíƒœ ì ‘ê·¼ìš©)
        client: Neo4j í´ë¼ì´ì–¸íŠ¸
        orchestrator: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
        stats: ë¶„ì„ í†µê³„
    """
    source_dir = orchestrator.dirs.get("source", "")
    
    if not source_dir or not os.path.exists(source_dir):
        yield emit_message("   â„¹ï¸ SP íŒŒì¼ ì—†ìŒ â†’ ë¦¬ë‹ˆì§€ ë¶„ì„ ê±´ë„ˆëœ€")
        return
    
    # SP íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    sql_files: List[str] = []
    for root, _, files in os.walk(source_dir):
        for f in files:
            if f.endswith(".sql"):
                sql_files.append(os.path.join(root, f))
    
    if not sql_files:
        yield emit_message("   â„¹ï¸ SP íŒŒì¼ ì—†ìŒ â†’ ë¦¬ë‹ˆì§€ ë¶„ì„ ê±´ë„ˆëœ€")
        return
    
    total_files = len(sql_files)
    log_process("LINEAGE", "START", f"ë¦¬ë‹ˆì§€ ë¶„ì„ ì‹œì‘: {total_files}ê°œ SP íŒŒì¼", logging.INFO)
    yield emit_message(f"   ğŸ” [Phase 5] {total_files}ê°œ SP íŒŒì¼ì—ì„œ ETL íŒ¨í„´ ë¶„ì„ ì‹œì‘...")
    yield emit_phase_event(
        phase_num=5,
        phase_name="ë¦¬ë‹ˆì§€ ë¶„ì„",
        status="in_progress",
        progress=0,
        details={"total_files": total_files}
    )
    
    # ë¦¬ë‹ˆì§€ ë¶„ì„ê¸° ìƒì„±
    lineage_analyzer = LineageAnalyzer(dbms="oracle")
    all_lineages: List[LineageInfo] = []
    files_with_etl = 0
    
    # ê° SP íŒŒì¼ ë¶„ì„
    for idx, sql_file in enumerate(sql_files, 1):
        file_name = os.path.basename(sql_file)
        progress = int((idx / total_files) * 80)  # 0-80% ë²”ìœ„ (ì €ì¥ì€ 80-100%)
        
        log_process("LINEAGE", "ANALYZE", f"[{idx}/{total_files}] {file_name} ë¶„ì„ ì¤‘", logging.INFO)
        
        try:
            async with aiofiles.open(sql_file, "r", encoding="utf-8", errors="ignore") as f:
                sql_content = await f.read()
            
            # ë¦¬ë‹ˆì§€ ë¶„ì„
            lineages = lineage_analyzer.analyze_sql_content(sql_content, file_name)
            
            # ETL íŒ¨í„´ì´ ê°ì§€ëœ ê²½ìš°ë§Œ ì €ì¥
            etl_lineages = [l for l in lineages if l.is_etl]
            if etl_lineages:
                files_with_etl += 1
                for l in etl_lineages:
                    l.file_name = file_name
                all_lineages.extend(etl_lineages)
                
                # ìƒì„¸ ì •ë³´ ë¡œê¹…: ì†ŒìŠ¤/íƒ€ê²Ÿ í…Œì´ë¸” í‘œì‹œ
                source_tables = set()
                target_tables = set()
                for l in etl_lineages:
                    source_tables.update(l.source_tables or [])
                    target_tables.update(l.target_tables or [])
                
                log_process("LINEAGE", "ETL_FOUND", 
                    f"{file_name}: ETL {len(etl_lineages)}ê°œ (ì†ŒìŠ¤: {len(source_tables)}ê°œ, íƒ€ê²Ÿ: {len(target_tables)}ê°œ)", 
                    logging.INFO)
                yield emit_message(
                    f"      âœ… [{idx}/{total_files}] {file_name}: ETL {len(etl_lineages)}ê°œ ê°ì§€"
                )
            else:
                yield emit_message(f"      â­ï¸ [{idx}/{total_files}] {file_name}: ETL íŒ¨í„´ ì—†ìŒ")
            
            yield emit_phase_event(
                phase_num=5,
                phase_name="ë¦¬ë‹ˆì§€ ë¶„ì„",
                status="in_progress",
                progress=progress,
                details={"current_file": file_name, "done": idx, "total": total_files, "etl_found": len(all_lineages)}
            )
            
        except Exception as e:
            error_msg = f"{file_name} ë¦¬ë‹ˆì§€ ë¶„ì„ ì‹¤íŒ¨: {e}"
            log_process("LINEAGE", "ERROR", error_msg, logging.ERROR, e)
            raise RuntimeError(error_msg) from e
    
    log_process("LINEAGE", "SCAN_DONE", f"íŒŒì¼ ìŠ¤ìº” ì™„ë£Œ: {files_with_etl}/{total_files}ê°œ íŒŒì¼ì—ì„œ ETL íŒ¨í„´ ë°œê²¬", logging.INFO)
    
    # ETL íŒ¨í„´ì´ ê°ì§€ëœ ê²½ìš° Neo4jì— ì €ì¥
    if all_lineages:
        log_process("LINEAGE", "SAVE_START", f"Neo4j ì €ì¥ ì‹œì‘: {len(all_lineages)}ê°œ ETL íŒ¨í„´", logging.INFO)
        yield emit_message(f"\n   ğŸ’¾ ì´ {len(all_lineages)}ê°œ ETL íŒ¨í„´ â†’ Neo4j ì €ì¥ ì¤‘...")
        yield emit_phase_event(
            phase_num=5,
            phase_name="ë¦¬ë‹ˆì§€ ë¶„ì„",
            status="in_progress",
            progress=85,
            details={"step": "saving", "etl_count": len(all_lineages)}
        )
        
        try:
            # name_case ì˜µì…˜ ê°€ì ¸ì˜¤ê¸°
            name_case = getattr(orchestrator, "name_case", "original")
            
            result = await lineage_analyzer.save_lineage_to_neo4j(
                client=client,
                lineage_list=all_lineages,
                file_name="",
                name_case=name_case,
            )
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if not hasattr(stats, 'etl_count'):
                stats.etl_count = 0
            if not hasattr(stats, 'data_flows'):
                stats.data_flows = 0
            
            stats.etl_count = result.get("etl_nodes", 0)
            stats.data_flows = result.get("data_flows", 0)
            
            log_process("LINEAGE", "COMPLETE", 
                f"ë¦¬ë‹ˆì§€ ì €ì¥ ì™„ë£Œ: ETL {result.get('etl_nodes', 0)}ê°œ, "
                f"READS {result.get('etl_reads', 0)}ê°œ, WRITES {result.get('etl_writes', 0)}ê°œ, "
                f"DATA_FLOWS {result.get('data_flows', 0)}ê°œ", 
                logging.INFO)
            
            yield emit_message(
                f"   âœ… ë¦¬ë‹ˆì§€ ì €ì¥ ì™„ë£Œ: "
                f"ETL í”„ë¡œì‹œì € {result.get('etl_nodes', 0)}ê°œ, "
                f"ETL_READS {result.get('etl_reads', 0)}ê°œ, "
                f"ETL_WRITES {result.get('etl_writes', 0)}ê°œ, "
                f"DATA_FLOWS_TO {result.get('data_flows', 0)}ê°œ"
            )
            yield emit_phase_event(
                phase_num=5,
                phase_name="ë¦¬ë‹ˆì§€ ë¶„ì„",
                status="completed",
                progress=100,
                details={
                    "etl_nodes": result.get('etl_nodes', 0),
                    "etl_reads": result.get('etl_reads', 0),
                    "etl_writes": result.get('etl_writes', 0),
                    "data_flows": result.get('data_flows', 0)
                }
            )
            
        except Exception as e:
            error_msg = f"ë¦¬ë‹ˆì§€ ì €ì¥ ì‹¤íŒ¨: {str(e)}"
            yield emit_message(f"   âŒ {error_msg}")
            log_process("LINEAGE", "ERROR", error_msg, logging.ERROR, e)
            raise RuntimeError(error_msg) from e
    else:
        log_process("LINEAGE", "SKIP", "ETL íŒ¨í„´ ì—†ìŒ - ë¦¬ë‹ˆì§€ ê´€ê³„ ë¯¸ìƒì„±", logging.INFO)
        yield emit_message("   â„¹ï¸ ETL íŒ¨í„´ ì—†ìŒ â†’ ë¦¬ë‹ˆì§€ ê´€ê³„ ë¯¸ìƒì„±")
        yield emit_phase_event(
            phase_num=5,
            phase_name="ë¦¬ë‹ˆì§€ ë¶„ì„",
            status="completed",
            progress=100,
            details={"etl_nodes": 0, "message": "no_etl_patterns"}
        )

