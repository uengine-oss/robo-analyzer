"""DBMS ì½”ë“œ ë¶„ì„ê¸° - PL/SQL AST â†’ Neo4j ê·¸ë˜í”„

í”„ë¡œì‹œì €/í•¨ìˆ˜ ë¶„ì„ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

ë¶„ì„ íŒŒì´í”„ë¼ì¸:
1. AST ìˆ˜ì§‘ (StatementCollector)
2. ì •ì  ê·¸ë˜í”„ ìƒì„± (PROCEDURE, FUNCTION ë…¸ë“œ)
3. DML ë¬¸ ë¶„ì„ (í…Œì´ë¸”/ì»¬ëŸ¼ ê´€ê³„)
4. LLM ë°°ì¹˜ ë¶„ì„ (ìš”ì•½, ë³€ìˆ˜ íƒ€ì…)
5. í”„ë¡œì‹œì € ìš”ì•½ ë° User Story ìƒì„±

ë¦¬íŒ©í† ë§: BaseAstProcessor ìƒì†ìœ¼ë¡œ ê³µí†µ ë¡œì§ ì¬ì‚¬ìš©
"""

from __future__ import annotations

import asyncio
import json
import logging
import re
from typing import Any, Dict, List, Optional, Tuple, Set

from config.settings import settings
from util.rule_loader import RuleLoader
# Exceptions: ëª¨ë“  ì»¤ìŠ¤í…€ ì˜ˆì™¸ëŠ” RuntimeErrorë¡œ ëŒ€ì²´ë¨
from util.text_utils import calculate_code_token, escape_for_cypher, parse_table_identifier, log_process

from analyzer.strategy.base.statement_node import StatementNode
from analyzer.strategy.base.batch import AnalysisBatch
from analyzer.strategy.base.processor import BaseAstProcessor


# ==================== ìƒìˆ˜ ì •ì˜ ====================
# ë…¸ë“œ íƒ€ì… ë¶„ë¥˜
PROCEDURE_TYPES = frozenset(["PROCEDURE", "FUNCTION", "CREATE_PROCEDURE_BODY", "TRIGGER", "BEGIN"])
NON_ANALYSIS_TYPES = frozenset(["CREATE_PROCEDURE_BODY", "FILE", "PROCEDURE", "FUNCTION", "DECLARE", "TRIGGER", "SPEC"])
NON_NEXT_RECURSIVE_TYPES = frozenset(["FUNCTION", "PROCEDURE", "PACKAGE_VARIABLE", "TRIGGER"])
DML_STATEMENT_TYPES = frozenset(["SELECT", "INSERT", "UPDATE", "DELETE", "MERGE", "EXECUTE_IMMEDIATE", "FETCH", "CREATE_TEMP_TABLE", "CTE", "OPEN_CURSOR", "CURSOR_VARIABLE"])
VARIABLE_DECLARATION_TYPES = frozenset(["PACKAGE_VARIABLE", "DECLARE", "SPEC"])

# ê´€ê³„ ë§¤í•‘
TABLE_RELATIONSHIP_MAP = {"r": "FROM", "w": "WRITES"}
VARIABLE_ROLE_MAP = {
    "PACKAGE_VARIABLE": "íŒ¨í‚¤ì§€ ì „ì—­ ë³€ìˆ˜",
    "DECLARE": "ë³€ìˆ˜ ì„ ì–¸ë° ì´ˆê¸°í™”",
    "SPEC": "í•¨ìˆ˜ ë° í”„ë¡œì‹œì € ì…ë ¥ ë§¤ê°œë³€ìˆ˜",
}

# ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ëŠ” ìƒìˆ˜
STATIC_QUERY_BATCH_SIZE = settings.batch.static_query_batch_size
VARIABLE_CONCURRENCY = settings.concurrency.variable_concurrency
MAX_BATCH_TOKEN = settings.batch.max_batch_token
MAX_CONCURRENCY = settings.concurrency.max_concurrency
MAX_SUMMARY_CHUNK_TOKEN = settings.batch.max_summary_chunk_token
MAX_CONTEXT_TOKEN = settings.batch.max_context_token
PARENT_EXPAND_THRESHOLD = settings.batch.parent_expand_threshold

# ì •ê·œì‹ íŒ¨í„´
LINE_NUMBER_PATTERN = re.compile(r"^\d+\s*:")


# ==================== ë°ì´í„° í´ë˜ìŠ¤ ====================
class ProcedureInfo:
    """í”„ë¡œì‹œì €/í•¨ìˆ˜ ì •ë³´"""
    __slots__ = ('key', 'procedure_type', 'procedure_name', 'schema_name', 'start_line', 'end_line', 'pending_nodes')
    
    def __init__(
        self,
        key: str,
        procedure_type: str,
        procedure_name: str,
        schema_name: Optional[str],
        start_line: int,
        end_line: int,
        pending_nodes: int = 0,
    ):
        self.key = key
        self.procedure_type = procedure_type
        self.procedure_name = procedure_name
        self.schema_name = schema_name
        self.start_line = start_line
        self.end_line = end_line
        self.pending_nodes = pending_nodes


# ==================== í—¬í¼ í•¨ìˆ˜ ====================
def get_procedure_name_from_code(code: str) -> Tuple[Optional[str], Optional[str]]:
    """ì½”ë“œ ë¬¸ìì—´ì—ì„œ ìŠ¤í‚¤ë§ˆ/í”„ë¡œì‹œì € ì´ë¦„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    pattern = re.compile(
        r"\b(?:CREATE\s+(?:OR\s+REPLACE\s+)?)?(?:PROCEDURE|FUNCTION|TRIGGER)\s+"
        r"((?:\"[^\"]+\"|[A-Za-z_][\w$#]*)"
        r"(?:\s*\.\s*(?:\"[^\"]+\"|[A-Za-z_][\w$#]*)){0,2})",
        re.IGNORECASE,
    )
    prefix_pattern = re.compile(r"^\d+\s*:\s*")
    normalized = prefix_pattern.sub("", code)
    match = pattern.search(normalized)
    if not match:
        return None, None
    parts = [segment.strip().strip('"') for segment in re.split(r"\s*\.\s*", match.group(1))]
    if len(parts) == 3:
        return parts[0], f"{parts[1]}.{parts[2]}"
    if len(parts) == 2:
        return parts[0], parts[1]
    if parts:
        return None, parts[0]
    return None, None


def build_statement_name(node_type: str, start_line: int) -> str:
    """ë…¸ë“œ íƒ€ì…ê³¼ ì‹œì‘ ë¼ì¸ì„ ì¡°í•©í•œ ì‹ë³„ì ë¬¸ìì—´ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    return f"{node_type}[{start_line}]"


# ==================== RuleLoader í—¬í¼ ====================
def _rule_loader() -> RuleLoader:
    return RuleLoader(target_lang="dbms")


def analyze_code(code: str, context: str, ranges: list, count: int, api_key: str, locale: str) -> Dict[str, Any]:
    """ì½”ë“œ ë¶„ì„ (ì»¨í…ìŠ¤íŠ¸ì™€ ì½”ë“œ ë¶„ë¦¬ ì „ë‹¬)"""
    inputs = {"code": code, "ranges": ranges, "count": count, "locale": locale}
    if context.strip():
        inputs["context"] = context
    return _rule_loader().execute(
        "analysis",
        inputs,
        api_key,
    )


def analyze_dml_tables(code: str, context: str, ranges: list, api_key: str, locale: str) -> Dict[str, Any]:
    """DML í…Œì´ë¸” ë¶„ì„ (ì»¨í…ìŠ¤íŠ¸ì™€ ì½”ë“œ ë¶„ë¦¬ ì „ë‹¬)"""
    inputs = {"code": code, "ranges": ranges, "locale": locale}
    if context.strip():
        inputs["context"] = context
    return _rule_loader().execute(
        "dml",
        inputs,
        api_key,
    )


def analyze_summary_only(summaries: dict, api_key: str, locale: str, previous_summary: str = "") -> Dict[str, Any]:
    """í”„ë¡œì‹œì €/í•¨ìˆ˜ ì „ì²´ ìš”ì•½ ìƒì„± (Summaryë§Œ)."""
    return _rule_loader().execute(
        "procedure_summary_only",
        {"summaries": summaries, "locale": locale, "previous_summary": previous_summary},
        api_key,
    )


def analyze_user_story(summary: str, api_key: str, locale: str) -> Dict[str, Any]:
    """í”„ë¡œì‹œì €/í•¨ìˆ˜ User Story + AC ìƒì„±."""
    return _rule_loader().execute(
        "procedure_user_story",
        {"summary": summary, "locale": locale},
        api_key,
    )


def summarize_table_metadata(
    table_name: str,
    table_sentences: list,
    column_sentences: dict,
    column_metadata: dict,
    api_key: str,
    locale: str,
) -> Dict[str, Any]:
    return _rule_loader().execute(
        "table_summary",
        {
            "table_name": table_name,
            "table_sentences": table_sentences,
            "column_sentences": column_sentences,
            "column_metadata": column_metadata,
            "locale": locale,
        },
        api_key,
    )


def analyze_variables(declaration_code: str, api_key: str, locale: str) -> Dict[str, Any]:
    return _rule_loader().execute(
        "variables",
        {"declaration_code": declaration_code, "locale": locale},
        api_key,
    )


def extract_parent_context(skeleton_code: str, ancestor_context: str, api_key: str, locale: str) -> str:
    """ë¶€ëª¨ ë…¸ë“œì˜ í•µì‹¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    result = _rule_loader().execute(
        "parent_context",
        {"skeleton_code": skeleton_code, "ancestor_context": ancestor_context, "locale": locale},
        api_key,
    )

    if isinstance(result, dict):
        return result.get("context_summary", "").strip()
    raise ValueError(f"parent_context ê·œì¹™ì´ dictê°€ ì•„ë‹Œ ê°’ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤: {type(result)}")


# ==================== ë…¸ë“œ ìˆ˜ì§‘ê¸° ====================
class StatementCollector:
    """ASTë¥¼ í›„ìœ„ìˆœíšŒí•˜ì—¬ `StatementNode`ì™€ í”„ë¡œì‹œì € ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    file_contentëŠ” ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŒ - AST JSONì˜ code ì†ì„± ì‚¬ìš©.
    """
    def __init__(self, antlr_data: Dict[str, Any], directory: str, file_name: str):
        """ìˆ˜ì§‘ê¸°ì— í•„ìš”í•œ AST ë°ì´í„°ì™€ íŒŒì¼ ë©”íƒ€ ì •ë³´ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.antlr_data = antlr_data
        self.directory = directory
        self.file_name = file_name
        self.nodes: List[StatementNode] = []
        self.procedures: Dict[str, ProcedureInfo] = {}
        self._node_id = 0

    def _parse_code_to_lines(self, code: str, start_line: int, end_line: int) -> List[Tuple[int, str]]:
        """JSON code ì†ì„±ì„ [(line_no, text), ...] í˜•íƒœë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
        
        Args:
            code: '1: CREATE...\n2: ...' ë˜ëŠ” '1: CREATE...\r\n2: ...' í˜•íƒœì˜ ë¬¸ìì—´
            start_line: ë…¸ë“œ ì‹œì‘ ë¼ì¸ (fallbackìš©)
            end_line: ë…¸ë“œ ì¢…ë£Œ ë¼ì¸ (fallbackìš©)
            
        Returns:
            [(line_no, text), ...] í˜•íƒœì˜ íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        if not code:
            return []
        
        # \r\n ë˜ëŠ” \nìœ¼ë¡œ ë¶„ë¦¬
        lines = code.replace('\r\n', '\n').split('\n')
        parsed_lines: List[Tuple[int, str]] = []
        
        for line in lines:
            if not line:
                continue
            # '123: text' í˜•íƒœ íŒŒì‹±
            match = re.match(r'^(\d+):\s?(.*)', line)
            if match:
                line_no = int(match.group(1))
                text = match.group(2)
                parsed_lines.append((line_no, text))
            else:
                # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì „ì²´ ë¼ì¸ì„ í…ìŠ¤íŠ¸ë¡œ (fallback)
                if parsed_lines:
                    last_no = parsed_lines[-1][0]
                    parsed_lines.append((last_no + 1, line))
                else:
                    parsed_lines.append((start_line, line))
        
        return parsed_lines

    def collect(self) -> Tuple[List[StatementNode], Dict[str, ProcedureInfo]]:
        """AST ì „ì—­ì„ í›„ìœ„ ìˆœíšŒí•˜ì—¬ ë…¸ë“œ ëª©ë¡ê³¼ í”„ë¡œì‹œì € ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        # ë£¨íŠ¸ ë…¸ë“œë¶€í„° í›„ìœ„ìˆœíšŒí•©ë‹ˆë‹¤ (ìì‹ â†’ ë¶€ëª¨ ìˆœì„œ ë³´ì¥)
        self._visit(self.antlr_data, current_proc=None, current_type=None, current_schema=None)
        return self.nodes, self.procedures

    def _make_proc_key(self, procedure_name: Optional[str], start_line: int) -> str:
        """í”„ë¡œì‹œì € ê³ ìœ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        base = procedure_name or f"anonymous_{start_line}"
        return f"{self.directory}:{self.file_name}:{base}:{start_line}"

    def _should_treat_as_procedure(self, node_type: str, current_proc: Optional[str]) -> bool:
        """ë…¸ë“œ íƒ€ì…ì´ í”„ë¡œì‹œì €ë¡œ ì²˜ë¦¬ë˜ì–´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
        if node_type not in PROCEDURE_TYPES:
            return False
        if node_type == "BEGIN":
            return current_proc is None
        return True

    def _visit(
        self,
        node: Dict[str, Any],
        current_proc: Optional[str],
        current_type: Optional[str],
        current_schema: Optional[str],
    ) -> Optional[StatementNode]:
        """ì¬ê·€ì ìœ¼ë¡œ ASTë¥¼ ë‚´ë ¤ê°€ë©° StatementNodeë¥¼ ìƒì„±í•˜ê³  ë¶€ëª¨-ìì‹ ê´€ê³„ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤."""
        start_line = node['startLine']
        end_line = node['endLine']
        node_type = node['type']
        children = node.get('children', []) or []

        child_nodes: List[StatementNode] = []
        procedure_key = current_proc
        procedure_type = current_type
        schema_name = current_schema

        # AST JSONì˜ code ì†ì„±ì—ì„œ ë¼ì¸ ì •ë³´ ì¶”ì¶œ
        # code í˜•ì‹: "1: CREATE...\r\n2: ..."
        raw_code = node.get('code', '')
        line_entries = self._parse_code_to_lines(raw_code, start_line, end_line)
        code = '\n'.join(f"{line_no}: {text}" for line_no, text in line_entries)

        # í”„ë¡œì‹œì € íƒ€ì… ì²˜ë¦¬: PROCEDURE/FUNCTION/TRIGGER/BEGIN
        if self._should_treat_as_procedure(node_type, current_proc):
            if node_type == "BEGIN":
                procedure_key = self._make_proc_key(None, start_line)
                procedure_type = "BEGIN"
                schema_name = None
                proc_name = f"anonymous_{start_line}"
            else:
                # JSONì—ì„œ name, schema ì§ì ‘ ì¶”ì¶œ (ì •ê·œì‹ ì¶”ì¶œë³´ë‹¤ ì •í™•)
                name_from_json = node.get('name')
                schema_from_json = node.get('schema')
                
                # JSONì— nameì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ì¡´ ì •ê·œì‹ fallback
                if name_from_json:
                    name_candidate = name_from_json
                    schema_candidate = schema_from_json
                else:
                    # fallback: ê¸°ì¡´ ì •ê·œì‹ ì¶”ì¶œ (deprecated)
                    schema_candidate, name_candidate = get_procedure_name_from_code(code)
                
                procedure_key = self._make_proc_key(name_candidate, start_line)
                procedure_type = node_type
                schema_name = schema_candidate
                proc_name = name_candidate or procedure_key
            
            if procedure_key not in self.procedures:
                self.procedures[procedure_key] = ProcedureInfo(
                    key=procedure_key,
                    procedure_type=procedure_type,
                    procedure_name=proc_name,
                    schema_name=schema_name,
                    start_line=start_line,
                    end_line=end_line,
                )
                log_process("ANALYZE", "COLLECT", f"ğŸ“‹ í”„ë¡œì‹œì € ì„ ì–¸ ë°œê²¬: {proc_name} (ë¼ì¸ {start_line}~{end_line})")

        for child in children:
            child_node = self._visit(child, procedure_key, procedure_type, schema_name)
            if child_node is not None:
                child_nodes.append(child_node)

        # ë¶„ì„ ê°€ëŠ¥ ì—¬ë¶€ ê³„ì‚° (ì›ë³¸ê³¼ ë™ì¼í•˜ê²Œ NON_ANALYSIS_TYPES ê¸°ì¤€)
        analyzable = node_type not in NON_ANALYSIS_TYPES
        token = calculate_code_token(code)
        dml = node_type in DML_STATEMENT_TYPES
        has_children = bool(child_nodes)

        # í˜„ì¬ í”„ë¡œì‹œì € ì •ë³´ ì¡°íšŒ
        proc_info = self.procedures.get(procedure_key) if procedure_key else None
        proc_name = proc_info.procedure_name if proc_info else None

        self._node_id += 1
        statement_node = StatementNode(
            node_id=self._node_id,
            start_line=start_line,
            end_line=end_line,
            node_type=node_type,
            code=code,
            token=token,
            has_children=has_children,
            analyzable=analyzable,
            # í†µí•© í•„ë“œ
            unit_key=procedure_key,
            unit_name=proc_name,
            unit_kind=procedure_type,
            # DBMS ì „ìš© í•„ë“œ
            schema_name=schema_name,
            dml=dml,
            # AST JSON ë©”íƒ€ë°ì´í„° (ì„ íƒì )
            signature=node.get('signature'),
            parameters=node.get('parameters'),
            lines=line_entries,
        )
        for child_node in child_nodes:
            child_node.parent = statement_node
        statement_node.children.extend(child_nodes)

        # í”„ë¡œì‹œì € ìš”ì•½ ì™„ë£Œ ì‹œì ì„ íŒë³„í•˜ê¸° ìœ„í•´ pending ë…¸ë“œ ìˆ˜ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.
        # analyzable=Trueì¸ ë…¸ë“œëŠ” ë°°ì¹˜ì— í¬í•¨ë˜ë¯€ë¡œ, completion_eventëŠ” ë°°ì¹˜ ì™„ë£Œ ì‹œì—ë§Œ ì„¤ì •
        # analyzable=Falseì¸ ë…¸ë“œëŠ” ë°°ì¹˜ì— í¬í•¨ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ìˆ˜ì§‘ ì‹œ ì²˜ë¦¬
        if not analyzable:
            # ë°°ì¹˜ì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ë…¸ë“œëŠ” ìˆ˜ì§‘ ì‹œ summary + completion_event ì„¤ì •
            statement_node.summary = statement_node.get_raw_code()
            statement_node.completion_event.set()
        elif procedure_key and procedure_key in self.procedures:
            # í”„ë¡œì‹œì €ì— ì†í•œ ë¶„ì„ ëŒ€ìƒ ë…¸ë“œ
            self.procedures[procedure_key].pending_nodes += 1
        # else: analyzable=Trueì´ì§€ë§Œ procedure_key ì—†ìŒ â†’ ë°°ì¹˜ì—ì„œ LLM ë¶„ì„ í›„ completion_event ì„¤ì •ë¨

        self.nodes.append(statement_node)
        log_process("ANALYZE", "COLLECT", f"âœ… {node_type} ë…¸ë“œ ìˆ˜ì§‘ ì™„ë£Œ: ë¼ì¸ {start_line}~{end_line}, í† í° {token}, ìì‹ {len(child_nodes)}ê°œ")
        return statement_node


# ==================== AST í”„ë¡œì„¸ì„œ ë³¸ì²´ ====================
class DbmsAstProcessor(BaseAstProcessor):
    """DBMS AST ì²˜ë¦¬ ë° LLM ë¶„ì„ íŒŒì´í”„ë¼ì¸
    
    BaseAstProcessorë¥¼ ìƒì†í•˜ì—¬ ê³µí†µ íŒŒì´í”„ë¼ì¸ ì¬ì‚¬ìš©.
    DBMS ì „ìš© ë¡œì§ë§Œ êµ¬í˜„.
    """
    def __init__(
        self,
        antlr_data: dict,
        directory: str,
        file_name: str,
        api_key: str,
        locale: str,
        dbms: str,
        last_line: int,
        default_schema: str = "public",
        ddl_table_metadata: Optional[Dict[Tuple[str, str], Dict[str, Any]]] = None,
        name_case: str = "original",
    ):
        """DBMS Analyzer ì´ˆê¸°í™”
        
        file_contentëŠ” ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŒ - AST JSONì˜ code ì†ì„± ì‚¬ìš©.
        """
        super().__init__(
            antlr_data=antlr_data,
            directory=directory,
            file_name=file_name,
            api_key=api_key,
            locale=locale,
            last_line=last_line,
        )
        
        self.dbms = (dbms or 'postgres').lower()
        self.default_schema = default_schema
        self._ddl_table_metadata = ddl_table_metadata or {}
        self.name_case = (name_case or 'original').lower()  # original, uppercase, lowercase
        
        self.table_base_props = ""
        
        # í…Œì´ë¸”/ì»¬ëŸ¼ ì„¤ëª… ìš”ì•½ìš© ì €ì¥ì†Œ (DML ë¶„ì„ì—ì„œ ìˆ˜ì§‘)
        self._table_summary_store: Dict[Tuple[str, str], Dict[str, Any]] = {}

    def _apply_name_case(self, name: str) -> str:
        """ë©”íƒ€ë°ì´í„° ëŒ€ì†Œë¬¸ì ë³€í™˜ ì ìš©
        
        Args:
            name: ë³€í™˜í•  ì´ë¦„ (í…Œì´ë¸”ëª…, ì»¬ëŸ¼ëª…, ìŠ¤í‚¤ë§ˆëª… ë“±)
        
        Returns:
            ë³€í™˜ëœ ì´ë¦„
        """
        if not name:
            return name
        if self.name_case == "uppercase":
            return name.upper()
        elif self.name_case == "lowercase":
            return name.lower()
        return name  # original: ê·¸ëŒ€ë¡œ ë°˜í™˜

    # =========================================================================
    # BaseAstProcessor ì¶”ìƒ ë©”ì„œë“œ êµ¬í˜„
    # =========================================================================
    
    def _collect_nodes(self) -> Tuple[List[StatementNode], Dict[str, ProcedureInfo]]:
        """AST ìˆ˜ì§‘"""
        collector = StatementCollector(
            self.antlr_data, self.directory, self.file_name
        )
        return collector.collect()

    def _get_excluded_context_types(self) -> Set[str]:
        """ì»¨í…ìŠ¤íŠ¸ ìƒì„±ì—ì„œ ì œì™¸í•  ë…¸ë“œ íƒ€ì…"""
        return PROCEDURE_TYPES

    def _use_dml_ranges(self) -> bool:
        """DBMSëŠ” DML ë²”ìœ„ í¬í•¨"""
        return True

    async def _extract_parent_context(self, skeleton_code: str, ancestor_context: str) -> str:
        """ë¶€ëª¨ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        return await asyncio.to_thread(
            extract_parent_context,
            skeleton_code,
            ancestor_context,
            self.api_key,
            self.locale,
        )

    def _build_static_node_queries(self, node: StatementNode) -> List[str]:
        """ì •ì  ë…¸ë“œ ìƒì„± ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        queries: List[str] = []
        label = node.node_type
        
        # name ì†ì„± ê²°ì •
        if label == "FILE":
            node_name = self.file_name
        elif label in PROCEDURE_TYPES and node.unit_name:
            node_name = node.unit_name
        else:
            node_name = f"{label}[{node.start_line}]"
        
        escaped_name = escape_for_cypher(node_name)
        has_children = "true" if node.has_children else "false"
        escaped_code = escape_for_cypher(node.code)
        
        base_set = [
            f"__cy_n__.endLine = {node.end_line}",
            f"__cy_n__.name = '{escaped_name}'",
            f"__cy_n__.node_code = '{escaped_code}'",
            f"__cy_n__.token = {node.token}",
            f"__cy_n__.has_children = {has_children}",
        ]
        
        # AST JSON ë©”íƒ€ë°ì´í„° ì†ì„± ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ)
        if node.signature:
            base_set.append(f"__cy_n__.signature = '{escape_for_cypher(node.signature)}'")
        if node.parameters:
            base_set.append(f"__cy_n__.parameters = '{escape_for_cypher(node.parameters)}'")
        
        # PROCEDURE/FUNCTION: procedure_name, schema_name, procedure_type ì†ì„± ì¶”ê°€
        if label in PROCEDURE_TYPES and node.unit_name:
            base_set.append(f"__cy_n__.procedure_name = '{escape_for_cypher(node.unit_name)}'")
            base_set.append(f"__cy_n__.procedure_type = '{label}'")
            if node.schema_name:
                base_set.append(f"__cy_n__.schema_name = '{escape_for_cypher(node.schema_name)}'")
        elif node.unit_name:
            base_set.append(f"__cy_n__.procedure_name = '{escape_for_cypher(node.unit_name)}'")
            if node.schema_name:
                base_set.append(f"__cy_n__.schema_name = '{escape_for_cypher(node.schema_name)}'")
        
        if node.has_children:
            escaped_placeholder = escape_for_cypher(node.get_placeholder_code())
            base_set.append(f"__cy_n__.summarized_code = '{escaped_placeholder}'")
        
        base_set_str = ", ".join(base_set)
        
        # PROCEDURE/FUNCTION ë…¸ë“œ: MERGEë¡œ ìƒì„± (ì¤‘ë³µ ë°©ì§€)
        if label in PROCEDURE_TYPES and node.unit_name:
            escaped_proc_name = escape_for_cypher(node.unit_name)
            escaped_schema = escape_for_cypher(node.schema_name or "")
            schema_match = f"schema_name: '{escaped_schema}', " if node.schema_name else ""
            queries.append(
                f"MERGE (__cy_n__:{label} {{{schema_match}procedure_name: '{escaped_proc_name}'}})\n"
                f"SET __cy_n__.startLine = {node.start_line}, __cy_n__.directory = '{escape_for_cypher(self.full_directory)}', __cy_n__.file_name = '{self.file_name}', {base_set_str}\n"
                f"RETURN __cy_n__"
            )
        else:
            queries.append(
                f"MERGE (__cy_n__:{label} {{startLine: {node.start_line}, {self.node_base_props}}})\n"
                f"SET {base_set_str}\n"
                f"RETURN __cy_n__"
            )
        return queries

    def _build_relationship_queries(self) -> List[str]:
        """ì •ì  ê´€ê³„ ì¿¼ë¦¬ (CONTAINS, PARENT_OF, NEXT)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        queries: List[str] = []
        
        for node in self._nodes or []:
            for child in node.children:
                if node.node_type == "FILE" and child.node_type in PROCEDURE_TYPES:
                    queries.append(self._build_contains_query(node, child))
                else:
                    queries.append(self._build_parent_of_query(node, child))
            
            # NEXT ê´€ê³„
            prev = None
            for child in node.children:
                if prev:
                    queries.append(self._build_next_query(prev, child))
                prev = child
        
        return queries
    
    def _build_next_query(self, prev: StatementNode, current: StatementNode) -> str:
        """NEXT ê´€ê³„ ì¿¼ë¦¬"""
        return (
            f"MATCH (__cy_prev__:{prev.node_type} {{startLine: {prev.start_line}, {self.node_base_props}}})\n"
            f"MATCH (__cy_curr__:{current.node_type} {{startLine: {current.start_line}, {self.node_base_props}}})\n"
            f"MERGE (__cy_prev__)-[__cy_r__:NEXT]->(__cy_curr__)\n"
            f"RETURN __cy_r__"
        )

    async def _run_preprocessing(self) -> List[str]:
        """ë³€ìˆ˜ ì„ í–‰ ì²˜ë¦¬"""
        return await self._analyze_variable_nodes()

    async def _invoke_llm(self, batch: AnalysisBatch) -> Tuple[Optional[Dict[str, Any]], Optional[Dict[str, Any]]]:
        """LLM í˜¸ì¶œ (ì¼ë°˜ ë¶„ì„ + DML ë¶„ì„)"""
        general_task = None
        if batch.ranges:
            code, context = batch.build_payload()
            general_task = asyncio.to_thread(
                analyze_code,
                code,
                context,
                batch.ranges,
                len(batch.ranges),
                self.api_key,
                self.locale,
            )

        table_task = None
        dml_payload = batch.build_dml_payload()
        if dml_payload and batch.dml_ranges:
            code, context = dml_payload
            table_task = asyncio.to_thread(
                analyze_dml_tables,
                code,
                context,
                batch.dml_ranges,
                self.api_key,
                self.locale,
            )

        if general_task and table_task:
            # asyncio.gatherëŠ” listë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ tupleë¡œ ë³€í™˜
            results = await asyncio.gather(general_task, table_task)
            return tuple(results)
        if general_task:
            return await general_task, None
        if table_task:
            return None, await table_task
        raise RuntimeError("LLM ë¶„ì„ ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤")

    def _build_analysis_queries(
        self, 
        batch: AnalysisBatch, 
        llm_result: Any,
        unit_summary_store: Optional[Dict[str, Dict[str, str]]] = None,
    ) -> List[str]:
        """LLM ë¶„ì„ ê²°ê³¼ë¥¼ ì¿¼ë¦¬ë¡œ ë³€í™˜"""
        queries: List[str] = []
        
        # llm_resultëŠ” (general_result, table_result) íŠœí”Œì´ì–´ì•¼ í•¨
        if not isinstance(llm_result, tuple):
            raise RuntimeError(f"ë°°ì¹˜#{batch.batch_id} llm_resultê°€ tupleì´ ì•„ë‹˜: {type(llm_result).__name__}")
        
        general_result, table_result = llm_result
        
        # ì¼ë°˜ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ (None í—ˆìš© - í…Œì´ë¸” ë¶„ì„ë§Œ ìˆëŠ” ê²½ìš°)
        general_result = self.validate_dict_result(
            general_result, "general_result", batch.batch_id, allow_none=True
        )
        if general_result:  # ë¹ˆ dictì´ë©´ ìŠ¤í‚µ
            analysis_list = general_result.get("analysis") or []
            for node, analysis in zip(batch.nodes, analysis_list):
                if not analysis:
                    continue
                
                # Summary ì—…ë°ì´íŠ¸
                summary = analysis.get("summary") or ""
                if summary:
                    escaped_summary = escape_for_cypher(str(summary))
                    escaped_code = escape_for_cypher(node.code)
                    node_name = build_statement_name(node.node_type, node.start_line)
                    escaped_node_name = escape_for_cypher(node_name)
                    
                    queries.append(
                        f"MATCH (__cy_n__:{node.node_type} {{startLine: {node.start_line}, {self.node_base_props}}})\n"
                        f"SET __cy_n__.endLine = {node.end_line}, __cy_n__.name = '{escaped_node_name}', "
                        f"__cy_n__.summary = '{escaped_summary}', __cy_n__.node_code = '{escaped_code}', "
                        f"__cy_n__.token = {node.token}, __cy_n__.procedure_name = '{escape_for_cypher(node.unit_name or '')}', "
                        f"__cy_n__.has_children = {'true' if node.has_children else 'false'}\n"
                        f"RETURN __cy_n__"
                    )
                    
                    # í”„ë¡œì‹œì €ë³„ summary ì €ì¥
                    if unit_summary_store is not None and node.unit_key:
                        if node.unit_key in unit_summary_store:
                            key = f"{node.node_type}_{node.start_line}_{node.end_line}"
                            unit_summary_store[node.unit_key][key] = summary
                
                # CALL ê´€ê³„ ìƒì„±
                for call_name in analysis.get('calls', []) or []:
                    if '.' in call_name:
                        package_raw, proc_raw = call_name.split('.', 1)
                        package_name = escape_for_cypher(package_raw.strip())
                        proc_name = escape_for_cypher(proc_raw.strip())
                        queries.append(
                            f"MATCH (__cy_c__:{node.node_type} {{startLine: {node.start_line}, {self.node_base_props}}})\n"
                            f"MERGE (__cy_target__:PROCEDURE {{directory: '{package_name}', procedure_name: '{proc_name}'}})\n"
                            f"MERGE (__cy_c__)-[__cy_r__:CALL {{scope: 'external'}}]->(__cy_target__)\n"
                            f"RETURN __cy_c__, __cy_target__, __cy_r__"
                        )
                    else:
                        escaped_call = escape_for_cypher(call_name)
                        queries.append(
                            f"MATCH (__cy_c__:{node.node_type} {{startLine: {node.start_line}, {self.node_base_props}}})\n"
                            f"MATCH (__cy_p__ {{procedure_name: '{escaped_call}', {self.node_base_props}}})\n"
                            f"WHERE __cy_p__:PROCEDURE OR __cy_p__:FUNCTION\n"
                            f"MERGE (__cy_c__)-[__cy_r__:CALL {{scope: 'internal'}}]->(__cy_p__)\n"
                            f"RETURN __cy_c__, __cy_p__, __cy_r__"
                        )
                
                # ë³€ìˆ˜ ì‚¬ìš© ë§ˆí‚¹
                for var_name in analysis.get('variables', []) or []:
                    queries.append(
                        f"MATCH (__cy_v__:Variable {{name: '{escape_for_cypher(var_name)}', {self.node_base_props}}})\n"
                        f"SET __cy_v__.`{node.start_line}_{node.end_line}` = 'Used'\n"
                        f"RETURN __cy_v__"
                    )
        
        # í…Œì´ë¸” ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ (None í—ˆìš© - ì¼ë°˜ ë¶„ì„ë§Œ ìˆëŠ” ê²½ìš°)
        table_result = self.validate_dict_result(
            table_result, "table_result", batch.batch_id, allow_none=True
        )
        if table_result:  # ë¹ˆ dictì´ë©´ ìŠ¤í‚µ
            table_queries = self._build_table_queries(batch, table_result)
            queries.extend(table_queries)
        
        return queries

    async def _process_unit_summaries(
        self, 
        unit_summary_store: Dict[str, Dict[str, str]]
    ) -> List[str]:
        """í”„ë¡œì‹œì €ë³„ summary ì²˜ë¦¬ + í…Œì´ë¸”/ì»¬ëŸ¼ ì„¤ëª… ë³´ê°•"""
        queries: List[str] = []
        
        procedures = self._unit_info
        if not procedures:
            # í”„ë¡œì‹œì €ê°€ ì—†ì–´ë„ í…Œì´ë¸”/ì»¬ëŸ¼ ì„¤ëª… ë³´ê°•ì€ ì‹¤í–‰í•´ì•¼ í•¨
            table_queries = await self._finalize_table_summaries()
            queries.extend(table_queries)
            return queries
        
        for proc_key, info in procedures.items():
            summaries = unit_summary_store.get(proc_key, {})
            if not summaries:
                continue
            
            # í”„ë¡œì‹œì € ìµœìƒìœ„ ë…¸ë“œ ì°¾ê¸°
            proc_root = next(
                (n for n in (self._nodes or []) 
                 if n.unit_key == proc_key and n.parent is None),
                None,
            )
            if proc_root and not proc_root.ok:
                log_process("ANALYZE", "SUMMARY", f"âš ï¸ {info.procedure_name}: í•˜ìœ„ ë¶„ì„ ì‹¤íŒ¨ë¡œ ìµœì¢… summary ìƒì„± ìŠ¤í‚µ")
                continue
            
            # ì²­í¬ ë¶„í• 
            chunks = self._split_summaries_by_token(summaries, MAX_SUMMARY_CHUNK_TOKEN)
            if not chunks:
                continue
            
            log_process("ANALYZE", "SUMMARY", f"ğŸ“¦ {info.procedure_name}: summary ì²­í¬ ë¶„í•  ({len(chunks)}ê°œ)")
            
            # ì²­í¬ë³„ ì²˜ë¦¬ (ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ â†’ ì „ì²´ ë¶„ì„ ì¤‘ë‹¨)
            async def process_chunk(chunk: dict) -> str:
                result = await asyncio.to_thread(
                    analyze_summary_only, chunk, self.api_key, self.locale, ""
                )
                validated = self.validate_dict_result(result, "ì²­í¬ ë¶„ì„")
                return validated.get('summary', '')
            
            chunk_results = await asyncio.gather(*[process_chunk(c) for c in chunks])
            chunk_results = [r for r in chunk_results if r]
            
            if not chunk_results:
                raise RuntimeError(f"{info.procedure_name}: ì²­í¬ ì²˜ë¦¬ ê²°ê³¼ê°€ ëª¨ë‘ ë¹„ì–´ìˆìŒ")
            
            # ì²­í¬ í†µí•©
            if len(chunk_results) == 1:
                final_summary = chunk_results[0]
            else:
                combined = {f"CHUNK_{i+1}": s for i, s in enumerate(chunk_results)}
                result = await asyncio.to_thread(
                    analyze_summary_only, combined, self.api_key, self.locale, ""
                )
                validated = self.validate_dict_result(result, "ì²­í¬ í†µí•©")
                final_summary = validated.get('summary') or "\n\n".join(chunk_results)
            
            log_process("ANALYZE", "SUMMARY", f"âœ… {info.procedure_name}: summary í†µí•© ì™„ë£Œ")
            
            # User Story ìƒì„± (ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ)
            all_user_stories = []
            if final_summary:
                us_result = await asyncio.to_thread(
                    analyze_user_story, final_summary, self.api_key, self.locale
                )
                validated = self.validate_dict_result(us_result, "User Story")
                all_user_stories = validated.get('user_stories', []) or []
            
            # Neo4j ì¿¼ë¦¬ ìƒì„±
            summary_json = json.dumps(final_summary, ensure_ascii=False)
            queries.append(
                f"MATCH (__cy_n__:{info.procedure_type} {{procedure_name: '{escape_for_cypher(info.procedure_name)}', {self.node_base_props}}})\n"
                f"SET __cy_n__.summary = {summary_json}\n"
                f"RETURN __cy_n__"
            )
            
            # User Story ë…¸ë“œ ìƒì„±
            proc_name_escaped = escape_for_cypher(info.procedure_name)
            for us_idx, us in enumerate(all_user_stories, 1):
                us_id = us.get('id', f"US-{us_idx}")
                role = escape_for_cypher(us.get('role', ''))
                goal = escape_for_cypher(us.get('goal', ''))
                benefit = escape_for_cypher(us.get('benefit', ''))
                
                queries.append(
                    f"MATCH (__cy_p__:{info.procedure_type} {{procedure_name: '{proc_name_escaped}', {self.node_base_props}}})\n"
                    f"MERGE (__cy_us__:UserStory {{id: '{us_id}', procedure_name: '{proc_name_escaped}', {self.node_base_props}}})\n"
                    f"SET __cy_us__.role = '{role}', __cy_us__.goal = '{goal}', __cy_us__.benefit = '{benefit}'\n"
                    f"MERGE (__cy_p__)-[__cy_r__:HAS_USER_STORY]->(__cy_us__)\n"
                    f"RETURN __cy_p__, __cy_us__, __cy_r__"
                )
                
                # Acceptance Criteria ë…¸ë“œ
                for ac_idx, ac in enumerate(us.get('acceptance_criteria', []), 1):
                    if not isinstance(ac, dict):
                        continue
                    ac_id = ac.get('id', f"AC-{us_idx}-{ac_idx}")
                    ac_title = escape_for_cypher(ac.get('title', ''))
                    ac_given = json.dumps(ac.get('given', []), ensure_ascii=False)
                    ac_when = json.dumps(ac.get('when', []), ensure_ascii=False)
                    ac_then = json.dumps(ac.get('then', []), ensure_ascii=False)
                    
                    queries.append(
                        f"MATCH (__cy_us__:UserStory {{id: '{us_id}', {self.node_base_props}}})\n"
                        f"MERGE (__cy_ac__:AcceptanceCriteria {{id: '{ac_id}', user_story_id: '{us_id}', {self.node_base_props}}})\n"
                        f"SET __cy_ac__.title = '{ac_title}', __cy_ac__.given = {ac_given}, __cy_ac__.when = {ac_when}, __cy_ac__.then = {ac_then}\n"
                        f"MERGE (__cy_us__)-[__cy_r__:HAS_AC]->(__cy_ac__)\n"
                        f"RETURN __cy_us__, __cy_ac__, __cy_r__"
                    )
            
            us_count = len(all_user_stories)
            log_process("ANALYZE", "SUMMARY", f"âœ… {info.procedure_name}: User Story {us_count}ê°œ ìƒì„±")
        
        # í…Œì´ë¸”/ì»¬ëŸ¼ ì„¤ëª… ìš”ì•½ ì²˜ë¦¬
        table_queries = await self._finalize_table_summaries()
        queries.extend(table_queries)
        
        return queries

    # =========================================================================
    # DBMS ì „ìš© ë©”ì„œë“œ
    # =========================================================================

    async def _analyze_variable_nodes(self) -> List[str]:
        """ë³€ìˆ˜ ì„ ì–¸ ë…¸ë“œë¥¼ ë¶„ì„í•˜ê³  ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        queries: List[str] = []
        variable_nodes = [n for n in (self._nodes or []) if n.node_type in VARIABLE_DECLARATION_TYPES]
        
        if not variable_nodes:
            return queries
        
        semaphore = asyncio.Semaphore(VARIABLE_CONCURRENCY)
        
        async def analyze_one(node: StatementNode) -> List[str]:
            """ë³€ìˆ˜ ë¶„ì„ (ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ â†’ ì „ì²´ ë¶„ì„ ì¤‘ë‹¨)"""
            async with semaphore:
                result = await asyncio.to_thread(
                    analyze_variables, node.code, self.api_key, self.locale
                )
                return self._build_variable_queries(node, result)
        
        results = await asyncio.gather(*[analyze_one(n) for n in variable_nodes])
        for r in results:
            queries.extend(r)
        
        return queries

    def _build_variable_queries(self, node: StatementNode, result: Dict[str, Any]) -> List[str]:
        """ë³€ìˆ˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì¿¼ë¦¬ë¡œ ë³€í™˜"""
        queries: List[str] = []
        
        if not isinstance(result, dict):
            raise RuntimeError(f"ë³€ìˆ˜ ë¶„ì„ ê²°ê³¼ê°€ dictê°€ ì•„ë‹˜ (node={node.start_line}): {type(result).__name__}")
        
        variables = result.get("variables") or []
        if not variables:
            return queries
        
        node_match = f"MATCH (__cy_n__:{node.node_type} {{startLine: {node.start_line}, {self.node_base_props}}})"
        
        for var in variables:
            var_name = var.get("name", "")
            var_type = var.get("type", "")
            var_role = var.get("role", "")
            var_desc = var.get("description", "")
            
            if not var_name:
                continue
            
            escaped_name = escape_for_cypher(var_name)
            escaped_type = escape_for_cypher(var_type)
            escaped_role = escape_for_cypher(VARIABLE_ROLE_MAP.get(var_role, var_role))
            escaped_desc = escape_for_cypher(var_desc)
            
            queries.append(
                f"{node_match}\n"
                f"MERGE (__cy_v__:Variable {{name: '{escaped_name}', {self.node_base_props}}})\n"
                f"SET __cy_v__.type = '{escaped_type}', __cy_v__.role = '{escaped_role}', __cy_v__.description = '{escaped_desc}'\n"
                f"MERGE (__cy_n__)-[:DECLARES]->(__cy_v__)\n"
                f"RETURN __cy_v__"
            )
        
        return queries

    def _build_table_queries(
        self,
        batch: AnalysisBatch,
        table_result: Dict[str, Any]
    ) -> List[str]:
        """DML í…Œì´ë¸” ë¶„ì„ ê²°ê³¼ë¥¼ ì¿¼ë¦¬ë¡œ ë³€í™˜"""
        queries: List[str] = []
        node_map: Dict[Tuple[int, int], StatementNode] = {
            (node.start_line, node.end_line): node for node in batch.nodes
        }
        ranges = table_result.get('ranges', []) or []
        
        for range_entry in ranges:
            start_line = range_entry.get('startLine')
            end_line = range_entry.get('endLine')
            tables = range_entry.get('tables') or []
            
            try:
                start_line = int(start_line)
                end_line = int(end_line)
            except (TypeError, ValueError) as e:
                raise RuntimeError(f"LLM í…Œì´ë¸” ë¶„ì„ ê²°ê³¼ì— ì˜ëª»ëœ ë¼ì¸ ë²ˆí˜¸: startLine={range_entry.get('startLine')}, endLine={range_entry.get('endLine')}") from e
            
            node = node_map.get((start_line, end_line))
            if not node:
                continue
            
            node_merge = f"MATCH (__cy_n__:{node.node_type} {{startLine: {node.start_line}, {self.node_base_props}}})"
            
            # CREATE_TEMP_TABLE ì²˜ë¦¬
            if node.node_type == 'CREATE_TEMP_TABLE':
                for entry in tables:
                    table_name = (entry.get('table') or '').strip()
                    if not table_name:
                        continue
                    schema_part_raw, name_part_raw, _ = parse_table_identifier(table_name)
                    # ëŒ€ì†Œë¬¸ì ë³€í™˜ ì ìš©
                    schema_part = self._apply_name_case(schema_part_raw)
                    name_part = self._apply_name_case(name_part_raw)
                    queries.append(
                        f"{node_merge}\n"
                        f"SET __cy_n__:Table, __cy_n__.name = '{escape_for_cypher(name_part)}', "
                        f"__cy_n__.schema = '{escape_for_cypher(schema_part)}', __cy_n__.db = '{self.dbms}'\n"
                        f"RETURN __cy_n__"
                    )
                continue
            
            # ì¼ë°˜ DML í…Œì´ë¸” ì²˜ë¦¬
            for entry in tables:
                table_name = (entry.get('table') or '').strip()
                if not table_name:
                    continue
                
                schema_part_raw, name_part_raw, db_link_value = parse_table_identifier(table_name)
                
                # DDL ìºì‹œì—ì„œ ì›ë³¸ ëŒ€ì†Œë¬¸ì ì¡°íšŒ
                # LLMì´ ë°˜í™˜í•œ í…Œì´ë¸”ëª…ì´ DDLì— ì¡´ì¬í•˜ë©´ DDLì˜ ëŒ€ì†Œë¬¸ìë¥¼ ì‚¬ìš©
                # ì´ë ‡ê²Œ í•˜ë©´ DDL í…Œì´ë¸”ê³¼ ë™ì¼í•œ ë…¸ë“œì— ì—…ë°ì´íŠ¸ë¨
                effective_schema = schema_part_raw if schema_part_raw else self.default_schema
                ddl_lookup_key = (effective_schema.lower() if effective_schema else 'public', name_part_raw.lower())
                ddl_meta = self._ddl_table_metadata.get(ddl_lookup_key, {})
                
                # DDL ìºì‹œì—ì„œ ì¡°íšŒ ì„±ê³µ ì—¬ë¶€
                skip_case_conversion = False
                if ddl_meta and ddl_meta.get('original_name'):
                    # DDLì— ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”: DDLì˜ ì›ë³¸ ëŒ€ì†Œë¬¸ì ì‚¬ìš©
                    schema_part = ddl_meta.get('original_schema', self._apply_name_case(effective_schema or 'public'))
                    name_part = ddl_meta.get('original_name')
                    skip_case_conversion = True  # ì´ë¯¸ DDLì—ì„œ ë³€í™˜ëœ ê°’ì´ë¯€ë¡œ ë‹¤ì‹œ ë³€í™˜í•˜ì§€ ì•ŠìŒ
                else:
                    # DDLì— ì—†ëŠ” í…Œì´ë¸”: name_case ë³€í™˜ ì ìš©
                    schema_part = self._apply_name_case(schema_part_raw)
                    name_part = self._apply_name_case(name_part_raw)
                
                access_mode = (entry.get('accessMode') or entry.get('mode') or 'r').lower()
                rel_types = []
                if 'r' in access_mode:
                    rel_types.append(TABLE_RELATIONSHIP_MAP.get('r', 'FROM'))
                if 'w' in access_mode:
                    rel_types.append(TABLE_RELATIONSHIP_MAP.get('w', 'WRITES'))
                
                table_merge = self._build_table_merge(name_part, schema_part, preserve_vars=['__cy_n__'], skip_case_conversion=skip_case_conversion)
                
                table_desc_raw = entry.get('tableDescription') or entry.get('description') or ''
                bucket_key = self._record_table_summary(schema_part, name_part, table_desc_raw, skip_case_conversion=skip_case_conversion)
                
                table_query = f"{node_merge}\nWITH __cy_n__\n{table_merge}\nSET __cy_t__.db = coalesce(__cy_t__.db, '{self.dbms}')"
                
                if db_link_value:
                    table_query += f"\nSET __cy_t__.db_link = COALESCE(__cy_t__.db_link, '{db_link_value}')"
                
                for i, rel_type in enumerate(rel_types):
                    table_query += f"\nMERGE (__cy_n__)-[__cy_r{i}__:{rel_type}]->(__cy_t__)"
                
                table_query += "\nRETURN __cy_n__, __cy_t__"
                queries.append(table_query)
                
                # ì»¬ëŸ¼ ì²˜ë¦¬ (ì»¬ëŸ¼ìš©ì€ preserve_vars=Noneìœ¼ë¡œ ë³„ë„ ìƒì„±)
                table_merge_for_column = self._build_table_merge(name_part, schema_part, preserve_vars=None, skip_case_conversion=skip_case_conversion)
                
                # DDL ì»¬ëŸ¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (ì›ë³¸ ëŒ€ì†Œë¬¸ì ì‚¬ìš©ì„ ìœ„í•´)
                ddl_columns = ddl_meta.get('columns', {}) if ddl_meta else {}
                
                for column in entry.get('columns', []) or []:
                    column_name_raw = (column.get('name') or '').strip()
                    if not column_name_raw:
                        continue
                    
                    # DDL ìºì‹œì—ì„œ ì»¬ëŸ¼ì˜ ì›ë³¸ ëŒ€ì†Œë¬¸ì ì¡°íšŒ
                    # DDL ì»¬ëŸ¼ì€ ì´ë¯¸ name_caseê°€ ì ìš©ëœ ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨
                    ddl_col_meta = ddl_columns.get(column_name_raw.upper() if self.name_case == 'uppercase' else column_name_raw)
                    if ddl_col_meta is None:
                        # ëŒ€ì†Œë¬¸ì ë¬´ê´€í•˜ê²Œ ê²€ìƒ‰
                        for ddl_col_name in ddl_columns.keys():
                            if ddl_col_name.lower() == column_name_raw.lower():
                                column_name = ddl_col_name  # DDLì˜ ì›ë³¸ ëŒ€ì†Œë¬¸ì ì‚¬ìš©
                                break
                        else:
                            column_name = self._apply_name_case(column_name_raw)
                    else:
                        # DDLì—ì„œ ì°¾ì€ ì»¬ëŸ¼ëª… ì‚¬ìš© (ì´ë¯¸ ë³€í™˜ë¨)
                        column_name = column_name_raw.upper() if self.name_case == 'uppercase' else column_name_raw
                    
                    raw_dtype = column.get('dtype') or ''
                    raw_column_desc = (column.get('description') or column.get('comment') or '').strip()
                    
                    self._record_column_summary(
                        bucket_key,
                        column_name,
                        raw_column_desc,
                        dtype=raw_dtype,
                        nullable=column.get('nullable', True),
                        examples=column.get('examples') or [],
                    )
                    
                    col_type = escape_for_cypher(raw_dtype)
                    col_desc = escape_for_cypher(raw_column_desc)
                    nullable = 'true' if column.get('nullable', True) else 'false'
                    escaped_col_name = escape_for_cypher(column_name)
                    
                    # ëŒ€ì†Œë¬¸ì ë³€í™˜ì´ ì´ë¯¸ _build_table_mergeì—ì„œ ì ìš©ë¨
                    converted_name_part = self._apply_name_case(name_part)
                    converted_schema_part = self._apply_name_case(schema_part) if schema_part else None
                    
                    # ì»¬ëŸ¼ëª…ì— íŠ¹ìˆ˜ë¬¸ìê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ëª¨ë‘ ì´ìŠ¤ì¼€ì´í”„
                    escaped_name_part = escape_for_cypher(converted_name_part)
                    escaped_column_name_for_fqn = escape_for_cypher(column_name)
                    
                    if converted_schema_part:
                        escaped_schema_part = escape_for_cypher(converted_schema_part)
                        fqn = escape_for_cypher('.'.join(filter(None, [converted_schema_part, converted_name_part, column_name])).lower())
                        # Column MERGE: fqn ê¸°ì¤€ (ê³ ìœ í‚¤)
                        queries.append(
                            f"{table_merge_for_column}\nWITH __cy_t__\n"
                            f"MERGE (__cy_c__:Column {{fqn: '{fqn}'}})\n"
                            f"SET __cy_c__.name = '{escaped_col_name}', __cy_c__.dtype = '{col_type}', "
                            f"__cy_c__.description = '{col_desc}', __cy_c__.description_source = 'procedure', __cy_c__.nullable = '{nullable}'\n"
                            f"MERGE (__cy_t__)-[__cy_r__:HAS_COLUMN]->(__cy_c__)\n"
                            f"RETURN __cy_t__, __cy_c__, __cy_r__"
                        )
                    else:
                        # schemaê°€ ì—†ëŠ” ê²½ìš° ë™ì  fqn ê³„ì‚° ëŒ€ì‹  ì •ì  fqn ì‚¬ìš©
                        # (CASE WHEN êµ¬ë¬¸ì€ ì»¬ëŸ¼ëª… íŠ¹ìˆ˜ë¬¸ìë¡œ ì¸í•´ êµ¬ë¬¸ ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥)
                        fqn = escape_for_cypher('.'.join(filter(None, [converted_name_part, column_name])).lower())
                        # Column MERGE: fqn ê¸°ì¤€
                        queries.append(
                            f"{table_merge_for_column}\nWITH __cy_t__\n"
                            f"MERGE (__cy_c__:Column {{fqn: '{fqn}'}})\n"
                            f"ON CREATE SET __cy_c__.name = '{escaped_col_name}', __cy_c__.dtype = '{col_type}', "
                            f"__cy_c__.description = '{col_desc}', __cy_c__.description_source = 'procedure', __cy_c__.nullable = '{nullable}'\n"
                            f"MERGE (__cy_t__)-[__cy_r__:HAS_COLUMN]->(__cy_c__)\n"
                            f"RETURN __cy_t__, __cy_c__, __cy_r__"
                        )
            
            # DBLink ì²˜ë¦¬
            for link_item in range_entry.get('dbLinks', []) or []:
                link_name_raw = (link_item.get('name') or '').strip()
                if not link_name_raw:
                    continue
                mode = escape_for_cypher((link_item.get('mode') or 'r').lower())
                schema_link_raw, name_link_raw, link_name = parse_table_identifier(link_name_raw)
                # ëŒ€ì†Œë¬¸ì ë³€í™˜ ì ìš©
                schema_link = self._apply_name_case(schema_link_raw)
                name_link = self._apply_name_case(name_link_raw)
                escaped_link_name = escape_for_cypher(link_name)
                remote_merge = self._build_table_merge(name_link, schema_link)
                queries.append(
                    f"{remote_merge}\nSET __cy_t__.db_link = '{escaped_link_name}'\n"
                    f"WITH __cy_t__\n"
                    f"MERGE (__cy_l__:DBLink {{name: '{escaped_link_name}'}})\n"
                    f"MERGE (__cy_l__)-[__cy_r1__:CONTAINS]->(__cy_t__)\n"
                    f"WITH __cy_t__, __cy_l__\n{node_merge}\n"
                    f"MERGE (__cy_n__)-[__cy_r2__:DB_LINK {{mode: '{mode}'}}]->(__cy_t__)\n"
                    f"RETURN __cy_l__, __cy_t__, __cy_n__"
                )
            
            # FK ê´€ê³„ ì²˜ë¦¬
            fk_relations = range_entry.get('fkRelations', []) or []
            for relation in fk_relations:
                src_table = (relation.get('sourceTable') or '').strip()
                tgt_table = (relation.get('targetTable') or '').strip()
                src_columns = [c.strip() for c in (relation.get('sourceColumns') or []) if c]
                tgt_columns = [c.strip() for c in (relation.get('targetColumns') or []) if c]
                
                if not (src_table and tgt_table and src_columns and tgt_columns):
                    continue
                
                src_schema_raw, src_name_raw, _ = parse_table_identifier(src_table)
                tgt_schema_raw, tgt_name_raw, _ = parse_table_identifier(tgt_table)
                
                # ëŒ€ì†Œë¬¸ì ë³€í™˜ ì ìš©
                src_schema = self._apply_name_case(src_schema_raw)
                src_name = self._apply_name_case(src_name_raw)
                tgt_schema = self._apply_name_case(tgt_schema_raw)
                tgt_name = self._apply_name_case(tgt_name_raw)
                
                # schemaê°€ ì—†ìœ¼ë©´ default_schema ì‚¬ìš© (í…Œì´ë¸” ìƒì„±ê³¼ ì¼ê´€ì„± ìœ ì§€)
                effective_src_schema = src_schema if src_schema else self._apply_name_case(self.default_schema)
                effective_tgt_schema = tgt_schema if tgt_schema else self._apply_name_case(self.default_schema)
                
                src_props = f"schema: '{escape_for_cypher(effective_src_schema)}', name: '{escape_for_cypher(src_name)}', db: '{self.dbms}'"
                tgt_props = f"schema: '{escape_for_cypher(effective_tgt_schema)}', name: '{escape_for_cypher(tgt_name)}', db: '{self.dbms}'"
                
                # ê° FK ë§¤í•‘ë§ˆë‹¤ ë³„ë„ì˜ FK_TO_TABLE ê´€ê³„ ìƒì„±
                # ì†ì„±: sourceColumn, targetColumn, type, source
                # source='procedure': ìŠ¤í† ì–´ë“œ í”„ë¡œì‹œì € ë¶„ì„ì—ì„œ ì¶”ì¶œ (ì ì„  í‘œì‹œ)
                for src_col, tgt_col in zip(src_columns, tgt_columns):
                    # ì»¬ëŸ¼ëª…ì—ë„ ëŒ€ì†Œë¬¸ì ë³€í™˜ ì ìš©
                    escaped_src_col = escape_for_cypher(self._apply_name_case(src_col))
                    escaped_tgt_col = escape_for_cypher(self._apply_name_case(tgt_col))
                    
                    fk_query = (
                        f"MATCH (__cy_st__:Table {{{src_props}}})\n"
                        f"MATCH (__cy_tt__:Table {{{tgt_props}}})\n"
                        f"MERGE (__cy_st__)-[__cy_r__:FK_TO_TABLE {{sourceColumn: '{escaped_src_col}', targetColumn: '{escaped_tgt_col}'}}]->(__cy_tt__)\n"
                        f"ON CREATE SET __cy_r__.type = 'many_to_one', __cy_r__.source = 'procedure'\n"
                        f"RETURN __cy_st__, __cy_tt__, __cy_r__"
                    )
                    queries.append(fk_query)
                
                # Column ê°„ FK_TO ê´€ê³„ë„ ìƒì„±
                # source='procedure': ìŠ¤í† ì–´ë“œ í”„ë¡œì‹œì € ë¶„ì„ì—ì„œ ì¶”ì¶œ (ì ì„  í‘œì‹œ)
                for src_col, tgt_col in zip(src_columns, tgt_columns):
                    # ì»¬ëŸ¼ëª…ì—ë„ ëŒ€ì†Œë¬¸ì ë³€í™˜ ì ìš©
                    converted_src_col = self._apply_name_case(src_col)
                    converted_tgt_col = self._apply_name_case(tgt_col)
                    # fqn ìƒì„± ì‹œì—ë„ effective_schema ì‚¬ìš© (í…Œì´ë¸” ìƒì„±ê³¼ ì¼ê´€ì„± ìœ ì§€)
                    src_fqn = escape_for_cypher('.'.join(filter(None, [effective_src_schema, src_name, converted_src_col])).lower())
                    tgt_fqn = escape_for_cypher('.'.join(filter(None, [effective_tgt_schema, tgt_name, converted_tgt_col])).lower())
                    fk_col_query = (
                        f"MATCH (__cy_sc__:Column {{fqn: '{src_fqn}'}})\n"
                        f"MATCH (__cy_dc__:Column {{fqn: '{tgt_fqn}'}})\n"
                        f"MERGE (__cy_sc__)-[__cy_r__:FK_TO]->(__cy_dc__)\n"
                        f"ON CREATE SET __cy_r__.source = 'procedure'\n"
                        f"RETURN __cy_sc__, __cy_dc__, __cy_r__"
                    )
                    queries.append(fk_col_query)
        
        return queries
    
    def _build_table_merge(self, table_name: str, schema: Optional[str], preserve_vars: Optional[List[str]] = None, skip_case_conversion: bool = False) -> str:
        """í…Œì´ë¸” MERGE ì¿¼ë¦¬ (Schema ë…¸ë“œ ë° BELONGS_TO ê´€ê³„ í¬í•¨)
        
        DDL ì²˜ë¦¬ì™€ ì¼ê´€ì„±ì„ ìœ„í•´ schemaê°€ ì—†ìœ¼ë©´ default_schema ì‚¬ìš©.
        default_schemaë„ ì—†ìœ¼ë©´ 'public' ì‚¬ìš©.
        Schema ë…¸ë“œë¥¼ ë¨¼ì € ìƒì„±í•˜ê³  Tableì´ Schemaì— BELONGS_TO ê´€ê³„ë¡œ ì—°ê²°ë¨.
        
        Args:
            table_name: í…Œì´ë¸” ì´ë¦„
            schema: ìŠ¤í‚¤ë§ˆ ì´ë¦„ (ì—†ìœ¼ë©´ default_schema ì‚¬ìš©)
            preserve_vars: WITH ì ˆì—ì„œ ìœ ì§€í•  ë³€ìˆ˜ ëª©ë¡ (ì˜ˆ: ['__cy_n__'] -> WITH __cy_n__, __cy_s__)
            skip_case_conversion: Trueë©´ ëŒ€ì†Œë¬¸ì ë³€í™˜ì„ ê±´ë„ˆëœ€ (ì´ë¯¸ ë³€í™˜ëœ ê°’ì¸ ê²½ìš°)
        """
        # schemaê°€ ì—†ìœ¼ë©´ default_schema ì‚¬ìš©, default_schemaë„ ì—†ìœ¼ë©´ 'public'
        effective_schema = schema if schema else (self.default_schema if self.default_schema else 'public')
        
        # ëŒ€ì†Œë¬¸ì ë³€í™˜ ì ìš© (skip_case_conversionì´ Falseì¸ ê²½ìš°ì—ë§Œ)
        if not skip_case_conversion:
            effective_schema = self._apply_name_case(effective_schema)
            converted_table_name = self._apply_name_case(table_name)
        else:
            converted_table_name = table_name
        
        schema_value = escape_for_cypher(effective_schema)
        escaped_name = escape_for_cypher(converted_table_name)
        
        # WITH ì ˆ êµ¬ì„±: preserve_varsê°€ ìˆìœ¼ë©´ í•´ë‹¹ ë³€ìˆ˜ë“¤ë„ í•¨ê»˜ ìœ ì§€
        if preserve_vars:
            with_vars = ", ".join(preserve_vars + ["__cy_s__"])
        else:
            with_vars = "__cy_s__"
        
        # Schema MERGE + Table MERGE + BELONGS_TO ê´€ê³„
        # MERGE í‚¤: db, schema, nameë§Œ ì‚¬ìš© (ê°™ì€ ìŠ¤í‚¤ë§ˆ/í…Œì´ë¸”ëª…ì´ë©´ ê°™ì€ ë…¸ë“œ)
        return (
            f"MERGE (__cy_s__:Schema {{db: '{self.dbms}', name: '{schema_value}'}})\n"
            f"WITH {with_vars}\n"
            f"MERGE (__cy_t__:Table {{name: '{escaped_name}', schema: '{schema_value}', db: '{self.dbms}'}})\n"
            f"MERGE (__cy_t__)-[:BELONGS_TO]->(__cy_s__)"
        )

    def _record_table_summary(self, schema: Optional[str], name: str, description: Optional[str], skip_case_conversion: bool = False) -> Tuple[str, str]:
        """í…Œì´ë¸” ì„¤ëª… ëˆ„ì 
        
        í…Œì´ë¸” ìƒì„± ì‹œ _build_table_mergeì—ì„œ default_schemaë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ,
        ì—¬ê¸°ì„œë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬í•˜ì—¬ MATCH ì¿¼ë¦¬ê°€ ì •í™•íˆ ë§¤ì¹­ë˜ë„ë¡ í•¨.
        
        ì¤‘ìš”: _apply_name_caseë¥¼ ì ìš©í•˜ì—¬ Neo4jì— ì €ì¥ëœ í…Œì´ë¸”ëª…ê³¼ ì¼ì¹˜ì‹œì¼œì•¼ í•¨.
        
        Args:
            schema: ìŠ¤í‚¤ë§ˆ ì´ë¦„
            name: í…Œì´ë¸” ì´ë¦„  
            description: í…Œì´ë¸” ì„¤ëª…
            skip_case_conversion: Trueë©´ ëŒ€ì†Œë¬¸ì ë³€í™˜ì„ ê±´ë„ˆëœ€ (DDL ìºì‹œì—ì„œ ì´ë¯¸ ë³€í™˜ëœ ê°’ì¸ ê²½ìš°)
        """
        # í…Œì´ë¸” ìƒì„± ì‹œ schema ì²˜ë¦¬ì™€ ì¼ê´€ì„± ìœ ì§€ (default_schema ì‚¬ìš©)
        effective_schema = schema if schema else (self.default_schema if self.default_schema else 'public')
        
        # ëŒ€ì†Œë¬¸ì ë³€í™˜ ì ìš© (skip_case_conversionì´ Falseì¸ ê²½ìš°ì—ë§Œ)
        if skip_case_conversion:
            schema_key = effective_schema
            name_key = name
        else:
            schema_key = self._apply_name_case(effective_schema)
            name_key = self._apply_name_case(name)
        
        bucket = self._table_summary_store.get((schema_key, name_key))
        if bucket is None:
            bucket = {"summaries": set(), "columns": {}}
            self._table_summary_store[(schema_key, name_key)] = bucket
        text = (description or '').strip()
        if text:
            bucket["summaries"].add(text)
        return (schema_key, name_key)
    
    def _record_column_summary(
        self,
        table_key: Tuple[str, str],
        column_name: str,
        description: Optional[str],
        dtype: Optional[str] = None,
        nullable: Optional[bool] = None,
        examples: Optional[List[str]] = None,
    ):
        """ì»¬ëŸ¼ ì„¤ëª… ëˆ„ì 
        
        ì¤‘ìš”: ì»¬ëŸ¼ëª…ì— _apply_name_caseë¥¼ ì ìš©í•˜ì—¬ Neo4jì— ì €ì¥ëœ ì»¬ëŸ¼ëª…ê³¼ ì¼ì¹˜ì‹œì¼œì•¼ í•¨.
        """
        text = (description or '').strip()
        bucket = self._table_summary_store.setdefault(table_key, {"summaries": set(), "columns": {}})
        columns = bucket["columns"]
        # ëŒ€ì†Œë¬¸ì ë³€í™˜ ì ìš© (DDL ì²˜ë¦¬ì™€ ë™ì¼í•˜ê²Œ)
        canonical = self._apply_name_case(column_name)
        entry = columns.get(canonical)
        if entry is None:
            entry = {"name": canonical, "summaries": set(), "dtype": (dtype or ''), "nullable": True if nullable is None else bool(nullable), "examples": set()}
            columns[canonical] = entry
        if dtype is not None and not entry.get("dtype"):
            entry["dtype"] = dtype
        if nullable is not None:
            entry["nullable"] = bool(nullable)
        if text:
            entry["summaries"].add(text)
        if examples:
            for v in examples:
                if v is not None:
                    s = str(v).strip()
                    if s:
                        entry["examples"].add(s)
    
    async def _finalize_table_summaries(self) -> List[str]:
        """í…Œì´ë¸”/ì»¬ëŸ¼ ì„¤ëª… ìš”ì•½"""
        log_process("ANALYZE", "TABLE_SUMMARY", f"ğŸ“Š í…Œì´ë¸” ìš”ì•½ ì‹œì‘: {len(self._table_summary_store)}ê°œ í…Œì´ë¸”")
        if not self._table_summary_store:
            log_process("ANALYZE", "TABLE_SUMMARY", "âš ï¸ í…Œì´ë¸” ìš”ì•½ ëŒ€ìƒ ì—†ìŒ (store ë¹„ì–´ìˆìŒ)")
            return []
        
        tasks = [
            self._summarize_table(table_key, data)
            for table_key, data in list(self._table_summary_store.items())
        ]
        if not tasks:
            return []
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        all_queries: List[str] = []
        for result in results:
            if isinstance(result, Exception):
                log_process("ANALYZE", "TABLE_SUMMARY", f"âŒ í…Œì´ë¸” ìš”ì•½ ì˜¤ë¥˜: {result}", logging.ERROR)
            elif result:
                all_queries.extend(result)
        
        self._table_summary_store.clear()
        return all_queries
    
    async def _summarize_table(self, table_key: Tuple[str, str], data: Dict[str, Any]) -> List[str]:
        """í…Œì´ë¸” ìš”ì•½ ì²˜ë¦¬"""
        schema_key, name_key = table_key
        
        ddl_key = (schema_key.lower(), name_key.lower())
        ddl_meta = self._ddl_table_metadata.get(ddl_key, {})
        ddl_description = (ddl_meta.get('description') or '').strip()
        ddl_columns = ddl_meta.get('columns') or {}
        
        summaries = list(data.get('summaries') or [])
        columns_map = data.get('columns') or {}
        column_sentences = {
            entry['name']: list(entry['summaries'])
            for entry in columns_map.values()
            if entry.get('summaries')
        }
        
        if ddl_description:
            summaries.insert(0, f"[DDL ë©”íƒ€ë°ì´í„°] {ddl_description}")
        
        for col_name, ddl_col in ddl_columns.items():
            ddl_col_desc = (ddl_col.get('description') or '').strip()
            if ddl_col_desc and col_name not in column_sentences:
                column_sentences[col_name] = [f"[DDL ë©”íƒ€ë°ì´í„°] {ddl_col_desc}"]
            elif ddl_col_desc and col_name in column_sentences:
                column_sentences[col_name].insert(0, f"[DDL ë©”íƒ€ë°ì´í„°] {ddl_col_desc}")
        
        if not summaries and not column_sentences:
            return []
        
        table_display = f"{schema_key}.{name_key}" if schema_key else name_key
        column_metadata = {}
        for entry in columns_map.values():
            col_name = entry['name']
            ddl_col = ddl_columns.get(col_name, {})
            column_metadata[col_name] = {
                "dtype": entry.get("dtype") or ddl_col.get("dtype") or "",
                "nullable": bool(entry.get("nullable", True)) if entry.get("nullable") is not None else ddl_col.get("nullable", True),
                "examples": sorted(list(entry.get("examples") or []))[:5],
            }
        
        for col_name, ddl_col in ddl_columns.items():
            if col_name not in column_metadata:
                column_metadata[col_name] = {
                    "dtype": ddl_col.get("dtype") or "",
                    "nullable": ddl_col.get("nullable", True),
                    "examples": [],
                }
        
        result = await asyncio.to_thread(
            summarize_table_metadata,
            table_display,
            summaries,
            column_sentences,
            column_metadata,
            self.api_key,
            self.locale,
        )
        
        if not isinstance(result, dict):
            raise RuntimeError(f"í…Œì´ë¸” ìš”ì•½ ê²°ê³¼ê°€ dictê°€ ì•„ë‹˜ ({schema_key}.{name_key}): {type(result).__name__}")
        
        queries: List[str] = []
        llm_table_desc = (result.get('tableDescription') or '').strip()
        escaped_schema = escape_for_cypher(schema_key)
        escaped_name = escape_for_cypher(name_key)
        # MATCH ì¡°ê±´: db, schema, nameë§Œ ì‚¬ìš© (ìŠ¤í‚¤ë§ˆ/í…Œì´ë¸”ëª…ì´ ê°™ìœ¼ë©´ ê°™ì€ ë…¸ë“œë¡œ ì·¨ê¸‰)
        table_props = (
            f"schema: '{escaped_schema}', name: '{escaped_name}', db: '{self.dbms}'"
        )
        
        if llm_table_desc:
            escaped_llm_table_desc = escape_for_cypher(llm_table_desc)
            # í”„ë¡œì‹œì € ë¶„ì„ ê²°ê³¼ëŠ” analyzed_descriptionì— í•­ìƒ ì €ì¥
            # ê¸°ì¡´ descriptionì´ ë¹„ì–´ìˆì„ ë•Œë§Œ descriptionì—ë„ ì €ì¥ + description_source='procedure' ì„¤ì •
            # description_sourceëŠ” descriptionì´ ë¹„ì–´ìˆì„ ë•Œë§Œ 'procedure'ë¡œ ì„¤ì •
            queries.append(
                f"MATCH (__cy_t__:Table {{{table_props}}})\n"
                f"SET __cy_t__.analyzed_description = '{escaped_llm_table_desc}'\n"
                f"WITH __cy_t__\n"
                f"WHERE __cy_t__.description IS NULL OR __cy_t__.description = ''\n"
                f"SET __cy_t__.description = '{escaped_llm_table_desc}', __cy_t__.description_source = 'procedure'\n"
                f"RETURN __cy_t__"
            )
        
        for column_info in result.get('columns', []) or []:
            column_name = (column_info.get('name') or '').strip()
            llm_column_desc = (column_info.get('description') or '').strip()
            if not column_name or not llm_column_desc:
                continue
            
            # fqnê³¼ column_name ëª¨ë‘ ì´ìŠ¤ì¼€ì´í”„ í•„ìš” (íŠ¹ìˆ˜ë¬¸ì í¬í•¨ ê°€ëŠ¥)
            escaped_column_name = escape_for_cypher(column_name)
            fqn = '.'.join(filter(None, [schema_key, name_key, column_name])).lower()
            escaped_fqn = escape_for_cypher(fqn)
            # MATCH ì¡°ê±´: fqn ê¸°ì¤€
            column_props = f"fqn: '{escaped_fqn}'"
            escaped_llm_column_desc = escape_for_cypher(llm_column_desc)
            # í”„ë¡œì‹œì € ë¶„ì„ ê²°ê³¼ëŠ” analyzed_descriptionì— í•­ìƒ ì €ì¥
            # ê¸°ì¡´ descriptionì´ ë¹„ì–´ìˆì„ ë•Œë§Œ descriptionì—ë„ ì €ì¥ + description_source='procedure' ì„¤ì •
            queries.append(
                f"MATCH (__cy_c__:Column {{{column_props}}})\n"
                f"SET __cy_c__.analyzed_description = '{escaped_llm_column_desc}'\n"
                f"WITH __cy_c__\n"
                f"WHERE __cy_c__.description IS NULL OR __cy_c__.description = ''\n"
                f"SET __cy_c__.description = '{escaped_llm_column_desc}', __cy_c__.description_source = 'procedure'\n"
                f"RETURN __cy_c__"
            )
        
        return queries
