"""Java/Framework Understanding íŒŒì´í”„ë¼ì¸ êµ¬í˜„.

ì´ ëª¨ë“ˆì€ Java ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±ì— í•„ìš”í•œ ì •ë³´ë¥¼
Neo4j ê·¸ë˜í”„ë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤. DBMS ë¶„ì„ íŒŒì´í”„ë¼ì¸ê³¼ ë™ì¼í•œ êµ¬ì¡°ë¥¼ ë”°ë¦…ë‹ˆë‹¤.

ì£¼ìš” íë¦„:
1. AST ìˆ˜ì§‘ (StatementCollector)
2. ì •ì  ê·¸ë˜í”„ ì´ˆê¸°í™”
3. ì„ í–‰ ì²˜ë¦¬ (ë³‘ë ¬):
   - ìƒì†/êµ¬í˜„ ê´€ê³„ ì¶”ì¶œ (EXTENDS, IMPLEMENTS ë…¸ë“œ)
   - í•„ë“œ ì •ë³´ ì¶”ì¶œ (FIELD ë…¸ë“œ)
4. ë°°ì¹˜ ë¶„ì„ (LLM í˜¸ì¶œ)
5. í´ë˜ìŠ¤ ìš”ì•½ ìƒì„±
"""

from __future__ import annotations

import asyncio
import json
import logging
import os
import re
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

from util.rule_loader import RuleLoader
from util.exception import LLMCallError, ProcessAnalyzeCodeError, AnalysisError
from util.utility_tool import calculate_code_token, escape_for_cypher, log_process


# ==================== ìƒìˆ˜ ì •ì˜ ====================
NON_ANALYSIS_TYPES = frozenset(["FILE", "PACKAGE", "IMPORT"])
CLASS_TYPES = frozenset(["CLASS", "INTERFACE", "ENUM"])
INHERITANCE_TYPES = frozenset(["EXTENDS", "IMPLEMENTS"])
FIELD_TYPES = frozenset(["FIELD"])
METHOD_TYPES = frozenset(["METHOD", "CONSTRUCTOR"])
METHOD_SIGNATURE_TYPES = frozenset(["METHOD_SIGNATURE"])
# METHOD_CALL íƒ€ì… ë…¸ë“œ - CALLS ê´€ê³„ ìƒì„±ì„ ìœ„í•´ ë³„ë„ ì²˜ë¦¬
METHOD_CALL_TYPES = frozenset(["METHOD_CALL", "METHOD_INVOCATION", "CALL"])
MAX_BATCH_TOKEN = int(os.getenv("FRAMEWORK_MAX_BATCH_TOKEN", "1000"))
MAX_CONCURRENCY = int(os.getenv("FRAMEWORK_MAX_CONCURRENCY", "5"))
INHERITANCE_CONCURRENCY = int(os.getenv("INHERITANCE_CONCURRENCY", "5"))
FIELD_CONCURRENCY = int(os.getenv("FIELD_CONCURRENCY", "5"))
METHOD_CONCURRENCY = int(os.getenv("METHOD_CONCURRENCY", "5"))
STATIC_QUERY_BATCH_SIZE = 40
LINE_NUMBER_PATTERN = re.compile(r"^(\d+)\s*:")
# ë©”ì„œë“œ í˜¸ì¶œ íŒ¨í„´: ì‹ë³„ì.ë©”ì„œë“œëª…( í˜•íƒœ (ASSIGNMENT, VARIABLE ë“±ì—ì„œ í˜¸ì¶œ ê°ì§€ìš©)
METHOD_CALL_PATTERN = re.compile(r'\w+\.\w+\s*\(')
# ëŒ€ìš©ëŸ‰ summary ì²­í¬ ë¶„í•  ì„¤ì • (summary ê°œìˆ˜ ê¸°ì¤€)
MAX_SUMMARY_CHUNK_SIZE = int(os.getenv('MAX_SUMMARY_CHUNK_SIZE', '50'))

# Java í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ê¸°ë³¸ íƒ€ì… - í´ë˜ìŠ¤ ìƒì„± ì œì™¸ ëŒ€ìƒ
JAVA_BUILTIN_TYPES = frozenset([
    # ê¸°ë³¸ íƒ€ì… ë° ë˜í¼
    "int", "long", "double", "float", "boolean", "char", "byte", "short", "void",
    "Integer", "Long", "Double", "Float", "Boolean", "Character", "Byte", "Short",
    # ê¸°ë³¸ í´ë˜ìŠ¤
    "String", "Object", "Class", "Enum", "System", "Math", "Runtime",
    # ì»¬ë ‰ì…˜
    "List", "ArrayList", "LinkedList", "Set", "HashSet", "TreeSet", "LinkedHashSet",
    "Map", "HashMap", "TreeMap", "LinkedHashMap", "ConcurrentHashMap",
    "Collection", "Collections", "Arrays", "Iterator", "Iterable",
    "Queue", "Deque", "Stack", "Vector", "PriorityQueue",
    # ìœ í‹¸ë¦¬í‹°
    "Optional", "Stream", "Collectors", "Comparator", "Comparable",
    "Date", "Calendar", "LocalDate", "LocalTime", "LocalDateTime", "Instant",
    "UUID", "Random", "Scanner", "Pattern", "Matcher",
    # ì˜ˆì™¸
    "Exception", "RuntimeException", "Throwable", "Error",
    "IOException", "SQLException", "NullPointerException", "IllegalArgumentException",
    # I/O
    "File", "Path", "Files", "InputStream", "OutputStream", "Reader", "Writer",
    "BufferedReader", "BufferedWriter", "PrintWriter", "FileReader", "FileWriter",
    # ê¸°íƒ€
    "StringBuilder", "StringBuffer", "BigDecimal", "BigInteger",
    "Logger", "Log", "LogFactory",
])

# ìœ í‹¸ë¦¬í‹°/í—¬í¼ í´ë˜ìŠ¤ íŒ¨í„´ - CALLS ê´€ê³„ ìƒì„± ì œì™¸ ëŒ€ìƒ
# (í”„ë¡œì íŠ¸ì— ì¡´ì¬í•˜ë”ë¼ë„ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê´€ì ì—ì„œ ì¤‘ìš”í•˜ì§€ ì•Šì€ í´ë˜ìŠ¤)
UTILITY_CLASS_PATTERNS = frozenset([
    "Debug", "Logger", "Log", "LogFactory", "LogManager",
    "Utils", "Utility", "Utilities", "Helper", "Helpers",
    "Constants", "Config", "Configuration", "Settings",
    "Validator", "Validation", "Formatter", "Converter",
    "StringUtils", "DateUtils", "NumberUtils", "CollectionUtils",
    "Assert", "Assertions", "Preconditions", "Check",
])

# Collection/Map íƒ€ì… í”„ë¦¬í”½ìŠ¤ - í•„ë“œ íƒ€ì… ê¸°ë°˜ method_call í•„í„°ë§ìš©
COLLECTION_TYPE_PREFIXES = (
    # Map ê³„ì—´
    "Map<", "HashMap<", "LinkedHashMap<", "TreeMap<", "ConcurrentHashMap<",
    "Hashtable<", "WeakHashMap<", "IdentityHashMap<", "EnumMap<",
    # List ê³„ì—´
    "List<", "ArrayList<", "LinkedList<", "CopyOnWriteArrayList<", "Vector<",
    # Set ê³„ì—´
    "Set<", "HashSet<", "TreeSet<", "LinkedHashSet<", "EnumSet<",
    "ConcurrentSkipListSet<", "CopyOnWriteArraySet<",
    # ê¸°íƒ€ Collection ê³„ì—´
    "Collection<", "Queue<", "Deque<", "Stack<", "PriorityQueue<",
    "ArrayDeque<", "ConcurrentLinkedQueue<", "BlockingQueue<",
)


# ==================== ë°ì´í„° í´ë˜ìŠ¤ ====================
@dataclass(slots=True)
class StatementNode:
    """í‰íƒ„í™”ëœ AST ë…¸ë“œë¥¼ í‘œí˜„í•©ë‹ˆë‹¤."""
    node_id: int
    start_line: int
    end_line: int
    node_type: str
    code: str
    token: int
    has_children: bool
    analyzable: bool
    class_key: Optional[str]
    class_name: Optional[str]
    class_kind: Optional[str]
    lines: List[Tuple[int, str]] = field(default_factory=list)
    parent: Optional["StatementNode"] = None
    children: List["StatementNode"] = field(default_factory=list)
    summary: Optional[str] = None
    completion_event: asyncio.Event = field(init=False, repr=False)

    def __post_init__(self):
        object.__setattr__(self, "completion_event", asyncio.Event())

    def get_raw_code(self) -> str:
        """ë¼ì¸ ë²ˆí˜¸ë¥¼ í¬í•¨í•˜ì—¬ ë…¸ë“œì˜ ì›ë¬¸ ì½”ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return "\n".join(f"{ln}: {text}" for ln, text in self.lines)

    def get_compact_code(self) -> str:
        """ìì‹ êµ¬ê°„ì€ ìì‹ ìš”ì•½(ì—†ìœ¼ë©´ placeholder)ìœ¼ë¡œ ì¹˜í™˜í•œ ì½”ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        DBMS ë°©ì‹ì²˜ëŸ¼ ë‹¨ìˆœ ìˆœíšŒë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        if not self.children:
            return self.get_raw_code()

        result_lines: List[str] = []
        line_index = 0
        total_lines = len(self.lines)
        sorted_children = sorted(self.children, key=lambda child: child.start_line)

        for child in sorted_children:
            # ìì‹ ì´ì „ì˜ ë¶€ëª¨ ê³ ìœ  ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬í•©ë‹ˆë‹¤.
            while line_index < total_lines and self.lines[line_index][0] < child.start_line:
                line_no, text = self.lines[line_index]
                result_lines.append(f"{line_no}: {text}")
                line_index += 1

            # ìì‹ êµ¬ê°„ì€ ìì‹ ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤ (ì—†ìœ¼ë©´ placeholder).
            if child.summary:
                child_summary = child.summary.strip()
                summary_line = f"{child.start_line}~{child.end_line}: {child_summary}"
            else:
                summary_line = f"{child.start_line}: ...code..."

            result_lines.append(summary_line)

            # ìì‹ êµ¬ê°„ ì›ë³¸ ì½”ë“œëŠ” ê±´ë„ˆëœë‹ˆë‹¤.
            while line_index < total_lines and self.lines[line_index][0] <= child.end_line:
                line_index += 1

        # ë§ˆì§€ë§‰ ìì‹ ì´í›„ ë¶€ëª¨ ì½”ë“œê°€ ë‚¨ì•„ ìˆë‹¤ë©´ ì¶”ê°€í•©ë‹ˆë‹¤.
        while line_index < total_lines:
            line_no, text = self.lines[line_index]
            result_lines.append(f"{line_no}: {text}")
            line_index += 1

        return "\n".join(result_lines)

    def get_placeholder_code(self, include_assigns: bool = False) -> str:
        """ìì‹ êµ¬ê°„ì„ placeholder(...code...)ë¡œ ì¹˜í™˜í•œ ì½”ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        ê¸°ë³¸ ë™ì‘:
        - ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜, ìƒì†, êµ¬í˜„ ê´€ê³„ëŠ” ì›ë¬¸ ìœ ì§€
        - ë‚˜ë¨¸ì§€ ëª¨ë“  ìì‹ì€ ...code...ë¡œ ì¹˜í™˜
        
        Args:
            include_assigns: Trueì´ë©´ ASSIGNMENT/NEW_INSTANCE ë…¸ë“œë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì°¾ì•„ì„œ ì›ë¬¸ ìœ ì§€
                            (ifë¬¸, forë¬¸ ë“±ì€ ì œê±°ë˜ê³  ASSIGN/NEW_INSTANCEë§Œ ë‚¨ìŒ)
        """
        if not self.children:
            return self.get_raw_code()
        
        # í•­ìƒ ì›ë¬¸ ìœ ì§€í•  ë…¸ë“œ íƒ€ì…: ìƒì†/êµ¬í˜„ ê´€ê³„, ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜
        PRESERVE_TYPES = INHERITANCE_TYPES | METHOD_TYPES | METHOD_SIGNATURE_TYPES
        
        # include_assigns=Trueì´ë©´ ASSIGNMENT/NEW_INSTANCEë¥¼ ì¬ê·€ì ìœ¼ë¡œ ìˆ˜ì§‘
        assign_node_set: set[Tuple[int, int]] = set()
        if include_assigns:
            ASSIGN_TYPES = {"ASSIGNMENT", "NEW_INSTANCE"}
            
            def find_assign_nodes_recursive(node: "StatementNode") -> List["StatementNode"]:
                """ì¬ê·€ì ìœ¼ë¡œ ASSIGNMENT, NEW_INSTANCE ë…¸ë“œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
                results = []
                for child in node.children:
                    if child.node_type in ASSIGN_TYPES:
                        results.append(child)
                    # ìì‹ì˜ ìì‹ë„ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰
                    results.extend(find_assign_nodes_recursive(child))
                return results
            
            assign_nodes = find_assign_nodes_recursive(self)
            assign_node_set = {(n.start_line, n.end_line) for n in assign_nodes}
        
        result_lines: List[str] = []
        line_index = 0
        total_lines = len(self.lines)
        sorted_children = sorted(self.children, key=lambda child: child.start_line)
        
        for child in sorted_children:
            # ìì‹ ì´ì „ì˜ ë¶€ëª¨ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ì¶œë ¥
            while line_index < total_lines and self.lines[line_index][0] < child.start_line:
                line_no, text = self.lines[line_index]
                result_lines.append(f"{line_no}: {text}")
                line_index += 1
            
            # ì›ë¬¸ ìœ ì§€í•  ë…¸ë“œ: ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜, ìƒì†/êµ¬í˜„, ë˜ëŠ” ASSIGNMENT/NEW_INSTANCE
            child_span = (child.start_line, child.end_line)
            should_preserve = (
                child.node_type in PRESERVE_TYPES or 
                (include_assigns and child_span in assign_node_set)
            )
            
            if should_preserve:
                # ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¶œë ¥
                while line_index < total_lines and self.lines[line_index][0] <= child.end_line:
                    line_no, text = self.lines[line_index]
                    result_lines.append(f"{line_no}: {text}")
                    line_index += 1
            else:
                # ë‚˜ë¨¸ì§€ ìì‹ì€ ...code...ë¡œ ì¹˜í™˜
                result_lines.append(f"{child.start_line}: ...code...")
                while line_index < total_lines and self.lines[line_index][0] <= child.end_line:
                    line_index += 1
        
        # ë§ˆì§€ë§‰ ìì‹ ì´í›„ ë¶€ëª¨ ì½”ë“œê°€ ë‚¨ì•„ ìˆë‹¤ë©´ ì¶”ê°€
        while line_index < total_lines:
            line_no, text = self.lines[line_index]
            result_lines.append(f"{line_no}: {text}")
            line_index += 1
        
        return "\n".join(result_lines)

    def get_code_with_assigns_only(self) -> str:
        """ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ + ASSIGNMENT/NEW_INSTANCE ìì‹ë§Œ í¬í•¨ëœ ì½”ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        get_placeholder_code(include_assigns=True)ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
        """
        return self.get_placeholder_code(include_assigns=True)


@dataclass(slots=True)
class ClassInfo:
    """í´ë˜ìŠ¤/ì¸í„°í˜ì´ìŠ¤ ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    key: str
    name: str
    kind: str
    node_start: int
    node_end: int
    pending_nodes: int = 0
    finalized: bool = False


@dataclass(slots=True)
class AnalysisBatch:
    """ë¶„ì„ ë°°ì¹˜ ì •ë³´."""
    batch_id: int
    nodes: List[StatementNode]
    ranges: List[Dict[str, int]]
    method_call_ranges: List[Dict[str, Any]]  # METHOD_CALL ë…¸ë“œ ë²”ìœ„
    progress_line: int

    def build_general_payload(self) -> str:
        """ì¼ë°˜ LLM í˜¸ì¶œìš© ì½”ë“œ í˜ì´ë¡œë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (DBMS ìŠ¤íƒ€ì¼ê³¼ ë™ì¼)."""
        return "\n\n".join(
            node.get_compact_code() if node.has_children else node.get_raw_code()
            for node in self.nodes
        )

    def build_method_call_payload(self) -> Optional[str]:
        """ë©”ì„œë“œ í˜¸ì¶œì„ í¬í•¨í•˜ëŠ” ë…¸ë“œë¥¼ ì¶”ì¶œí•˜ì—¬ í˜¸ì¶œ ë¶„ì„ í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬.
        
        METHOD_CALL íƒ€ì…ë¿ ì•„ë‹ˆë¼ ASSIGNMENT, VARIABLE ë“± ë©”ì„œë“œ í˜¸ì¶œ íŒ¨í„´ì„ í¬í•¨í•˜ëŠ” ë…¸ë“œë„ í¬í•¨.
        """
        method_call_nodes = [
            node for node in self.nodes 
            if node.node_type in METHOD_CALL_TYPES or METHOD_CALL_PATTERN.search(node.code)
        ]
        if not method_call_nodes:
            return None
        return "\n\n".join(
            node.get_raw_code() for node in method_call_nodes
        )

    def get_parent_code(self) -> str:
        """ë°°ì¹˜ ë…¸ë“œë“¤ì˜ ë¶€ëª¨ ì½”ë“œë¥¼ ê°€ì ¸ì˜´ (ì»¨í…ìŠ¤íŠ¸ìš©)."""
        if not self.nodes:
            return ""
        # ì²« ë²ˆì§¸ ë…¸ë“œì˜ ë¶€ëª¨ ì½”ë“œ ì‚¬ìš©
        first_node = self.nodes[0]
        if first_node.parent:
            # ì»¨í…ìŠ¤íŠ¸(parent_code)ëŠ” ìš”ì•½ ì¹˜í™˜ê³¼ ë³„ê°œë¡œ, í•­ìƒ placeholder ìŠ¤ì¼ˆë ˆí†¤ë§Œ ì „ë‹¬
            return (
                first_node.parent.get_placeholder_code()
                if first_node.parent.has_children
                else first_node.parent.get_raw_code()
            )
        return ""


@dataclass(slots=True)
class BatchResult:
    """ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼."""
    batch: AnalysisBatch
    general_result: Optional[Dict[str, Any]]
    method_call_result: Optional[Dict[str, Any]] = None  # METHOD_CALL ë¶„ì„ ê²°ê³¼


# ==================== í—¬í¼ í•¨ìˆ˜ ====================
def _is_valid_class_name_for_calls(name: str) -> bool:
    """calls ê´€ê³„ ìƒì„±ì— ìœ íš¨í•œ í´ë˜ìŠ¤ëª…ì¸ì§€ ê²€ì¦.
    
    ê°€ì§œ í´ë˜ìŠ¤ ìƒì„±ì„ ë°©ì§€í•˜ê¸° ìœ„í•´:
    - Java í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œì™¸
    - ìœ í‹¸ë¦¬í‹°/í—¬í¼ í´ë˜ìŠ¤ ì œì™¸ (Debug, Logger, Utils ë“±)
    - ì†Œë¬¸ìë§Œìœ¼ë¡œ ëœ ì§§ì€ ì´ë¦„(ë³€ìˆ˜ëª…ìœ¼ë¡œ ë³´ì´ëŠ” ê²ƒ) ì œì™¸
    - í•œ ê¸€ì ì´ë¦„ ì œì™¸
    """
    if not name:
        return False
    
    # Java í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œì™¸
    if name in JAVA_BUILTIN_TYPES:
        return False
    
    # ìœ í‹¸ë¦¬í‹°/í—¬í¼ í´ë˜ìŠ¤ ì œì™¸ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê´€ì ì—ì„œ ì¤‘ìš”í•˜ì§€ ì•ŠìŒ)
    if name in UTILITY_CLASS_PATTERNS:
        return False
    
    # í•œ ê¸€ì ì´ë¦„ ì œì™¸ (i, j, k, o, e ë“± ë°˜ë³µ ë³€ìˆ˜)
    if len(name) == 1:
        return False
    
    # ì†Œë¬¸ìë¡œë§Œ ì‹œì‘í•˜ê³  3ê¸€ì ì´í•˜ì¸ ê²ƒ ì œì™¸ (ë³€ìˆ˜ëª…ìœ¼ë¡œ ë³´ì„)
    if name[0].islower() and len(name) <= 3:
        return False
    
    # ëª¨ë‘ ì†Œë¬¸ìì¸ ì§§ì€ ì´ë¦„ ì œì™¸ (item, items, list, map ë“±)
    if name.islower() and len(name) <= 6:
        return False
    
    return True


# ==================== RuleLoader í—¬í¼ ====================
def _rule_loader() -> RuleLoader:
    return RuleLoader(target_lang="framework", domain="understand")


def understand_code(code: str, ranges: list, count: int, api_key: str, locale: str, parent_code: str = "") -> Dict[str, Any]:
    """ì½”ë“œ ë²”ìœ„ë³„ ë¶„ì„ - summary, calls, variables ì¶”ì¶œ."""
    return _rule_loader().execute(
        "analysis",
        {"code": code, "ranges": ranges, "count": count, "locale": locale, "parent_code": parent_code},
        api_key,
    )


def understand_class_summary(summaries: dict, api_key: str, locale: str, previous_summary: str = "", previous_user_stories: list = None) -> Dict[str, Any]:
    """í´ë˜ìŠ¤ ì „ì²´ ìš”ì•½ + User Story + AC ìƒì„±.
    
    Args:
        summaries: ë©¤ë²„ ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        api_key: LLM API í‚¤
        locale: ì¶œë ¥ ì–¸ì–´
        previous_summary: ì´ì „ ì²­í¬ì˜ ìš”ì•½ ê²°ê³¼ (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œ)
        previous_user_stories: ì´ì „ ì²­í¬ì˜ User Story ë¦¬ìŠ¤íŠ¸ (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œ, ì¤‘ë³µ ë°©ì§€ìš©)
    """
    return _rule_loader().execute(
        "class_summary",
        {
            "summaries": summaries, 
            "locale": locale, 
            "previous_summary": previous_summary,
            "previous_user_stories": previous_user_stories or []
        },
        api_key,
    )


def understand_inheritance(declaration_code: str, api_key: str, locale: str) -> Dict[str, Any]:
    """ìƒì†/êµ¬í˜„ ê´€ê³„ ì¶”ì¶œ."""
    return _rule_loader().execute(
        "inheritance",
        {"declaration_code": declaration_code, "locale": locale},
        api_key,
    )


def understand_field(declaration_code: str, api_key: str, locale: str) -> Dict[str, Any]:
    """í•„ë“œ ì •ë³´ ì¶”ì¶œ."""
    return _rule_loader().execute(
        "field",
        {"declaration_code": declaration_code, "locale": locale},
        api_key,
    )


def understand_method(declaration_code: str, api_key: str, locale: str) -> Dict[str, Any]:
    """ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ ë¶„ì„ - íŒŒë¼ë¯¸í„°/ë°˜í™˜ íƒ€ì… ì¶”ì¶œ."""
    return _rule_loader().execute(
        "method",
        {"declaration_code": declaration_code, "locale": locale},
        api_key,
    )


def understand_method_call(code: str, ranges: list, api_key: str, locale: str) -> Dict[str, Any]:
    """METHOD_CALL ë…¸ë“œ ë¶„ì„ - í´ë˜ìŠ¤ í•„ë“œ ê°ì²´ì˜ ë©”ì„œë“œ í˜¸ì¶œë§Œ ì‹ë³„."""
    return _rule_loader().execute(
        "method_call",
        {"code": code, "ranges": ranges, "locale": locale},
        api_key,
    )


# ==================== ë…¸ë“œ ìˆ˜ì§‘ê¸° ====================
class StatementCollector:
    """ASTë¥¼ í›„ìœ„ìˆœíšŒí•˜ì—¬ StatementNodeì™€ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""

    def __init__(self, antlr_data: Dict[str, Any], file_content: str, directory: str, file_name: str):
        self.antlr_data = antlr_data
        self.file_content = file_content
        self.directory = directory
        self.file_name = file_name
        self.nodes: List[StatementNode] = []
        self.classes: Dict[str, ClassInfo] = {}
        self._node_id = 0
        self._file_lines = file_content.split("\n")

    def collect(self) -> Tuple[List[StatementNode], Dict[str, ClassInfo]]:
        """AST ì „ì—­ì„ í›„ìœ„ ìˆœíšŒí•˜ì—¬ ë…¸ë“œ ëª©ë¡ê³¼ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        self._visit(self.antlr_data, None, None, None, None)
        return self.nodes, self.classes

    def _make_class_key(self, class_name: Optional[str], start_line: int) -> str:
        """í´ë˜ìŠ¤ ê³ ìœ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        base = class_name or f"anonymous_{start_line}"
        return f"{self.directory}:{self.file_name}:{base}:{start_line}"

    def _extract_class_name(self, code: str, node_type: str) -> Optional[str]:
        """ì½”ë“œì—ì„œ í´ë˜ìŠ¤/ì¸í„°í˜ì´ìŠ¤ ì´ë¦„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        patterns = {
            "CLASS": r"\bclass\s+(\w+)",
            "INTERFACE": r"\binterface\s+(\w+)",
            "ENUM": r"\benum\s+(\w+)",
            "RECORD": r"\brecord\s+(\w+)",
            "ANNOTATION_TYPE": r"@interface\s+(\w+)",
        }
        pattern = patterns.get(node_type)
        if pattern:
            match = re.search(pattern, code, re.IGNORECASE)
            if match:
                return match.group(1)
        return None

    def _visit(
        self,
        node: Dict[str, Any],
        parent: Optional[StatementNode],
        current_class: Optional[str],
        current_class_name: Optional[str],
        current_class_kind: Optional[str],
    ) -> Optional[StatementNode]:
        """ì¬ê·€ì ìœ¼ë¡œ ASTë¥¼ ë‚´ë ¤ê°€ë©° StatementNodeë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        node_type = node["type"]
        start_line = node["startLine"]
        end_line = node["endLine"]
        children = node.get("children", []) or []

        # ì½”ë“œ ì¶”ì¶œ
        line_entries = [
            (ln, self._file_lines[ln - 1] if 0 < ln <= len(self._file_lines) else "")
            for ln in range(start_line, end_line + 1)
        ]
        code = "\n".join(f"{ln}: {txt}" for ln, txt in line_entries)

        class_key = current_class
        class_name = current_class_name
        class_kind = current_class_kind

        # í´ë˜ìŠ¤/ì¸í„°í˜ì´ìŠ¤ ë…¸ë“œ ì²˜ë¦¬
        if node_type in CLASS_TYPES:
            extracted_name = self._extract_class_name(code, node_type)
            class_key = self._make_class_key(extracted_name, start_line)
            class_name = extracted_name
            class_kind = node_type
            if class_key not in self.classes:
                self.classes[class_key] = ClassInfo(
                    key=class_key,
                    name=extracted_name or class_key,
                    kind=node_type,
                    node_start=start_line,
                    node_end=end_line,
                )
                log_process("UNDERSTAND", "COLLECT", f"ğŸ“‹ í´ë˜ìŠ¤ ë°œê²¬: {extracted_name} ({node_type}, ë¼ì¸ {start_line}~{end_line})")

        # ìì‹ ë…¸ë“œ ìˆ˜ì§‘
        child_nodes: List[StatementNode] = []
        for ch in children:
            cn = self._visit(ch, None, class_key, class_name, class_kind)
            if cn:
                child_nodes.append(cn)

        # ë¶„ì„ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨ (FIELDëŠ” ì„ í–‰ ì²˜ë¦¬ì—ì„œ ASSOCIATIONìœ¼ë¡œ ì²˜ë¦¬ë¨)
        analyzable = node_type not in NON_ANALYSIS_TYPES and node_type not in CLASS_TYPES and node_type not in FIELD_TYPES
        token = calculate_code_token(code)

        self._node_id += 1
        st = StatementNode(
            node_id=self._node_id,
            start_line=start_line,
            end_line=end_line,
            node_type=node_type,
            code=code,
            token=token,
            has_children=bool(child_nodes),
            analyzable=analyzable,
            class_key=class_key,
            class_name=class_name,
            class_kind=class_kind,
            lines=line_entries,
        )
        for c in child_nodes:
            c.parent = st
        st.children.extend(child_nodes)

        # ë¶„ì„ ëŒ€ìƒ ë…¸ë“œ ì¹´ìš´íŠ¸
        if analyzable and class_key and class_key in self.classes:
            self.classes[class_key].pending_nodes += 1

        if not analyzable and node_type not in CLASS_TYPES:
            st.completion_event.set()

        self.nodes.append(st)
        log_process(
            "UNDERSTAND",
            "COLLECT",
            f"âœ… {node_type} ë…¸ë“œ ìˆ˜ì§‘ ì™„ë£Œ: ë¼ì¸ {start_line}~{end_line}, í† í° {token}, ìì‹ {len(child_nodes)}ê°œ",
        )
        return st


# ==================== ë°°ì¹˜ í”Œë˜ë„ˆ ====================
class BatchPlanner:
    """ìˆ˜ì§‘ëœ ë…¸ë“œë¥¼ í† í° í•œë„ ë‚´ì—ì„œ ë°°ì¹˜ë¡œ ë¬¶ìŠµë‹ˆë‹¤."""

    def __init__(self, token_limit: int = MAX_BATCH_TOKEN):
        self.token_limit = token_limit

    def plan(self, nodes: List[StatementNode]) -> List[AnalysisBatch]:
        """í† í° í•œë„ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ë…¸ë“œë¥¼ ë¶„í• í•˜ì—¬ ë¶„ì„ ë°°ì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        batches: List[AnalysisBatch] = []
        current_nodes: List[StatementNode] = []
        current_tokens = 0
        batch_id = 1

        for node in nodes:
            if not node.analyzable:
                continue
            if node.has_children:
                if current_nodes:
                    batches.append(self._create_batch(batch_id, current_nodes))
                    log_process(
                        "UNDERSTAND",
                        "BATCH",
                        f"ğŸ“¦ ë°°ì¹˜ #{batch_id} í™•ì •: ë¦¬í”„ ë…¸ë“œ {len(current_nodes)}ê°œ (í† í° {current_tokens}/{self.token_limit})",
                    )
                    batch_id += 1
                    current_nodes = []
                    current_tokens = 0
                batches.append(self._create_batch(batch_id, [node]))
                log_process(
                    "UNDERSTAND",
                    "BATCH",
                    f"ğŸ“¦ ë°°ì¹˜ #{batch_id} í™•ì •: ë¶€ëª¨ ë…¸ë“œ ë‹¨ë… (ë¼ì¸ {node.start_line}~{node.end_line}, í† í° {node.token})",
                )
                batch_id += 1
                continue
            if current_nodes and current_tokens + node.token > self.token_limit:
                batches.append(self._create_batch(batch_id, current_nodes))
                log_process(
                    "UNDERSTAND",
                    "BATCH",
                    f"ğŸ“¦ ë°°ì¹˜ #{batch_id} í™•ì •: í† í° í•œë„ ë„ë‹¬ (ëˆ„ì  {current_tokens}/{self.token_limit})",
                )
                batch_id += 1
                current_nodes = []
                current_tokens = 0
            current_nodes.append(node)
            current_tokens += node.token

        if current_nodes:
            batches.append(self._create_batch(batch_id, current_nodes))
            log_process(
                "UNDERSTAND",
                "BATCH",
                f"ğŸ“¦ ë°°ì¹˜ #{batch_id} í™•ì •: ë§ˆì§€ë§‰ ë¦¬í”„ ë…¸ë“œ {len(current_nodes)}ê°œ (í† í° {current_tokens}/{self.token_limit})",
            )
        return batches

    def _create_batch(self, batch_id: int, nodes: List[StatementNode]) -> AnalysisBatch:
        """ë°°ì¹˜ IDì™€ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ë¡œ AnalysisBatch ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (DBMS ìŠ¤íƒ€ì¼ê³¼ ë™ì¼)."""
        ranges = [{"startLine": node.start_line, "endLine": node.end_line} for node in nodes]
        # ë©”ì„œë“œ í˜¸ì¶œì„ í¬í•¨í•˜ëŠ” ë…¸ë“œ ìˆ˜ì§‘ (METHOD_CALL íƒ€ì… ë˜ëŠ” ì½”ë“œì— í˜¸ì¶œ íŒ¨í„´ í¬í•¨)
        method_call_ranges = [
            {"startLine": node.start_line, "endLine": node.end_line, "type": node.node_type, "code": node.code}
            for node in nodes
            if node.node_type in METHOD_CALL_TYPES or METHOD_CALL_PATTERN.search(node.code)
        ]
        progress = max(node.end_line for node in nodes)
        return AnalysisBatch(
            batch_id=batch_id, 
            nodes=nodes, 
            ranges=ranges, 
            method_call_ranges=method_call_ranges,
            progress_line=progress
        )


# ==================== LLM í˜¸ì¶œ ====================
class LLMInvoker:
    """ë°°ì¹˜ë¥¼ ì…ë ¥ ë°›ì•„ ì¼ë°˜ ë¶„ì„/METHOD_CALL ë¶„ì„ì„ ë³‘ë ¬ í˜¸ì¶œí•©ë‹ˆë‹¤."""

    def __init__(self, api_key: str, locale: str):
        self.api_key = api_key
        self.locale = locale

    async def invoke(self, batch: AnalysisBatch) -> Tuple[Optional[Dict[str, Any]], Optional[Dict[str, Any]]]:
        """ë°°ì¹˜ ì½”ë“œë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.
        
        Returns:
            (general_result, method_call_result) íŠœí”Œ
        """
        if not batch.ranges:
            return None, None

        # ì¼ë°˜ ë¶„ì„ íƒœìŠ¤í¬ (ë¶€ëª¨ ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
        general_task = asyncio.to_thread(
            understand_code,
            batch.build_general_payload(),
            batch.ranges,
            len(batch.ranges),
            self.api_key,
            self.locale,
            batch.get_parent_code(),  # ë¶€ëª¨ ì½”ë“œ ì»¨í…ìŠ¤íŠ¸
        )

        # METHOD_CALL ë¶„ì„ íƒœìŠ¤í¬ (METHOD_CALL ë…¸ë“œê°€ ìˆì„ ë•Œë§Œ)
        method_call_task = None
        method_call_payload = batch.build_method_call_payload()
        if method_call_payload and batch.method_call_ranges:
            method_call_task = asyncio.to_thread(
                understand_method_call,
                method_call_payload,
                batch.method_call_ranges,
                self.api_key,
                self.locale,
            )

        # ë³‘ë ¬ ì‹¤í–‰
        if method_call_task:
            general_result, method_call_result = await asyncio.gather(
                general_task, method_call_task
            )
            return general_result, method_call_result
        else:
            general_result = await general_task
            return general_result, None


# ==================== ì ìš© ë§¤ë‹ˆì € ====================
class ApplyManager:
    """LLM ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ì ìš©í•˜ê³  í´ë˜ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""

    def __init__(
        self,
        send_queue: asyncio.Queue,
        receive_queue: asyncio.Queue,
        file_last_line: int,
        nodes: List[StatementNode],
        node_base_props: str,
        classes: Dict[str, ClassInfo],
        api_key: str,
        locale: str,
        user_id: str,
        project_name: str,
        directory: str,
        file_name: str,
    ):
        self.send_queue = send_queue
        self.receive_queue = receive_queue
        self.file_last_line = file_last_line
        self._nodes = nodes
        self.node_base_props = node_base_props
        self.classes = classes
        self.api_key = api_key
        self.locale = locale
        self.user_id = user_id
        self.project_name = project_name
        # directoryëŠ” ì´ë¯¸ full_directory í˜•íƒœ (íŒŒì¼ëª… í¬í•¨)
        self.directory = directory
        self.file_name = file_name

        self._pending: Dict[int, BatchResult] = {}
        self._next_batch_id = 1
        self._lock = asyncio.Lock()
        self._finalized_classes: set[str] = set()
        self._class_summary_store: Dict[str, Dict[str, Any]] = {key: {} for key in classes}
        # í•„ë“œ íƒ€ì… ìºì‹œ: class_key â†’ {field_name: field_type}
        # Collection/Map íƒ€ì… í•„ë“œì˜ ë©”ì„œë“œ í˜¸ì¶œ í•„í„°ë§ì— ì‚¬ìš©
        self._field_type_cache: Dict[str, Dict[str, str]] = {key: {} for key in classes}

    async def submit(
        self, 
        batch: AnalysisBatch, 
        general_result: Optional[Dict[str, Any]],
        method_call_result: Optional[Dict[str, Any]] = None
    ):
        """ì›Œì»¤ê°€ batch ì²˜ë¦¬ë¥¼ ë§ˆì¹œ ë’¤ Apply íì— ë“±ë¡í•©ë‹ˆë‹¤."""
        async with self._lock:
            self._pending[batch.batch_id] = BatchResult(
                batch=batch, 
                general_result=general_result,
                method_call_result=method_call_result
            )
            await self._flush_ready()

    async def finalize(self):
        """ëª¨ë“  ë°°ì¹˜ê°€ ì ìš©ëœ í›„ í´ë˜ìŠ¤ ìš”ì•½ì„ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤."""
        async with self._lock:
            await self._flush_ready(force=True)
        await self._finalize_remaining_classes()

    async def _flush_ready(self, force: bool = False):
        """ë°°ì¹˜ ID ìˆœì„œëŒ€ë¡œ ì ìš©í•©ë‹ˆë‹¤."""
        while self._next_batch_id in self._pending:
            result = self._pending.pop(self._next_batch_id)
            await self._apply_batch(result)
            self._next_batch_id += 1
        if force and self._pending:
            for bid in sorted(self._pending):
                result = self._pending.pop(bid)
                await self._apply_batch(result)

    async def _apply_batch(self, result: BatchResult):
        """LLM ê²°ê³¼ë¥¼ Neo4j ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ê³  ì ìš©í•©ë‹ˆë‹¤."""
        queries: List[str] = []
        analysis_list = (result.general_result.get("analysis") or []) if result.general_result else []
        
        # ë¶„ì„ ì •ë³´ ìˆ˜ì§‘ (ìŠ¤íŠ¸ë¦¼ ë©”ì‹œì§€ìš©)
        analyzed_node_info: Optional[Dict[str, Any]] = None

        for node, analysis in zip(result.batch.nodes, analysis_list):
            if not analysis:
                log_process("UNDERSTAND", "APPLY", f"âš ï¸ {node.start_line}~{node.end_line} êµ¬ê°„ ìš”ì•½ ì—†ìŒ - ê±´ë„ˆëœ€")
                node.completion_event.set()
                continue

            summary = analysis.get("summary") or ""
            node.summary = summary
            escaped_summary = escape_for_cypher(str(summary))
            queries.append(
                f"MATCH (n:{node.node_type} {{startLine: {node.start_line}, {self.node_base_props}}}) "
                f"SET n.summary = '{escaped_summary}' "
                f"RETURN n"
            )
            log_process("UNDERSTAND", "APPLY", f"âœ… {node.start_line}~{node.end_line} êµ¬ê°„ ìš”ì•½ ë°˜ì˜")
            
            # ì²« ë²ˆì§¸ ë¶„ì„ ê²°ê³¼ì˜ ì •ë³´ ì €ì¥
            if not analyzed_node_info:
                analyzed_node_info = {
                    "type": node.node_type,
                    "name": node.class_name or f"Line {node.start_line}",
                    "summary": str(summary)[:100],
                    "line_range": f"{node.start_line}-{node.end_line}",
                }

            # ë¡œì»¬ ë³€ìˆ˜ ì˜ì¡´ ê´€ê³„ (DEPENDENCY) - ì—°ê´€ ê´€ê³„ê°€ ì—†ì„ ë•Œë§Œ
            # localDependenciesëŠ” ê°ì²´ ë°°ì—´: [{"type": "íƒ€ì…ëª…", "sourceMember": "ë©”ì„œë“œëª…"}]
            #
            # âœ… ê´€ê³„ ì¤‘ë³µ ë°©ì§€ ì •ì±…:
            # - (src)-[:DEPENDENCY {usage:'local'}]->(dst) ê´€ê³„ëŠ” src->dstë‹¹ 1ê°œë§Œ ìœ ì§€
            # - ì˜ì¡´ ë°œìƒ ìœ„ì¹˜ëŠ” r.source_members(List<String>)ì— ëˆ„ì 
            for dep in analysis.get("localDependencies", []) or []:
                if not dep:
                    continue
                
                # ê°ì²´ í˜•íƒœì¸ì§€ í™•ì¸ (í•˜ìœ„ í˜¸í™˜ì„± - ë¬¸ìì—´ì´ë©´ ë³€í™˜)
                if isinstance(dep, str):
                    dep_type = dep
                    source_member = "unknown"
                else:
                    dep_type = dep.get("type", "")
                    source_member = dep.get("sourceMember", "") or "unknown"
                
                if not dep_type:
                    continue
                    
                # ìœ íš¨í•˜ì§€ ì•Šì€ í´ë˜ìŠ¤ëª…ì´ë©´ DEPENDENCY ê´€ê³„ ìƒì„± ê±´ë„ˆëœ€
                if not _is_valid_class_name_for_calls(dep_type):
                    log_process("UNDERSTAND", "APPLY", f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ì˜ì¡´ ëŒ€ìƒ ì œì™¸: {dep_type}")
                    continue
                    
                escaped_dep = escape_for_cypher(dep_type)
                escaped_source = escape_for_cypher(source_member)
                # ì†Œì† í´ë˜ìŠ¤ì—ì„œ íƒ€ê²Ÿ í´ë˜ìŠ¤ë¡œ DEPENDENCY ê´€ê³„ ìƒì„± (ê¸°ì¡´ í´ë˜ìŠ¤ê°€ ìˆì„ ë•Œë§Œ)
                if node.class_kind and node.parent:
                    queries.append(
                        f"MATCH (src:{node.class_kind} {{startLine: {node.parent.start_line}, {self.node_base_props}}})\n"
                        f"MATCH (dst)\n"
                        f"WHERE (dst:CLASS OR dst:INTERFACE OR dst:ENUM OR dst:TEMP)\n"
                        f"  AND toLower(dst.class_name) = toLower('{escaped_dep}')\n"
                        f"  AND dst.user_id = '{self.user_id}'\n"
                        f"  AND dst.project_name = '{self.project_name}'\n"
                        f"  AND src <> dst\n"  # ìê¸° ìì‹  ì˜ì¡´ ë°©ì§€
                        f"  AND NOT (src)-[:ASSOCIATION|COMPOSITION]->(dst)\n"
                        f"MERGE (src)-[r:DEPENDENCY {{usage: 'local', source_member: '{escaped_source}'}}]->(dst)\n"
                        f"RETURN src, dst, r"
                    )

            self._update_class_store(node, analysis)
            node.completion_event.set()

        # completion_event ë¯¸ì„¤ì • ë…¸ë“œ ì²˜ë¦¬
        for node in result.batch.nodes:
            if not node.completion_event.is_set():
                node.completion_event.set()

        # METHOD_CALL ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ (ë³„ë„ í”„ë¡¬í”„íŠ¸ë¡œ ë¶„ì„ëœ ê²°ê³¼)
        if result.method_call_result:
            method_call_queries = self._build_method_call_queries(result)
            queries.extend(method_call_queries)

        if queries:
            await self._send_queries(queries, result.batch.progress_line, analyzed_node_info)
        log_process("UNDERSTAND", "APPLY", f"âœ… ë°°ì¹˜ #{result.batch.batch_id} ì ìš© ì™„ë£Œ")

    def _build_method_call_queries(self, result: BatchResult) -> List[str]:
        """METHOD_CALL ë¶„ì„ ê²°ê³¼ë¥¼ CALLS ê´€ê³„ ì¿¼ë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        í•„í„°ë§ ìˆœì„œ:
        1. targetClass ìœ íš¨ì„± ê²€ì‚¬ (ë¹ˆ ê°’, Java í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë“±)
        2. í•„ë“œ íƒ€ì… ê¸°ë°˜ Collection/Map í•„í„°ë§
        3. ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤ì—ë§Œ CALLS ê´€ê³„ ìƒì„± (MATCH)
        """
        queries: List[str] = []
        
        if not result.method_call_result:
            return queries
        
        calls = result.method_call_result.get("calls", []) or []
        
        for call in calls:
            target_class = call.get("targetClass")
            method_name = call.get("methodName")
            start_line = call.get("startLine")
            
            # targetClassê°€ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
            if not target_class:
                continue
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ í´ë˜ìŠ¤ëª… í•„í„°ë§ (Java í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬, ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤, ì§§ì€ ë³€ìˆ˜ëª… ë“±)
            if not _is_valid_class_name_for_calls(target_class):
                log_process("UNDERSTAND", "APPLY", f"âš ï¸ METHOD_CALL ì œì™¸ (í‘œì¤€ë¼ì´ë¸ŒëŸ¬ë¦¬/ìœ í‹¸ë¦¬í‹°/ë³€ìˆ˜ëª…): {target_class}.{method_name}")
                continue
            
            # í•´ë‹¹ ë¼ì¸ì˜ ë¶€ëª¨ ë…¸ë“œ ì°¾ê¸°
            parent_node = None
            for node in result.batch.nodes:
                if node.start_line <= start_line <= node.end_line:
                    if parent_node is None or node.start_line > parent_node.start_line:
                        parent_node = node
            
            if not parent_node:
                continue
            
            # í•„ë“œ íƒ€ì… ê¸°ë°˜ Collection/Map í•„í„°ë§
            # target_classê°€ í˜„ì¬ í´ë˜ìŠ¤ì˜ í•„ë“œëª…ì´ê³ , í•´ë‹¹ í•„ë“œê°€ Collection/Map íƒ€ì…ì´ë©´ ì œì™¸
            class_key = parent_node.class_key
            if class_key and class_key in self._field_type_cache:
                field_types = self._field_type_cache[class_key]
                if target_class in field_types:
                    field_type = field_types[target_class]
                    if field_type.startswith(COLLECTION_TYPE_PREFIXES):
                        log_process(
                            "UNDERSTAND", "APPLY", 
                            f"âš ï¸ METHOD_CALL ì œì™¸ (Collection í•„ë“œ): {target_class}({field_type}).{method_name}"
                        )
                        continue
            
            escaped_target = escape_for_cypher(target_class)
            escaped_method = escape_for_cypher(method_name or "")
            
            # ê¸°ì¡´ í´ë˜ìŠ¤ê°€ ìˆì„ ë•Œë§Œ CALLS ê´€ê³„ ìƒì„±
            queries.append(
                f"MATCH (c:{parent_node.node_type} {{startLine: {parent_node.start_line}, {self.node_base_props}}})\n"
                f"MATCH (t)\n"
                f"WHERE (t:CLASS OR t:INTERFACE OR t:ENUM OR t:TEMP)\n"
                f"  AND toLower(t.class_name) = toLower('{escaped_target}')\n"
                f"  AND t.user_id = '{self.user_id}'\n"
                f"  AND t.project_name = '{self.project_name}'\n"
                f"MERGE (c)-[r:CALLS {{method: '{escaped_method}'}}]->(t)\n"
                f"RETURN c, t, r"
            )
        
        return queries

    def _update_class_store(self, node: StatementNode, analysis: Dict[str, Any]):
        """í´ë˜ìŠ¤ ìš”ì•½ í›„ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        if not node.class_key or node.class_key not in self.classes:
            return
        summary_entry = analysis.get("summary")
        if summary_entry:
            key = f"{node.node_type}_{node.start_line}_{node.end_line}"
            self._class_summary_store[node.class_key][key] = summary_entry
        info = self.classes[node.class_key]
        if info.pending_nodes > 0:
            info.pending_nodes -= 1
        if info.pending_nodes == 0 and info.key not in self._finalized_classes:
            asyncio.create_task(self._finalize_class_summary(info))

    async def _finalize_class_summary(self, info: ClassInfo):
        """í´ë˜ìŠ¤ ìš”ì•½ + User Story + AC ìƒì„±.
        
        ëŒ€ìš©ëŸ‰ summaryê°€ ìˆì„ ê²½ìš° ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬í•˜ê³ ,
        ì´ì „ ì²­í¬ ê²°ê³¼ë¥¼ ë‹¤ìŒ ì²­í¬ì— ì „ë‹¬í•˜ì—¬ ì—°ì†ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.
        """
        if info.key in self._finalized_classes:
            return
        self._finalized_classes.add(info.key)

        class_node = next(
            (n for n in self._nodes if n.start_line == info.node_start and n.node_type == info.kind),
            None,
        )
        if not class_node:
            return

        summaries = self._class_summary_store.pop(info.key, {})
        if not summaries:
            class_node.completion_event.set()
            return

        try:
            # ëŒ€ìš©ëŸ‰ ì²˜ë¦¬: summary ê°œìˆ˜ê°€ MAX_SUMMARY_CHUNK_SIZEë¥¼ ì´ˆê³¼í•˜ë©´ ì²­í¬ë¡œ ë¶„í• 
            summary_items = list(summaries.items())
            total_count = len(summary_items)
            
            if total_count <= MAX_SUMMARY_CHUNK_SIZE:
                # ë‹¨ì¼ ì²­í¬ ì²˜ë¦¬
                result = await asyncio.to_thread(
                    understand_class_summary,
                    summaries,
                    self.api_key,
                    self.locale,
                )
            else:
                # ì²­í¬ ë¶„í•  ì²˜ë¦¬
                log_process("UNDERSTAND", "SUMMARY", f"ğŸ“¦ {info.name}: ëŒ€ìš©ëŸ‰ summary ({total_count}ê°œ) ì²­í¬ ë¶„í•  ì²˜ë¦¬ ì‹œì‘")
                
                chunks = [
                    dict(summary_items[i:i + MAX_SUMMARY_CHUNK_SIZE])
                    for i in range(0, total_count, MAX_SUMMARY_CHUNK_SIZE)
                ]
                
                previous_summary = ""
                previous_user_stories = []
                final_summary = ""
                all_user_stories = []  # ëª¨ë“  ì²­í¬ì˜ User Story ëˆ„ì 
                
                for chunk_idx, chunk in enumerate(chunks, 1):
                    log_process("UNDERSTAND", "SUMMARY", f"  â†’ ì²­í¬ {chunk_idx}/{len(chunks)} ì²˜ë¦¬ ì¤‘ ({len(chunk)}ê°œ)")
                    
                    chunk_result = await asyncio.to_thread(
                        understand_class_summary, 
                        chunk, 
                        self.api_key, 
                        self.locale, 
                        previous_summary,
                        previous_user_stories
                    )
                    
                    if isinstance(chunk_result, dict):
                        # summaryëŠ” ë§ˆì§€ë§‰ ì²­í¬ì˜ ê²ƒì„ ìµœì¢… ì‚¬ìš© (ì´ì „ summaryë¥¼ í¬í•¨í•œ ì „ì²´ ìš”ì•½)
                        final_summary = chunk_result.get('summary', '')
                        previous_summary = final_summary
                        
                        # user_storiesëŠ” ëˆ„ì  (LLMì´ ì´ì „ ê²ƒê³¼ ì¤‘ë³µ ì œê±°í•˜ë©° ìƒì„±)
                        chunk_stories = chunk_result.get('user_stories', [])
                        if chunk_stories:
                            # ì´ì „ User Storyë¥¼ ë‹¤ìŒ ì²­í¬ì— ì „ë‹¬ (ì¤‘ë³µ ë°©ì§€ìš©)
                            previous_user_stories = chunk_stories
                            # ëª¨ë“  ì²­í¬ì˜ User Story ëˆ„ì 
                            all_user_stories.extend(chunk_stories)
                
                # ìµœì¢… ê²°ê³¼ ì¡°í•© (ë§ˆì§€ë§‰ summary + ëª¨ë“  ì²­í¬ì˜ User Story)
                result = {
                    'summary': final_summary,
                    'user_stories': all_user_stories
                }
                log_process("UNDERSTAND", "SUMMARY", f"âœ… {info.name}: ì²­í¬ ë¶„í•  ì²˜ë¦¬ ì™„ë£Œ (User Story {len(all_user_stories)}ê°œ)")
                
        except Exception as exc:
            log_process("UNDERSTAND", "SUMMARY", f"âŒ í´ë˜ìŠ¤ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {info.name}", logging.ERROR, exc)
            class_node.completion_event.set()
            return

        if not isinstance(result, dict):
            class_node.completion_event.set()
            return
            
        summary_value = result.get("summary")
        user_stories = result.get("user_stories", [])
        
        if not summary_value:
            log_process("UNDERSTAND", "SUMMARY", f"âš ï¸ í´ë˜ìŠ¤ ìš”ì•½ ì—†ìŒ: {info.name}")
            class_node.completion_event.set()
            return

        # Neo4jì— summaryì™€ user_stories ì €ì¥
        escaped_summary = escape_for_cypher(str(summary_value))
        user_stories_json = json.dumps(user_stories, ensure_ascii=False)
        
        query = (
            f"MATCH (n:{info.kind} {{startLine: {info.node_start}, {self.node_base_props}}})\n"
            f"SET n.summary = '{escaped_summary}',\n"
            f"    n.user_stories = {user_stories_json}\n"
            f"RETURN n"
        )
        await self._send_queries([query], info.node_end)
        class_node.summary = str(summary_value)
        class_node.completion_event.set()
        
        # User Story ê°œìˆ˜ ë¡œê¹…
        us_count = len(user_stories) if user_stories else 0
        log_process("UNDERSTAND", "SUMMARY", f"âœ… í´ë˜ìŠ¤ ìš”ì•½ + User Story({us_count}ê°œ) ì™„ë£Œ: {info.name}")

    async def _finalize_remaining_classes(self):
        """ë‚¨ì€ í´ë˜ìŠ¤ ìš”ì•½ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        for key, info in list(self.classes.items()):
            if info.pending_nodes == 0 and key not in self._finalized_classes:
                await self._finalize_class_summary(info)

    async def _send_queries(
        self,
        queries: List[str],
        progress_line: int,
        analysis_info: Optional[Dict[str, Any]] = None
    ):
        """ì¿¼ë¦¬ë¥¼ ì „ì†¡í•˜ê³  ì™„ë£Œë¥¼ ëŒ€ê¸°í•©ë‹ˆë‹¤."""
        if not queries:
            return
        event = {
            "type": "analysis_code",
            "query_data": queries,
            "line_number": progress_line,
        }
        if analysis_info:
            event["analysis_info"] = analysis_info
        await self.send_queue.put(event)
        while True:
            resp = await self.receive_queue.get()
            if resp.get("type") == "process_completed":
                break
        log_process("UNDERSTAND", "APPLY", f"âœ… Neo4j ë°˜ì˜ ì™„ë£Œ (ë¼ì¸ {progress_line})")


# ==================== Analyzer ë³¸ì²´ ====================
class FrameworkAnalyzer:
    """Framework Understanding íŒŒì´í”„ë¼ì¸ì˜ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸."""

    def __init__(
        self,
        antlr_data: dict,
        file_content: str,
        send_queue: asyncio.Queue,
        receive_queue: asyncio.Queue,
        last_line: int,
        directory: str,
        file_name: str,
        user_id: str,
        api_key: str,
        locale: str,
        project_name: str,
    ):
        self.antlr_data = antlr_data
        self.file_content = file_content
        self.send_queue = send_queue
        self.receive_queue = receive_queue
        self.last_line = last_line
        self.directory = directory
        self.file_name = file_name
        self.user_id = user_id
        self.api_key = api_key
        self.locale = locale
        self.project_name = project_name
        self.max_workers = MAX_CONCURRENCY
        # full_directory: ë””ë ‰í† ë¦¬ + íŒŒì¼ëª… (Neo4j directory ì†ì„±ìœ¼ë¡œ ì‚¬ìš©)
        # Windows ê²½ë¡œ êµ¬ë¶„ì(\\)ë¥¼ /ë¡œ ë³€í™˜í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
        normalized_dir = directory.replace('\\', '/') if directory else ''
        self.full_directory = f"{normalized_dir}/{file_name}" if normalized_dir else file_name

        self.node_base_props = (
            f"directory: '{escape_for_cypher(self.full_directory)}', file_name: '{file_name}', "
            f"user_id: '{user_id}', project_name: '{project_name}'"
        )

    async def run(self):
        """íŒŒì¼ ë‹¨ìœ„ Understanding íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        log_process("UNDERSTAND", "START", f"ğŸš€ {self.full_directory} ë¶„ì„ ì‹œì‘ (ì´ {self.last_line}ì¤„)")
        try:
            # 1. AST ìˆ˜ì§‘
            collector = StatementCollector(self.antlr_data, self.file_content, self.directory, self.file_name)
            nodes, classes = collector.collect()

            # 2. ì •ì  ê·¸ë˜í”„ ì´ˆê¸°í™”
            await self._initialize_static_graph(nodes)

            # 3. ì„ í–‰ ì²˜ë¦¬ (ë³‘ë ¬): ìƒì†/êµ¬í˜„ + í•„ë“œ
            await self._process_preprocessing(nodes)

            # 4. ë°°ì¹˜ ë¶„ì„
            planner = BatchPlanner()
            batches = planner.plan(nodes)

            if not batches:
                await self.send_queue.put({"type": "end_analysis"})
                return

            # LLM ë¶„ì„ ì‹œì‘ ì•Œë¦¼ (ì´ ë°°ì¹˜ ìˆ˜ ì „ë‹¬)
            await self.send_queue.put({"type": "llm_start", "total_batches": len(batches)})
            while True:
                resp = await self.receive_queue.get()
                if resp.get("type") == "process_completed":
                    break

            invoker = LLMInvoker(self.api_key, self.locale)
            apply_manager = ApplyManager(
                send_queue=self.send_queue,
                receive_queue=self.receive_queue,
                file_last_line=self.last_line,
                nodes=nodes,
                node_base_props=self.node_base_props,
                classes=classes,
                api_key=self.api_key,
                locale=self.locale,
                user_id=self.user_id,
                project_name=self.project_name,
                directory=self.directory,
                file_name=self.file_name,
            )

            semaphore = asyncio.Semaphore(min(self.max_workers, len(batches)))

            async def worker(batch: AnalysisBatch):
                await self._wait_for_dependencies(batch)
                async with semaphore:
                    log_process(
                        "UNDERSTAND",
                        "LLM",
                        f"ğŸ¤– ë°°ì¹˜ #{batch.batch_id} LLM ìš”ì²­: ë…¸ë“œ {len(batch.nodes)}ê°œ ({self.full_directory})",
                    )
                    general_result, method_call_result = await invoker.invoke(batch)
                await apply_manager.submit(batch, general_result, method_call_result)

            await asyncio.gather(*(worker(b) for b in batches))
            await apply_manager.finalize()

            log_process("UNDERSTAND", "DONE", f"âœ… {self.full_directory} ë¶„ì„ ì™„ë£Œ")
            await self.send_queue.put({"type": "end_analysis"})

        except (AnalysisError, LLMCallError) as exc:
            log_process("UNDERSTAND", "ERROR", "âŒ Understanding íŒŒì´í”„ë¼ì¸ ì˜ˆì™¸", logging.ERROR, exc)
            await self.send_queue.put({"type": "error", "message": str(exc)})
            raise
        except Exception as exc:
            err_msg = f"Understanding ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {exc}"
            log_process("UNDERSTAND", "ERROR", f"âŒ {err_msg}", logging.ERROR, exc)
            await self.send_queue.put({"type": "error", "message": err_msg})
            raise ProcessAnalyzeCodeError(err_msg)

    async def _wait_for_dependencies(self, batch: AnalysisBatch):
        """ë¶€ëª¨ ë…¸ë“œ ë¶„ì„ ì „ ìì‹ ì™„ë£Œ ëŒ€ê¸°."""
        waiters = []
        for n in batch.nodes:
            for ch in n.children:
                if ch.analyzable:
                    waiters.append(ch.completion_event.wait())
        if waiters:
            log_process(
                "UNDERSTAND",
                "WAIT",
                f"â³ ë°°ì¹˜ #{batch.batch_id}ê°€ ìì‹ {len(waiters)}ê°œ ì™„ë£Œ ëŒ€ê¸°",
            )
            await asyncio.gather(*waiters)

    # ===== ì •ì  ê·¸ë˜í”„ ì´ˆê¸°í™” =====
    async def _initialize_static_graph(self, nodes: List[StatementNode]):
        """íŒŒì¼ ë¶„ì„ ì „ì— ì •ì  ë…¸ë“œ/ê´€ê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if not nodes:
            return
        await self._create_static_nodes(nodes)
        await self._create_relationships(nodes)
        # ì •ì  ê·¸ë˜í”„ ì´ˆê¸°í™” ì™„ë£Œ ì•Œë¦¼
        await self.send_queue.put({"type": "static_complete"})
        while True:
            resp = await self.receive_queue.get()
            if resp.get("type") == "process_completed":
                break

    async def _create_static_nodes(self, nodes: List[StatementNode]):
        """ê° StatementNodeì— ëŒ€ì‘í•˜ëŠ” ê¸°ë³¸ ë…¸ë“œë¥¼ Neo4jì— ìƒì„±í•©ë‹ˆë‹¤."""
        queries: List[str] = []
        current_batch_nodes: List[StatementNode] = []
        
        for node in nodes:
            queries.extend(self._build_static_node_queries(node))
            current_batch_nodes.append(node)
            
            if len(queries) >= STATIC_QUERY_BATCH_SIZE:
                node_info = self._build_batch_node_info(current_batch_nodes)
                await self._send_static_queries(queries, node.end_line, node_info)
                queries.clear()
                current_batch_nodes.clear()
                
        if queries:
            node_info = self._build_batch_node_info(current_batch_nodes)
            await self._send_static_queries(queries, nodes[-1].end_line, node_info)

    def _build_batch_node_info(self, nodes: List[StatementNode]) -> Dict[str, Any]:
        """ë°°ì¹˜ì˜ ë…¸ë“œë“¤ ì •ë³´ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
        if not nodes:
            return {}
        
        # ë…¸ë“œ íƒ€ì…ë³„ ì§‘ê³„
        type_counts: Dict[str, int] = {}
        for node in nodes:
            type_counts[node.node_type] = type_counts.get(node.node_type, 0) + 1
        
        # ì²« ë²ˆì§¸ ì˜ë¯¸ ìˆëŠ” ë…¸ë“œ ì •ë³´ (CLASS, INTERFACE, METHOD ë“±)
        first_node = nodes[0]
        for node in nodes:
            if node.node_type in CLASS_TYPES or node.class_name:
                first_node = node
                break
        
        return {
            "type": first_node.node_type,
            "name": first_node.class_name or f"Line {first_node.start_line}",
            "start_line": first_node.start_line,
            "node_count": len(nodes),
            "type_summary": type_counts,
        }

    def _build_static_node_queries(self, node: StatementNode) -> List[str]:
        """ì •ì  ë…¸ë“œ ìƒì„± ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        queries: List[str] = []
        label = node.node_type
        
        # name ì†ì„± ê²°ì •: CLASS/INTERFACE/METHODëŠ” ì‹¤ì œ ì´ë¦„, ê·¸ ì™¸ëŠ” íƒ€ì…[ë¼ì¸ë²ˆí˜¸]
        if label == "FILE":
            node_name = self.file_name
        elif label in CLASS_TYPES and node.class_name:
            node_name = node.class_name
        else:
            node_name = f"{label}[{node.start_line}]"
        
        escaped_name = escape_for_cypher(node_name)
        has_children = "true" if node.has_children else "false"
        escaped_code = escape_for_cypher(node.code)

        base_set = [
            f"n.endLine = {node.end_line}",
            f"n.name = '{escaped_name}'",
            f"n.node_code = '{escaped_code}'",
            f"n.token = {node.token}",
            f"n.has_children = {has_children}",
        ]

        # CLASS/INTERFACE ë“±: class_nameê³¼ type ì†ì„± ì¶”ê°€
        if label in CLASS_TYPES and node.class_name:
            base_set.append(f"n.class_name = '{escape_for_cypher(node.class_name)}'")
            base_set.append(f"n.type = '{label}'")
        # ê·¸ ì™¸ ë…¸ë“œ: ì†Œì† í´ë˜ìŠ¤ëª… ì €ì¥
        elif node.class_name:
            base_set.append(f"n.class_name = '{escape_for_cypher(node.class_name)}'")

        if node.has_children:
            escaped_placeholder = escape_for_cypher(node.get_placeholder_code())
            base_set.append(f"n.summarized_code = '{escaped_placeholder}'")

        base_set_str = ", ".join(base_set)
        
        # CLASS/INTERFACE/ENUM ë…¸ë“œ: ê¸°ì¡´ ë…¸ë“œ(TEMP í¬í•¨) íƒìƒ‰ â†’ ì—†ìœ¼ë©´ ìƒì„±, ìˆìœ¼ë©´ ë ˆì´ë¸” í™•ì •
        if label in ("CLASS", "INTERFACE", "ENUM") and node.class_name:
            escaped_class_name = escape_for_cypher(node.class_name)
            queries.append(
                f"OPTIONAL MATCH (existing)\n"
                f"WHERE (existing:CLASS OR existing:INTERFACE OR existing:ENUM OR existing:TEMP)\n"
                f"  AND toLower(existing.class_name) = toLower('{escaped_class_name}')\n"
                f"  AND existing.user_id = '{self.user_id}'\n"
                f"  AND existing.project_name = '{self.project_name}'\n"
                f"WITH existing\n"
                f"FOREACH(_ IN CASE WHEN existing IS NULL THEN [1] ELSE [] END |\n"
                f"    CREATE (:{label} {{class_name: '{escaped_class_name}', user_id: '{self.user_id}', project_name: '{self.project_name}'}}))\n"
                f"WITH 1 as dummy\n"
                f"MATCH (n)\n"
                f"WHERE (n:CLASS OR n:INTERFACE OR n:ENUM OR n:TEMP)\n"
                f"  AND toLower(n.class_name) = toLower('{escaped_class_name}')\n"
                f"  AND n.user_id = '{self.user_id}'\n"
                f"  AND n.project_name = '{self.project_name}'\n"
                f"REMOVE n:TEMP\n"
                f"SET n:{label}, n.startLine = {node.start_line}, n.directory = '{escape_for_cypher(self.full_directory)}', n.file_name = '{self.file_name}', {base_set_str}\n"
                f"RETURN n"
            )
        else:
            queries.append(
                f"MERGE (n:{label} {{startLine: {node.start_line}, {self.node_base_props}}})\n"
                f"SET {base_set_str}\n"
                f"RETURN n"
            )
        return queries

    async def _create_relationships(self, nodes: List[StatementNode]):
        """PARENT_OF / NEXT ê´€ê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        queries: List[str] = []
        for node in nodes:
            for child in node.children:
                queries.append(self._build_parent_relationship_query(node, child))
                if len(queries) >= STATIC_QUERY_BATCH_SIZE:
                    await self._send_static_queries(queries, child.end_line)
                    queries.clear()

            prev = None
            for child in node.children:
                if prev:
                    queries.append(self._build_next_relationship_query(prev, child))
                    if len(queries) >= STATIC_QUERY_BATCH_SIZE:
                        await self._send_static_queries(queries, child.end_line)
                        queries.clear()
                prev = child
        if queries:
            await self._send_static_queries(queries, nodes[-1].end_line)

    def _build_parent_relationship_query(self, parent: StatementNode, child: StatementNode) -> str:
        """ë¶€ëª¨ì™€ ìì‹ ë…¸ë“œ ì‚¬ì´ì˜ PARENT_OF ê´€ê³„ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤ (DBMS ìŠ¤íƒ€ì¼ê³¼ ë™ì¼)."""
        parent_match = f"MATCH (parent:{parent.node_type} {{startLine: {parent.start_line}, {self.node_base_props}}})"
        child_match = f"MATCH (child:{child.node_type} {{startLine: {child.start_line}, {self.node_base_props}}})"
        return f"{parent_match}\n{child_match}\nMERGE (parent)-[r:PARENT_OF]->(child)\nRETURN parent, child, r"

    def _build_next_relationship_query(self, prev_node: StatementNode, current_node: StatementNode) -> str:
        """í˜•ì œ ë…¸ë“œ ì‚¬ì´ì˜ NEXT ê´€ê³„ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤ (DBMS ìŠ¤íƒ€ì¼ê³¼ ë™ì¼)."""
        prev_match = f"MATCH (prev:{prev_node.node_type} {{startLine: {prev_node.start_line}, {self.node_base_props}}})"
        curr_match = f"MATCH (current:{current_node.node_type} {{startLine: {current_node.start_line}, {self.node_base_props}}})"
        return f"{prev_match}\n{curr_match}\nMERGE (prev)-[r:NEXT]->(current)\nRETURN prev, current, r"

    async def _send_static_queries(
        self,
        queries: List[str],
        progress_line: int,
        node_info: Optional[Dict[str, Any]] = None
    ):
        """ì •ì  ê·¸ë˜í”„ ì¿¼ë¦¬ ì „ì†¡."""
        if not queries:
            return
        event = {
            "type": "static_graph",
            "query_data": queries,
            "line_number": progress_line,
        }
        if node_info:
            event["node_info"] = node_info
        await self.send_queue.put(event)
        while True:
            resp = await self.receive_queue.get()
            if resp.get("type") == "process_completed":
                break

    # ===== ì„ í–‰ ì²˜ë¦¬: ìƒì†/êµ¬í˜„ + í•„ë“œ + ë©”ì„œë“œ (ë³‘ë ¬) =====
    async def _process_preprocessing(self, nodes: List[StatementNode]):
        """ìƒì†/êµ¬í˜„, í•„ë“œ, ë©”ì„œë“œ ë…¸ë“œë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        inheritance_nodes = [n for n in nodes if n.node_type in INHERITANCE_TYPES]
        field_nodes = [n for n in nodes if n.node_type in FIELD_TYPES]
        method_nodes = [n for n in nodes if n.node_type in METHOD_TYPES]

        log_process("UNDERSTAND", "PREPROCESS", f"ğŸ” ì„ í–‰ ì²˜ë¦¬ ì‹œì‘: ìƒì†/êµ¬í˜„ {len(inheritance_nodes)}ê°œ, í•„ë“œ {len(field_nodes)}ê°œ, ë©”ì„œë“œ {len(method_nodes)}ê°œ")

        # 1ë‹¨ê³„: ìƒì†/êµ¬í˜„ + í•„ë“œ ë³‘ë ¬ ì²˜ë¦¬ (ASSOCIATION ìƒì„±)
        await asyncio.gather(
            self._process_inheritance_nodes(inheritance_nodes),
            self._process_field_nodes(field_nodes, nodes),
        )

        # 2ë‹¨ê³„: ë©”ì„œë“œ ì²˜ë¦¬ (ASSOCIATION â†’ COMPOSITION ë³€ê²½)
        await self._process_method_nodes(method_nodes)

        log_process("UNDERSTAND", "PREPROCESS", f"âœ… ì„ í–‰ ì²˜ë¦¬ ì™„ë£Œ")

    async def _process_inheritance_nodes(self, nodes: List[StatementNode]):
        """ìƒì†/êµ¬í˜„ ë…¸ë“œë¥¼ ë³‘ë ¬ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."""
        if not nodes:
            return

        log_process("UNDERSTAND", "INHERITANCE", f"ğŸ” ìƒì†/êµ¬í˜„ ê´€ê³„ ë¶„ì„ ì‹œì‘: {len(nodes)}ê°œ ë…¸ë“œ")
        semaphore = asyncio.Semaphore(INHERITANCE_CONCURRENCY)

        async def worker(node: StatementNode):
            async with semaphore:
                try:
                    result = await asyncio.to_thread(
                        understand_inheritance,
                        node.get_raw_code(),
                        self.api_key,
                        self.locale,
                    )
                except Exception as exc:
                    log_process("UNDERSTAND", "INHERITANCE", f"âŒ ìƒì†/êµ¬í˜„ ë¶„ì„ ì˜¤ë¥˜: ë¼ì¸ {node.start_line}", logging.ERROR, exc)
                    return

                queries = self._build_inheritance_queries(node, result)
                if queries:
                    await self._send_static_queries(queries, node.end_line)

        await asyncio.gather(*(worker(n) for n in nodes))
        log_process("UNDERSTAND", "INHERITANCE", f"âœ… ìƒì†/êµ¬í˜„ ê´€ê³„ ë¶„ì„ ì™„ë£Œ")

    def _build_inheritance_queries(self, node: StatementNode, analysis: Dict[str, Any]) -> List[str]:
        """ìƒì†/êµ¬í˜„ ë¶„ì„ ê²°ê³¼ë¥¼ Neo4j ì¿¼ë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not isinstance(analysis, dict):
            return []

        queries: List[str] = []
        relations = analysis.get("relations") or []

        for rel in relations:
            to_type = escape_for_cypher(rel.get("toType") or "")
            rel_type = rel.get("relationType") or "EXTENDS"
            to_type_kind = escape_for_cypher(rel.get("toTypeKind") or ("INTERFACE" if rel_type == "IMPLEMENTS" else "CLASS"))

            if not to_type:
                continue

            # ì†ŒìŠ¤ í´ë˜ìŠ¤ ë…¸ë“œ ë§¤ì¹­
            src_match = f"MATCH (src:{node.class_kind or 'CLASS'} {{startLine: {node.parent.start_line if node.parent else node.start_line}, {self.node_base_props}}})"

            # íƒ€ê²Ÿ ë…¸ë“œ: DBMS íŒ¨í„´ - OPTIONAL MATCHë¡œ ê¸°ì¡´ ë…¸ë“œ ì°¾ê³ , ì—†ìœ¼ë©´ CREATE (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            queries.append(
                f"{src_match}\n"
                f"OPTIONAL MATCH (existing)\n"
                f"WHERE (existing:CLASS OR existing:INTERFACE OR existing:ENUM OR existing:TEMP)\n"
                f"  AND toLower(existing.class_name) = toLower('{to_type}')\n"
                f"  AND existing.user_id = '{self.user_id}'\n"
                f"  AND existing.project_name = '{self.project_name}'\n"
                f"WITH src, existing\n"
                f"FOREACH(_ IN CASE WHEN existing IS NULL THEN [1] ELSE [] END |\n"
                f"    CREATE (:TEMP {{class_name: '{to_type}', name: '{to_type}', user_id: '{self.user_id}', project_name: '{self.project_name}'}}))\n"
                f"WITH src\n"
                f"MATCH (dst)\n"
                f"WHERE (dst:CLASS OR dst:INTERFACE OR dst:ENUM OR dst:TEMP)\n"
                f"  AND toLower(dst.class_name) = toLower('{to_type}')\n"
                f"  AND dst.user_id = '{self.user_id}'\n"
                f"  AND dst.project_name = '{self.project_name}'\n"
                f"MERGE (src)-[r:{rel_type}]->(dst)\n"
                f"RETURN src, dst, r"
            )

        return queries

    async def _process_field_nodes(self, field_nodes: List[StatementNode], all_nodes: List[StatementNode]):
        """í•„ë“œ ë…¸ë“œë¥¼ ë³‘ë ¬ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."""
        if not field_nodes:
            return

        log_process("UNDERSTAND", "FIELD", f"ğŸ” í•„ë“œ ì •ë³´ ë¶„ì„ ì‹œì‘: {len(field_nodes)}ê°œ ë…¸ë“œ")
        semaphore = asyncio.Semaphore(FIELD_CONCURRENCY)

        async def worker(node: StatementNode):
            async with semaphore:
                try:
                    result = await asyncio.to_thread(
                        understand_field,
                        node.get_raw_code(),
                        self.api_key,
                        self.locale,
                    )
                except Exception as exc:
                    log_process("UNDERSTAND", "FIELD", f"âŒ í•„ë“œ ë¶„ì„ ì˜¤ë¥˜: ë¼ì¸ {node.start_line}", logging.ERROR, exc)
                    return

                queries = self._build_field_queries(node, result)
                if queries:
                    await self._send_static_queries(queries, node.end_line)

        await asyncio.gather(*(worker(n) for n in field_nodes))
        log_process("UNDERSTAND", "FIELD", f"âœ… í•„ë“œ ì •ë³´ ë¶„ì„ ì™„ë£Œ")

    def _build_field_queries(self, node: StatementNode, analysis: Dict[str, Any]) -> List[str]:
        """í•„ë“œ ë¶„ì„ ê²°ê³¼ë¥¼ Neo4j ì¿¼ë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not isinstance(analysis, dict):
            return []

        queries: List[str] = []
        fields = analysis.get("fields") or []

        for field_info in fields:
            field_name = escape_for_cypher(field_info.get("field_name") or "")
            field_type_raw = field_info.get("field_type") or ""
            field_type = escape_for_cypher(field_type_raw)
            target_class_raw = field_info.get("target_class")
            target_class = escape_for_cypher(target_class_raw) if target_class_raw else None
            visibility = escape_for_cypher(field_info.get("visibility") or "private")
            is_static = "true" if field_info.get("is_static") else "false"
            is_final = "true" if field_info.get("is_final") else "false"
            multiplicity = escape_for_cypher(field_info.get("multiplicity") or "1")
            association_type = field_info.get("association_type") or "ASSOCIATION"

            if not field_name:
                continue

            # í•„ë“œ íƒ€ì… ìºì‹œ ì—…ë°ì´íŠ¸ (Collection/Map í•„í„°ë§ìš©)
            if node.class_key and node.class_key in self._field_type_cache:
                # escape ì „ ì›ë³¸ í•„ë“œëª…ê³¼ íƒ€ì… ì €ì¥
                original_field_name = field_info.get("field_name") or ""
                self._field_type_cache[node.class_key][original_field_name] = field_type_raw

            # FIELD ë…¸ë“œ ì†ì„± ì—…ë°ì´íŠ¸
            # target_classê°€ ìˆìœ¼ë©´ í´ë˜ìŠ¤ íƒ€ì… í•„ë“œ (ì—°ê´€ ê´€ê³„ ëŒ€ìƒ)
            target_class_set = f", f.target_class = '{target_class}'" if target_class else ""
            queries.append(
                f"MATCH (f:FIELD {{startLine: {node.start_line}, {self.node_base_props}}})\n"
                f"SET f.name = '{field_name}', f.field_type = '{field_type}', "
                f"f.visibility = '{visibility}', f.is_static = {is_static}, f.is_final = {is_final}{target_class_set}\n"
                f"RETURN f"
            )

            # ì—°ê´€ ê´€ê³„ ìƒì„± (ASSOCIATION, COMPOSITION)
            # íƒ€ê²Ÿ ë…¸ë“œ: DBMS íŒ¨í„´ - OPTIONAL MATCHë¡œ ê¸°ì¡´ ë…¸ë“œ ì°¾ê³ , ì—†ìœ¼ë©´ CREATE (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            if target_class:
                src_match = f"MATCH (src:{node.class_kind or 'CLASS'} {{startLine: {node.parent.start_line if node.parent else node.start_line}, {self.node_base_props}}})"
                queries.append(
                    f"{src_match}\n"
                    f"OPTIONAL MATCH (existing)\n"
                    f"WHERE (existing:CLASS OR existing:INTERFACE OR existing:ENUM OR existing:TEMP)\n"
                    f"  AND toLower(existing.class_name) = toLower('{target_class}')\n"
                    f"  AND existing.user_id = '{self.user_id}'\n"
                    f"  AND existing.project_name = '{self.project_name}'\n"
                    f"WITH src, existing\n"
                    f"FOREACH(_ IN CASE WHEN existing IS NULL THEN [1] ELSE [] END |\n"
                    f"    CREATE (:TEMP {{class_name: '{target_class}', name: '{target_class}', user_id: '{self.user_id}', project_name: '{self.project_name}'}}))\n"
                    f"WITH src\n"
                    f"MATCH (dst)\n"
                    f"WHERE (dst:CLASS OR dst:INTERFACE OR dst:ENUM OR dst:TEMP)\n"
                    f"  AND toLower(dst.class_name) = toLower('{target_class}')\n"
                    f"  AND dst.user_id = '{self.user_id}'\n"
                    f"  AND dst.project_name = '{self.project_name}'\n"
                    f"MERGE (src)-[r:{association_type} {{source_member: '{field_name}', multiplicity: '{multiplicity}'}}]->(dst)\n"
                    f"RETURN src, dst, r"
                )

        return queries

    async def _process_method_nodes(self, method_nodes: List[StatementNode]):
        """ë©”ì„œë“œ ë…¸ë“œë¥¼ ë³‘ë ¬ë¡œ ë¶„ì„í•©ë‹ˆë‹¤ - íŒŒë¼ë¯¸í„°/ë°˜í™˜ íƒ€ì… ì¶”ì¶œ."""
        if not method_nodes:
            return

        log_process("UNDERSTAND", "METHOD", f"ğŸ” ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ ë¶„ì„ ì‹œì‘: {len(method_nodes)}ê°œ ë…¸ë“œ")
        semaphore = asyncio.Semaphore(METHOD_CONCURRENCY)

        async def worker(node: StatementNode):
            async with semaphore:
                try:
                    # ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ + ASSIGNMENT êµ¬ë¬¸ë§Œ í¬í•¨ëœ ì½”ë“œ ì „ë‹¬
                    code_for_analysis = node.get_code_with_assigns_only() if node.has_children else node.get_raw_code()
                    result = await asyncio.to_thread(
                        understand_method,
                        code_for_analysis,
                        self.api_key,
                        self.locale,
                    )
                except Exception as exc:
                    log_process("UNDERSTAND", "METHOD", f"âŒ ë©”ì„œë“œ ë¶„ì„ ì˜¤ë¥˜: ë¼ì¸ {node.start_line}", logging.ERROR, exc)
                    return

                queries = self._build_method_queries(node, result)
                if queries:
                    await self._send_static_queries(queries, node.end_line)

        await asyncio.gather(*(worker(n) for n in method_nodes))
        log_process("UNDERSTAND", "METHOD", f"âœ… ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ ë¶„ì„ ì™„ë£Œ")

    def _build_method_queries(self, node: StatementNode, analysis: Dict[str, Any]) -> List[str]:
        """ë©”ì„œë“œ ë¶„ì„ ê²°ê³¼ë¥¼ Neo4j ì¿¼ë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not isinstance(analysis, dict):
            return []

        queries: List[str] = []
        
        method_name = escape_for_cypher(analysis.get("method_name") or "")
        return_type = escape_for_cypher(analysis.get("return_type") or "void")
        visibility = escape_for_cypher(analysis.get("visibility") or "public")
        is_static = "true" if analysis.get("is_static") else "false"
        method_kind = escape_for_cypher(analysis.get("method_type") or "normal")
        parameters = analysis.get("parameters") or []
        dependencies = analysis.get("dependencies") or []

        # METHOD ë…¸ë“œì— ì‹œê·¸ë‹ˆì²˜ ì •ë³´ ì €ì¥ (nameë„ methodNameìœ¼ë¡œ ì„¤ì •)
        queries.append(
            f"MATCH (m:{node.node_type} {{startLine: {node.start_line}, {self.node_base_props}}})\n"
            f"SET m.name = '{method_name}', m.return_type = '{return_type}', "
            f"m.visibility = '{visibility}', m.is_static = {is_static}, "
            f"m.method_type = '{method_kind}'\n"
            f"RETURN m"
        )

        # ê° íŒŒë¼ë¯¸í„°ë¥¼ ê°œë³„ Parameter ë…¸ë“œë¡œ ì €ì¥
        for idx, param in enumerate(parameters):
            param_name = escape_for_cypher(param.get("name") or "")
            param_type = escape_for_cypher(param.get("type") or "")
            if not param_name:
                continue
            queries.append(
                f"MATCH (m:{node.node_type} {{startLine: {node.start_line}, {self.node_base_props}}})\n"
                # Parameter ë…¸ë“œ ì†ì„±ëª…ì€ snake_caseë¡œ í†µì¼
                f"MERGE (p:Parameter {{name: '{param_name}', method_start_line: {node.start_line}, {self.node_base_props}}})\n"
                f"SET p.type = '{param_type}', p.index = {idx}\n"
                f"MERGE (m)-[r:HAS_PARAMETER]->(p)\n"
                f"RETURN m, p, r"
            )

        # ì˜ì¡´ ê´€ê³„ ìƒì„± (DEPENDENCY) - ì—°ê´€ ê´€ê³„ê°€ ì—†ì„ ë•Œë§Œ
        # íƒ€ê²Ÿ ë…¸ë“œ: DBMS íŒ¨í„´ - OPTIONAL MATCHë¡œ ê¸°ì¡´ ë…¸ë“œ ì°¾ê³ , ì—†ìœ¼ë©´ CREATE
        for dep in dependencies:
            target_type = escape_for_cypher(dep.get("target_class") or "")
            usage = escape_for_cypher(dep.get("usage") or "parameter")
            # Noneì„ Falseë¡œ ì •ê·œí™”í•˜ì—¬ boolean ê°’ë§Œ í—ˆìš© (ë‹¤ë¥¸ boolean í•„ë“œë“¤ê³¼ ì¼ê´€ì„± ìœ ì§€)
            is_value_object_cypher = "true" if dep.get("is_value_object") else "false"

            if not target_type:
                continue

            src_match = f"MATCH (src:{node.class_kind or 'CLASS'} {{startLine: {node.parent.start_line if node.parent else node.start_line}, {self.node_base_props}}})"
            queries.append(
                f"{src_match}\n"
                f"OPTIONAL MATCH (existing)\n"
                f"WHERE (existing:CLASS OR existing:INTERFACE OR existing:ENUM OR existing:TEMP)\n"
                f"  AND toLower(existing.class_name) = toLower('{target_type}')\n"
                f"  AND existing.user_id = '{self.user_id}'\n"
                f"  AND existing.project_name = '{self.project_name}'\n"
                f"WITH src, existing\n"
                f"FOREACH(_ IN CASE WHEN existing IS NULL THEN [1] ELSE [] END |\n"
                f"    CREATE (:TEMP {{class_name: '{target_type}', name: '{target_type}', user_id: '{self.user_id}', project_name: '{self.project_name}'}}))\n"
                f"WITH src\n"
                f"MATCH (dst)\n"
                f"WHERE (dst:CLASS OR dst:INTERFACE OR dst:ENUM OR dst:TEMP)\n"
                f"  AND toLower(dst.class_name) = toLower('{target_type}')\n"
                f"  AND dst.user_id = '{self.user_id}'\n"
                f"  AND dst.project_name = '{self.project_name}'\n"
                f"  AND src <> dst\n"  # ìê¸° ìì‹  ì˜ì¡´ ë°©ì§€
                f"  AND NOT (src)-[:ASSOCIATION|COMPOSITION]->(dst)\n"
                f"MERGE (src)-[r:DEPENDENCY {{usage: '{usage}', source_member: '{method_name}'}}]->(dst)\n"
                f"SET r.is_value_object = {is_value_object_cypher}\n"
                f"RETURN src, dst, r"
            )

        # í•„ë“œ í• ë‹¹ íŒ¨í„´ì— ë”°ë¥¸ ì—°ê´€ ê´€ê³„ ì„¸ë¶„í™” (ASSOCIATION â†’ COMPOSITION)
        field_assignments = analysis.get("field_assignments") or []
        src_start_line = node.parent.start_line if node.parent else node.start_line
        for assign in field_assignments:
            field_name = escape_for_cypher(assign.get("field_name") or "")
            value_source = assign.get("value_source") or ""

            if not field_name or not value_source:
                continue

            # value_sourceê°€ "new"ì¸ ê²½ìš°ì—ë§Œ COMPOSITIONìœ¼ë¡œ ë³€ê²½ (parameterëŠ” ASSOCIATION ìœ ì§€)
            if value_source == "new":
                # FIELD ë…¸ë“œì˜ target_classê°€ ìˆìœ¼ë©´ (í´ë˜ìŠ¤ íƒ€ì… í•„ë“œ) ê¸°ì¡´ ASSOCIATIONì„ COMPOSITIONìœ¼ë¡œ ë³€ê²½
                queries.append(
                    f"MATCH (field:FIELD {{name: '{field_name}', {self.node_base_props}}})\n"
                    f"WHERE field.target_class IS NOT NULL\n"
                    f"MATCH (src:{node.class_kind or 'CLASS'} {{startLine: {src_start_line}, {self.node_base_props}}})"
                    f"-[r:ASSOCIATION {{source_member: '{field_name}'}}]->(dst)\n"
                    f"WITH src, dst, COALESCE(r.multiplicity, '1') AS mult, r\n"
                    f"DELETE r\n"
                    f"MERGE (src)-[r2:COMPOSITION {{source_member: '{field_name}', multiplicity: mult}}]->(dst)\n"
                    f"RETURN src, dst, r2"
                )

        return queries


# ì´ì „ ë²„ì „ í˜¸í™˜ì„ ìœ„í•œ ë³„ì¹­
Analyzer = FrameworkAnalyzer
