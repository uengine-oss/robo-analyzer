import logging
import textwrap

from prompt.convert_service_prompt import convert_service_code
from prompt.convert_summarized_service_prompt import convert_summarized_code
from understand.neo4j_connection import Neo4jConnection
from util.exception import ConvertingError
from util.utility_tool import extract_used_query_methods, collect_variables_in_range



class ServicePreprocessor:
    """
    ì—­í• :
      - ì„œë¹„ìŠ¤ ì „ì²˜ë¦¬ ì „ì²´ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬
      - ë‹¨ì¼ ì»¨í…ìŠ¤íŠ¸ ëˆ„ì (ë©”ëª¨ë¦¬) ë°©ì‹ìœ¼ë¡œ ìë°” ì½”ë“œ ìƒì„± íë¦„ êµ¬ì„±
      - ëŒ€ìš©ëŸ‰ ë¶€ëª¨(í† í°â‰¥1500, ìì‹ ë³´ìœ ) ìŠ¤ì¼ˆë ˆí†¤ ê´€ë¦¬ ë° ìì‹ ì½”ë“œ/ìŠ¤ì¼ˆë ˆí†¤ ë‹¨ì¼ ì¹˜í™˜ ì²˜ë¦¬
      - í† í° ì„ê³„(ê¸°ë³¸ 1500) ë„ë‹¬ ì‹œ LLM ë¶„ì„ ìˆ˜í–‰(ë³€ìˆ˜/JPA ì¶”ì¶œ), DB ì—…ë°ì´íŠ¸ëŠ” í•˜ì§€ ì•ŠìŒ

    ë§¤ê°œë³€ìˆ˜:
      - traverse_nodes(list[dict]): ê·¸ë˜í”„ì—ì„œ ì¡°íšŒí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë…¸ë“œ ë ˆì½”ë“œë“¤({'n','r','m','nType'} ë“±)
      - variable_nodes(list[dict]): ë³€ìˆ˜ ë²”ìœ„ ì •ë³´ë¥¼ ë‹´ì€ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸({'v': Variable})
      - connection(Neo4jConnection): Neo4j ì—°ê²° ê°ì²´
      - command_class_variable(dict): ì»¤ë§¨ë“œ í´ë˜ìŠ¤ í•„ë“œ ì •ì˜ ì •ë³´
      - service_skeleton(str): ì„œë¹„ìŠ¤ ë©”ì„œë“œ ìŠ¤ì¼ˆë ˆí†¤ í…œí”Œë¦¿
      - query_method_list(list|dict): ì‚¬ìš© ê°€ëŠ¥í•œ JPA ì¿¼ë¦¬ ë©”ì„œë“œ ëª©ë¡
      - object_name(str): ì˜¤ë¸Œì íŠ¸(íŒ¨í‚¤ì§€)ëª…
      - procedure_name(str): í”„ë¡œì‹œì €ëª…
      - sequence_methods(list): ì‹œí€€ìŠ¤ ë©”ì„œë“œ ëª©ë¡
      - user_id(str): ì‚¬ìš©ì ID
      - api_key(str): LLM API í‚¤
      - locale(str): ë¡œì¼€ì¼
    """

    TOKEN_THRESHOLD = 1500
    CODE_PLACEHOLDER = "...code..."
    DML_TYPES = ["SELECT", "INSERT", "UPDATE", "DELETE", "FETCH", "MERGE", "JOIN", "ALL_UNION", "UNION"]

    def __init__(self, traverse_nodes: list, variable_nodes: list, connection: Neo4jConnection,
                 command_class_variable: dict, service_skeleton: str, query_method_list: dict,
                 object_name: str, procedure_name: str, sequence_methods: list, user_id: str,
                 api_key: str, locale: str) -> None:
        self.traverse_nodes = traverse_nodes
        self.variable_nodes = variable_nodes
        self.connection = connection
        self.command_class_variable = command_class_variable
        self.service_skeleton = service_skeleton
        self.query_method_list = query_method_list
        self.object_name = object_name
        self.procedure_name = procedure_name
        self.sequence_methods = sequence_methods
        self.user_id = user_id
        self.api_key = api_key
        self.locale = locale

        # ìƒíƒœ ê°’
        self.merged_java_code = ""  
        self.total_tokens = 0
        self.used_variables = []
        self.used_query_method_dict = {}
        self.tracking_variables = {}
        self.current_parent = None 
        self.java_buffer = ""
        self.sp_code = ""
        self.sp_range = {"startLine": None, "endLine": None}

    #==================================================================
    # ë¡œê¹…/ì¶œë ¥
    #==================================================================
    def _log_node_info(self, record: dict) -> None:
        """
        ì—­í• :
          - ë…¸ë“œì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ë¡œê·¸ë¡œ ë‚¨ê¹€(ê°€ë…ì„± í–¥ìƒ)

        ë§¤ê°œë³€ìˆ˜:
          - record(dict): ìˆœíšŒ ì¤‘ì¸ ë ˆì½”ë“œ(í‚¤ 'n','r','m','nType' ë“± í¬í•¨ ê°€ëŠ¥)
        """
        start_node = record['n']
        raw_name = str(start_node.get('name', '') or '')
        name = raw_name.split('[')[0] if '[' in raw_name else raw_name
        token = int(start_node.get('token', 0) or 0)
        start_line = int(start_node.get('startLine', 0) or 0)
        end_line = int(start_node.get('endLine', 0) or 0)
        rel = record.get('r')
        relationship = rel[1] if rel else 'NEXT'

        logging.info("---------------------- [Node] ------------------------")
        logging.info(f"íƒ€ì…:{name} ë¼ì¸:{start_line}~{end_line} í† í°:{token} ê´€ê³„:{relationship}")

    #==================================================================
    # ëŒ€ìš©ëŸ‰ ìŠ¤ì¼ˆë ˆí†¤ ì²˜ë¦¬
    #==================================================================
    async def _generate_large_node_code(self, summarized_code: str) -> str:
        """
        ì—­í• :
          - ìš”ì•½ëœ ìì‹ ì½”ë“œê°€ í¬í•¨ëœ í° ë…¸ë“œì˜ ìš”ì•½ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ìë°” ìŠ¤ì¼ˆë ˆí†¤ì„ ìƒì„±

        ë§¤ê°œë³€ìˆ˜:
          - summarized_code(str): ìì‹ì´ "...code..." ë“±ìœ¼ë¡œ ìš”ì•½ëœ ì½”ë“œ ë¬¸ìì—´

        ë°˜í™˜ê°’:
          - str: ìƒì„±ëœ ìë°” ìŠ¤ì¼ˆë ˆí†¤ ì½”ë“œ
        """
        analysis_result = convert_summarized_code(
            summarized_code, 
            self.service_skeleton,
            self.used_variables,
            self.command_class_variable,
            self.used_query_method_dict,
            self.sequence_methods,
            self.api_key,
            self.locale)
        return analysis_result['code']

    def _insert_into_parent(self, child_start: int, child_code: str) -> bool:
        """
        ì—­í• :
          - í˜„ì¬ ë¶€ëª¨ ìŠ¤ì¼ˆë ˆí†¤ì˜ ì¼ë°˜ í”Œë ˆì´ìŠ¤í™€ë”("...code...")ë¥¼ 1íšŒ ì¹˜í™˜

        ë§¤ê°œë³€ìˆ˜:
          - child_start(int): ì‚¬ìš©ë˜ì§€ ì•ŠìŒ(í˜¸ì¶œ ì‹œ 0 ì „ë‹¬), ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ìš©
          - child_code(str): ë¶€ëª¨ ë‚´ë¶€ì— ì‚½ì…í•  ìì‹(ë˜ëŠ” ëˆ„ì ëœ) ì½”ë“œ ë¬¸ìì—´

        ë°˜í™˜ê°’:
          - bool: ì¹˜í™˜ ì„±ê³µ ì—¬ë¶€
        """
        if not self.current_parent:
            return False
        placeholder = self.CODE_PLACEHOLDER
        self.current_parent['code'] = self.current_parent['code'].replace(
            placeholder, f"\n{textwrap.indent(child_code, '    ')}", 1
        )
        return True

    async def _finalize_parent_if_passed(self, current_start_line: int, relationship: str) -> None:
        """
        ì—­í• :
          - í˜„ì¬ ë…¸ë“œê°€ ë¶€ëª¨ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ëŠ”ì§€ íŒë‹¨í•˜ê³ , ë²—ì–´ë‚¬ë‹¤ë©´ ë¶€ëª¨ë¥¼ ë§ˆë¬´ë¦¬

        ë§¤ê°œë³€ìˆ˜:
          - current_start_line(int): í˜„ì¬ ë…¸ë“œì˜ ì‹œì‘ ë¼ì¸
          - relationship(str): í˜„ì¬ ë ˆì½”ë“œì˜ ê´€ê³„ íƒ€ì…(ì£¼ë¡œ 'NEXT')
        """
        if not self.current_parent:
            return
        if relationship == 'NEXT' and current_start_line > self.current_parent['end']:
            logging.info(f"ğŸ§© ë¶€ëª¨ ê²½ê³„ í†µê³¼ë¡œ ë§ˆë¬´ë¦¬ íŠ¸ë¦¬ê±°: ë¶€ëª¨={self.current_parent['start']}~{self.current_parent['end']} ë‹¤ìŒë…¸ë“œì‹œì‘={current_start_line}")
            # ë¶€ëª¨ ì¢…ë£Œ ì „ì— ë‚¨ì€ sp_codeê°€ ìˆìœ¼ë©´ ë¶„ì„í•´ì„œ java_bufferì— ë°˜ì˜
            if self.sp_code:
                await self._analyze_and_update()
            await self._finalize_current_parent()

    async def _finalize_current_parent(self) -> None:
        """
        ì—­í• :
          - í˜„ì¬ ë¶€ëª¨ì˜ "...code..."ì— ëˆ„ì ëœ ìì‹ ì½”ë“œ(java_buffer)ë¥¼ 1íšŒ ì¹˜í™˜í•˜ê³ ,
            ì™„ì„±ëœ ë¶€ëª¨ ì½”ë“œë¥¼ ìµœì¢… ì»¨í…ìŠ¤íŠ¸ì— ë³‘í•©
        """
        if not self.current_parent:
            return
        if self.java_buffer:
            self._insert_into_parent(0, self.java_buffer.strip('\n'))
        self.merged_java_code += f"\n{self.current_parent['code']}"
        self.total_tokens += self.TOKEN_THRESHOLD
        self.current_parent = None
        self.java_buffer = ""
        logging.info("ğŸ§© ë¶€ëª¨ ë³‘í•© ì™„ë£Œ (í† í° ì„ê³„ ì¬ì¡°ì •)")

    # (ì»¨í…ìŠ¤íŠ¸ ë²”ìœ„ ê´€ë¦¬ëŠ” sp_rangeë¡œë§Œ ìˆ˜í–‰)

    #==================================================================
    # ëŒ€ìš©ëŸ‰ ë…¸ë“œ/ì¼ë°˜ ë…¸ë“œ ì²˜ë¦¬
    #==================================================================
    async def _handle_large_node(self, summarized_code: str, start_line: int, end_line: int, token: int) -> None:
        """
        ì—­í• :
          - í° ë…¸ë“œ(ìì‹ ìˆìŒ, í† í° ì„ê³„ ì´ìƒ)ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìŠ¤ì¼ˆë ˆí†¤ì„ ì ìš©

        ë§¤ê°œë³€ìˆ˜:
          - summarized_code(str): ìš”ì•½ ì½”ë“œ
          - start_line(int): ë…¸ë“œ ì‹œì‘ ë¼ì¸
          - end_line(int): ë…¸ë“œ ë ë¼ì¸
          - token(int): ë…¸ë“œ í† í° ìˆ˜
        """
        logging.info(f"ğŸ”€ ë¶„ê¸°: ëŒ€ìš©ëŸ‰ ë…¸ë“œ lines={start_line}~{end_line} í† í°={token}")
        skeleton = await self._generate_large_node_code(summarized_code)
        # ë£¨íŠ¸ ë¶€ëª¨ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ë…¸ë“œë¥¼ ë¶€ëª¨ë¡œ ì„¤ì •, ìˆìœ¼ë©´ ì¦‰ì‹œ ë¶€ëª¨ì— ì¹˜í™˜
        if not self.current_parent:
            self.current_parent = {'start': start_line, 'end': end_line, 'code': skeleton}
        else:
            self._insert_into_parent(0, skeleton)
        self.total_tokens += token
        logging.info(f"ğŸ“¦ ëˆ„ì : total_tokens={self.total_tokens}")

    def _handle_small_or_leaf_node(self, node_code: str, token: int, start_line: int, end_line: int) -> None:
        """
        ì—­í• :
          - ì‘ì€ ë…¸ë“œ ë˜ëŠ” ìì‹ ì—†ëŠ” í° ë…¸ë“œë¥¼ ì²˜ë¦¬(ë¶€ëª¨ ì§„í–‰ ì¤‘ì´ë©´ ë²„í¼, ì•„ë‹ˆë©´ ì¦‰ì‹œ ëˆ„ì )

        ë§¤ê°œë³€ìˆ˜:
          - node_code(str): ìë°” ì½”ë“œ ì¡°ê°
          - token(int): í† í° ìˆ˜
        """
        # ì‘ì€/ìì‹ì—†ìŒ ë…¸ë“œëŠ” ì›ë³¸ì„ sp_codeì— ëˆ„ì í•˜ì—¬ ì„ê³„ ì‹œ LLM ë³€í™˜
        logging.info(f"ğŸ”€ ë¶„ê¸°: ì†Œí˜•/ë¦¬í”„ ë…¸ë“œ lines={start_line}~{end_line} í† í°={token}")
        self.sp_code += f"\n{node_code}"
        self.total_tokens += token
        if self.sp_range['startLine'] is None or start_line < self.sp_range['startLine']:
            self.sp_range['startLine'] = start_line
        if self.sp_range['endLine'] is None or end_line > self.sp_range['endLine']:
            self.sp_range['endLine'] = end_line
        logging.info(f"ğŸ“¦ ëˆ„ì : total_tokens={self.total_tokens} ë²”ìœ„={self.sp_range['startLine']}~{self.sp_range['endLine']}")

    #==================================================================
    # ë¶„ì„ ë° ë³€ìˆ˜/JPA ì—…ë°ì´íŠ¸
    #==================================================================
    async def _maybe_analyze(self) -> None:
        """
        ì—­í• :
          - í† í° ì„ê³„ ë„ë‹¬ ì‹œ LLM ë¶„ì„ ìˆ˜í–‰(ë³€ìˆ˜/JPA ìˆ˜ì§‘ í›„ ë¶„ì„ ì‹¤í–‰)
        """
        if self.total_tokens >= self.TOKEN_THRESHOLD:
            logging.info(f"ğŸ¤– ë¶„ì„ íŠ¸ë¦¬ê±°: total_tokens={self.total_tokens} ë²”ìœ„={self.sp_range['startLine']}~{self.sp_range['endLine']}")
            await self._analyze_and_update()

    #==================================================================
    # ë¶„ì„/ì—…ë°ì´íŠ¸
    #==================================================================
    async def _update_variables(self, analysis_result: dict) -> None:
        """LLM ë¶„ì„ ê²°ê³¼ì˜ ë³€ìˆ˜ ì¶”ì  ì •ë³´ë¥¼ ë©”ëª¨ë¦¬ì—ë§Œ ë°˜ì˜í•©ë‹ˆë‹¤(DB ë¯¸ë°˜ì˜)."""
        variables_info = analysis_result['analysis'].get('variables', {})
        for var_name, var_info in variables_info.items():
            self.tracking_variables[var_name] = var_info

    async def _analyze_and_update(self) -> None:
        """
        ì—­í• :
          - í˜„ì¬ ëˆ„ì  ì»¨í…ìŠ¤íŠ¸ë¡œ LLM ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , ë³€ìˆ˜/JPA ìˆ˜ì§‘ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
            ë³€ìˆ˜ ì¶”ì  ìƒíƒœë§Œ ë©”ëª¨ë¦¬ì— ë°˜ì˜
        """
        if not self.sp_code or self.sp_range['startLine'] is None or self.sp_range['endLine'] is None:
            return
        start_line_ctx = self.sp_range['startLine']
        end_line_ctx = self.sp_range['endLine']
        logging.info(f"ğŸ¤– ë¶„ì„ ì‹œì‘: ë²”ìœ„={start_line_ctx}~{end_line_ctx} í† í°={self.total_tokens}")

        try:
            collected = await collect_variables_in_range(self.variable_nodes, start_line_ctx, end_line_ctx)
            self.used_variables = [
                {**v, 'role': self.tracking_variables.get(v['name'], '')}
                for v in collected
            ]
        except Exception as _e:
            logging.debug(f"ë³€ìˆ˜ ìˆ˜ì§‘ ìŠ¤í‚µ: {_e}")

        try:
            self.used_query_method_dict = await extract_used_query_methods(
                start_line_ctx, end_line_ctx, self.query_method_list, {}
            )
        except Exception as _e:
            logging.debug(f"JPA ìˆ˜ì§‘ ìŠ¤í‚µ: {_e}")

        analysis_result = convert_service_code(
            self.sp_code,
            self.service_skeleton,
            self.used_variables,
            self.command_class_variable,
            self.used_query_method_dict,
            self.sequence_methods,
            self.api_key,
            self.locale
        )
        await self._update_variables(analysis_result)
        # ìƒì„±ëœ ìë°” ì½”ë“œë¥¼ ëˆ„ì  (ë¶€ëª¨ ì§„í–‰ ì¤‘ì´ë©´ java_buffer, ì•„ë‹ˆë©´ merged_java_code)
        generated_java = analysis_result.get('analysis', {}).get('code', '') or ''
        if generated_java:
            if self.current_parent:
                self.java_buffer += f"\n{generated_java}"
                logging.info("ğŸ”— ë³‘í•©: ë¶€ëª¨ í™œì„± â†’ java_buffer")
            else:
                self.merged_java_code += f"\n{generated_java}"
                logging.info("ğŸ”— ë³‘í•©: ë¶€ëª¨ ì—†ìŒ â†’ merged_java_code")

        # ì„ê³„ ì´ˆê¸°í™”
        self.total_tokens = 0
        self.used_variables.clear()
        self.used_query_method_dict.clear()
        self.sp_code = ""
        self.sp_range = {"startLine": None, "endLine": None}
        logging.info("ğŸ¤– ë¶„ì„ ì¢…ë£Œ: ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”")

    #==================================================================
    # ë©”ì¸ ì²˜ë¦¬
    #==================================================================
    async def process(self) -> None:
        """
        ì—­í• :
          - ì „ì²´ ë…¸ë“œë¥¼ ìˆœíšŒí•˜ë©° ë‹¨ì¼ ì»¨í…ìŠ¤íŠ¸ ëˆ„ì ê³¼ ëŒ€ìš©ëŸ‰ ìŠ¤ì¼ˆë ˆí†¤ ë³‘í•©, ì„ê³„ ë¶„ì„ íŠ¸ë¦¬ê±°ë¥¼ ìˆ˜í–‰
        """
        logging.info(f"ğŸ“‹ ì²˜ë¦¬ ì‹œì‘: object={self.object_name} procedure={self.procedure_name}")
        for record in self.traverse_nodes:
            start_node = record['n']
            type = start_node.get('labels', 'UNKNOWN')
            has_children = bool(start_node.get('has_children', False))
            token = int(start_node.get('token', 0) or 0)
            start_line = int(start_node.get('startLine', 0) or 0)
            end_line = int(start_node.get('endLine', 0) or 0)
            rel = record.get('r')
            relationship = rel[1] if rel else 'NEXT'

            # ë…¸ë“œ ì •ë³´ ì¶œë ¥
            self._log_node_info(record)

            # ë¶€ëª¨ ì¢…ë£Œ íŒë‹¨ ë° ë§ˆë¬´ë¦¬
            await self._finalize_parent_if_passed(start_line, relationship)

            # ë¶„ê¸°: í° ë¶€ëª¨ vs ì¼ë°˜ ë…¸ë“œ(DML ì œì™¸)
            if token >= self.TOKEN_THRESHOLD and has_children and start_node and type not in self.DML_TYPES:
                await self._handle_large_node(start_node.get('summarized_code', '') or '', start_line, end_line, token)
            else:
                # ì‘ì€/ìì‹ì—†ìŒ ë…¸ë“œ ì²˜ë¦¬
                self._handle_small_or_leaf_node(start_node.get('node_code', ''), token, start_line, end_line)

            await self._maybe_analyze()

        # ë‚¨ì•„ ìˆëŠ” ë¶€ëª¨ ì •ë¦¬(1íšŒ ì¹˜í™˜ í›„ ë³‘í•©)
        if self.current_parent:
            # ë¶€ëª¨ ë§ˆë¬´ë¦¬ ì „ì— ë‚¨ì€ pending ë³€í™˜ì„ ë¨¼ì € ì²˜ë¦¬
            if self.sp_code:
                await self._analyze_and_update()
            await self._finalize_current_parent()

        # ë‚¨ì€ ë³€í™˜ ëŒ€ê¸° ì½”ë“œê°€ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ë¶„ì„ ì‹¤í–‰
        if self.sp_code:
            await self._analyze_and_update()
        logging.info("âœ… ì²˜ë¦¬ ì™„ë£Œ")


async def start_service_preprocessing(service_skeleton: str, command_class_variable: dict, procedure_name: str,
                                      query_method_list: dict, object_name: str, sequence_methods: list, user_id: str,
                                      api_key: str, locale: str) -> tuple:
    """
    ì—­í• :
      - ì„œë¹„ìŠ¤ ì½”ë“œ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
      - service_skeleton(str): ì„œë¹„ìŠ¤ ë©”ì„œë“œ ìŠ¤ì¼ˆë ˆí†¤ í…œí”Œë¦¿
      - command_class_variable(dict): ì»¤ë§¨ë“œ í´ë˜ìŠ¤ í•„ë“œ ì •ì˜ ì •ë³´
      - procedure_name(str): í”„ë¡œì‹œì € ì´ë¦„
      - query_method_list(dict): ì‚¬ìš© ê°€ëŠ¥í•œ ì¿¼ë¦¬ ë©”ì„œë“œ ëª©ë¡
      - object_name(str): íŒ¨í‚¤ì§€/í”„ë¡œì‹œì € ì´ë¦„
      - sequence_methods(list): ì‹œí€€ìŠ¤ ë©”ì„œë“œ ëª©ë¡
      - user_id(str): ì‚¬ìš©ì ID
      - api_key(str): LLM API í‚¤
      - locale(str): ë¡œì¼€ì¼

    ë°˜í™˜ê°’:
      - (variable_nodes, merged_java_code): ë³€ìˆ˜ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ì™€ ìµœì¢… ë³‘í•©ëœ ìë°” ì½”ë“œ
    """
    
    connection = Neo4jConnection() 
    logging.info(f"[{object_name}] {procedure_name} í”„ë¡œì‹œì €ì˜ ì„œë¹„ìŠ¤ ì½”ë“œ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    try:
        node_query = [
            f"""
            MATCH (p)
            WHERE p.object_name = '{object_name}'
                AND p.procedure_name = '{procedure_name}'
                AND p.user_id = '{user_id}'
                AND (p:FUNCTION OR p:PROCEDURE OR p:CREATE_PROCEDURE_BODY OR p:TRIGGER)
            MATCH (p)-[:PARENT_OF]->(c)
            WHERE NOT (c:ROOT OR c:Variable OR c:DECLARE OR c:Table OR c:SPEC)
            MATCH path = (c)-[:PARENT_OF*0..]->(n)
            WHERE NOT (n:ROOT OR n:Variable OR n:DECLARE OR n:Table OR n:SPEC)
            OPTIONAL MATCH (n)-[r]->(m)
            WHERE m.object_name = '{object_name}'
                AND m.user_id = '{user_id}'
                AND NOT (m:ROOT OR m:Variable OR m:DECLARE OR m:Table OR m:SPEC)
                AND NOT type(r) CONTAINS 'CALL'
                AND NOT type(r) CONTAINS 'WRITES'
                AND NOT type(r) CONTAINS 'FROM'
            RETURN DISTINCT n, r, m ORDER BY n.startLine
            """,
            f"""
            MATCH (n)
            WHERE n.object_name = '{object_name}'
            AND n.procedure_name = '{procedure_name}'
            AND n.user_id = '{user_id}'
            AND (n:DECLARE)
            MATCH (n)-[r:SCOPE]->(v:Variable)
            RETURN v
            """
        ]

        service_nodes, variable_nodes = await connection.execute_queries(node_query)        

        processor = ServicePreprocessor(
            service_nodes, 
            variable_nodes,
            connection, 
            command_class_variable, 
            service_skeleton, 
            query_method_list, 
            object_name, 
            procedure_name,
            sequence_methods,
            user_id,
            api_key,
            locale
        )
        await processor.process()

        final_code = processor.merged_java_code.strip()
        logging.info(f"[{object_name}] {procedure_name} í”„ë¡œì‹œì €ì˜ ì„œë¹„ìŠ¤ ì½”ë“œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n")
        return variable_nodes, final_code
    except ConvertingError: 
        raise
    except Exception as e:
        err_msg = f"(ì „ì²˜ë¦¬) ì„œë¹„ìŠ¤ ì½”ë“œ ìƒì„± ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        logging.error(err_msg)
        raise ConvertingError(err_msg)
    finally:
        await connection.close()