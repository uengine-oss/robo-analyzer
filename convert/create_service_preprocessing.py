import logging
import textwrap
from prompt.convert_service_prompt import convert_service_code, convert_exception_code
from prompt.convert_summarized_service_prompt import convert_summarized_code
from understand.neo4j_connection import Neo4jConnection
from util.exception import ConvertingError
from util.utility_tool import extract_used_query_methods, collect_variables_in_range, build_java_base_path, save_file, convert_to_pascal_case


# ----- ìƒìˆ˜ ì •ì˜ -----
TOKEN_THRESHOLD = 1000
CODE_PLACEHOLDER = "...code..."
DML_TYPES = frozenset(["SELECT", "INSERT", "UPDATE", "DELETE", "FETCH", "MERGE", "JOIN", "ALL_UNION", "UNION"])


# ----- ì„œë¹„ìŠ¤ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ -----
class ServicePreprocessingGenerator:
    """
    ì„œë¹„ìŠ¤ ì „ì²˜ë¦¬ ì „ì²´ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬
    - ë‹¨ì¼ ì»¨í…ìŠ¤íŠ¸ ëˆ„ì  ë°©ì‹ìœ¼ë¡œ ìë°” ì½”ë“œ ìƒì„±
    - ëŒ€ìš©ëŸ‰ ë¶€ëª¨(í† í°â‰¥1000, ìì‹ ë³´ìœ ) ìŠ¤ì¼ˆë ˆí†¤ ê´€ë¦¬
    - í† í° ì„ê³„ ë„ë‹¬ ì‹œ LLM ë¶„ì„ ìˆ˜í–‰
    """
    __slots__ = (
        'traverse_nodes', 'variable_nodes', 'command_class_variable', 'service_skeleton',
        'query_method_list', 'folder_name', 'file_name', 'procedure_name', 'sequence_methods',
        'user_id', 'api_key', 'locale', 'project_name',
        'merged_java_code', 'total_tokens', 'tracking_variables', 'current_parent', 
        'java_buffer', 'sp_code_parts', 'sp_start', 'sp_end',
        'pending_try_mode'
    )

    def __init__(self, traverse_nodes: list, variable_nodes: list, command_class_variable: dict,
                 service_skeleton: str, query_method_list: dict, folder_name: str, file_name: str,
                 procedure_name: str, sequence_methods: list, user_id: str, api_key: str, locale: str, project_name: str = "demo"):
        self.traverse_nodes = traverse_nodes
        self.variable_nodes = variable_nodes
        self.command_class_variable = command_class_variable
        self.service_skeleton = service_skeleton
        self.query_method_list = query_method_list
        self.folder_name = folder_name
        self.file_name = file_name
        self.procedure_name = procedure_name
        self.sequence_methods = sequence_methods
        self.user_id = user_id
        self.api_key = api_key
        self.locale = locale
        self.project_name = project_name or "demo"

        # ìƒíƒœ ì´ˆê¸°í™”
        self.merged_java_code = ""
        self.total_tokens = int(0)  # ëª…ì‹œì  int íƒ€ì…
        self.tracking_variables = {}
        self.current_parent = None
        self.java_buffer = ""
        self.sp_code_parts = []  # ë¬¸ìì—´ ì—°ê²° ìµœì í™”
        self.sp_start = None
        self.sp_end = None
        
        # TRY-EXCEPTION ì²˜ë¦¬
        self.pending_try_mode = False

    # ----- ê³µê°œ ë©”ì„œë“œ -----

    async def generate(self) -> str:
        """
        ì „ì²´ ë…¸ë“œë¥¼ ìˆœíšŒí•˜ë©° ìë°” ì½”ë“œ ìƒì„±
        
        Returns:
            str: ìµœì¢… ë³‘í•©ëœ ìë°” ì½”ë“œ
        """
        logging.info(f"ğŸ“‹ ë…¸ë“œ ìˆœíšŒ ì‹œì‘")

        # ğŸ¯ ì¤‘ë³µ ì œê±°: ê°™ì€ ë¼ì¸ ë²”ìœ„ëŠ” í•œ ë²ˆë§Œ ì²˜ë¦¬
        seen_nodes = set()
        node_count = 0
        for record in self.traverse_nodes:
            node = record['n']
            node_key = (node.get('startLine'), node.get('endLine'))
            if node_key in seen_nodes:
                continue
            seen_nodes.add(node_key)
            node_count += 1
            await self._process_node(record)

        await self._finalize_remaining()

        logging.info(f"âœ… ì´ {node_count}ê°œ ë…¸ë“œ ì²˜ë¦¬ ì™„ë£Œ\n")
        return self.merged_java_code.strip()

    # ----- ë…¸ë“œ ì²˜ë¦¬ -----

    async def _process_node(self, record: dict) -> None:
        """ë‹¨ì¼ ë…¸ë“œ ì²˜ë¦¬"""
        node = record['n']
        # Neo4j labels() í•¨ìˆ˜ë¡œ ê°€ì ¸ì˜¨ ë ˆì´ë¸” ì‚¬ìš©
        node_labels = record.get('nodeLabels', [])
        node_type = node_labels[0] if node_labels else node.get('name', 'UNKNOWN')
        has_children = bool(node.get('has_children', False))
        token = int(node.get('token', 0) or 0)
        start_line = int(node.get('startLine', 0) or 0)
        end_line = int(node.get('endLine', 0) or 0)
        relationship = record['r'][1] if record.get('r') else 'NEXT'

        # ë…¸ë“œ ì²˜ë¦¬ ë¡œê·¸ (ê°„ê²°í•˜ê²Œ)
        name = node_type.split('[')[0] if '[' in str(node_type) else str(node_type)
        depth = "  " if self.current_parent else ""
        logging.debug(f"{depth}â†’ {name}[{start_line}~{end_line}] í† í°={token}")

        # ğŸš€ TRY ë…¸ë“œ ê°ì§€ â†’ í”Œë˜ê·¸ ì„¤ì •
        if node_type == 'TRY':
            self.pending_try_mode = True
            logging.info(f"  ğŸ”’ TRY ë…¸ë“œ ê°ì§€ â†’ EXCEPTIONê¹Œì§€ merge ë³´ë¥˜")
        
        # ğŸš€ EXCEPTION ë…¸ë“œ ê°ì§€ â†’ ì „ìš© ì²˜ë¦¬
        if node_type == 'EXCEPTION':
            await self._handle_exception_node(node, start_line, end_line)
            return  # EXCEPTION ì²˜ë¦¬ ì™„ë£Œ, ë‹¤ìŒ ë…¸ë“œë¡œ
        
        # ë¶€ëª¨ ê²½ê³„ ì²´í¬
        parent = self.current_parent
        if parent and relationship == 'NEXT' and start_line > parent['end']:
            if self.sp_code_parts:
                await self._analyze_and_merge()
            await self._finalize_parent()

        # ë…¸ë“œ íƒ€ì…ë³„ ì²˜ë¦¬
        if token >= TOKEN_THRESHOLD and has_children and node_type not in DML_TYPES:
            # í° ë…¸ë“œ ì²˜ë¦¬ ì „ì— ìŒ“ì¸ ì‘ì€ ë…¸ë“œë“¤ ë¨¼ì € ë³€í™˜
            if self.sp_code_parts:
                await self._analyze_and_merge()
            
            logging.info(f"  â”Œâ”€ í° ë…¸ë“œ ì§„ì… [{start_line}~{end_line}] (í† í°: {token})")
            await self._handle_large_node(node, start_line, end_line, token)
        else:
            self._handle_small_node(node, start_line, end_line, token)

        # ì„ê³„ê°’ ì²´í¬
        if int(self.total_tokens) >= TOKEN_THRESHOLD:
            logging.info(f"  âš ï¸  í† í° ì„ê³„ê°’ ë„ë‹¬ ({int(self.total_tokens)}) â†’ LLM ë¶„ì„ ì‹¤í–‰")
            await self._analyze_and_merge()

    # ----- ëŒ€ìš©ëŸ‰ ë…¸ë“œ ì²˜ë¦¬ -----

    async def _handle_large_node(self, node: dict, start_line: int, end_line: int, token: int) -> None:
        """ëŒ€ìš©ëŸ‰ ë…¸ë“œ(ìì‹ ìˆìŒ, í† í°â‰¥1000) ì²˜ë¦¬"""
        summarized = (node.get('summarized_code') or '').strip()
        if not summarized:
            return
        

        # í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        used_vars, used_queries = await self._collect_current_context()

        # LLMìœ¼ë¡œ ìŠ¤ì¼ˆë ˆí†¤ ìƒì„±
        result = convert_summarized_code(
            summarized,
            self.service_skeleton,
            used_vars,
            self.command_class_variable,
            used_queries,
            self.sequence_methods,
            self.api_key,
            self.locale
        )
        skeleton = result['code']

        # ë¶€ëª¨ ì„¤ì • ë˜ëŠ” ì‚½ì…
        if not self.current_parent:
            self.current_parent = {'start': start_line, 'end': end_line, 'code': skeleton}
            logging.info(f"  â”‚  ë¶€ëª¨ ì„¤ì • ì™„ë£Œ â†’ ìì‹ ë…¸ë“œ ì²˜ë¦¬ ì‹œì‘")
        else:
            self.current_parent['code'] = self.current_parent['code'].replace(
                CODE_PLACEHOLDER, f"\n{textwrap.indent(skeleton, '    ')}", 1
            )
            logging.info(f"  â”‚  ì¤‘ì²© ë¶€ëª¨ì— ì‚½ì… ì™„ë£Œ")


    # ----- ì†Œí˜• ë…¸ë“œ ì²˜ë¦¬ -----

    def _handle_small_node(self, node: dict, start_line: int, end_line: int, token: int) -> None:
        """ì†Œí˜• ë…¸ë“œ ë˜ëŠ” ë¦¬í”„ ë…¸ë“œ ì²˜ë¦¬"""
        node_code = (node.get('node_code') or '').strip()
        if not node_code:
            return

        # SP ì½”ë“œ ëˆ„ì 
        self.sp_code_parts.append(node_code)
        self.total_tokens = int(self.total_tokens) + int(token)

        # ë²”ìœ„ ì—…ë°ì´íŠ¸
        if self.sp_start is None or start_line < self.sp_start:
            self.sp_start = start_line
        if self.sp_end is None or end_line > self.sp_end:
            self.sp_end = end_line

    # ----- ë³€ìˆ˜/JPA ìˆ˜ì§‘ -----

    async def _collect_current_context(self) -> tuple:
        """í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ë³€ìˆ˜ì™€ ì¿¼ë¦¬ ë©”ì„œë“œ ìˆ˜ì§‘"""
        if not self.sp_start:
            return [], {}

        used_vars = []
        used_queries = {}

        # ë³€ìˆ˜ ìˆ˜ì§‘
        if self.variable_nodes:
            try:
                collected = await collect_variables_in_range(
                    self.variable_nodes, self.sp_start, self.sp_end or self.sp_start
                )
                used_vars = [{**v, 'role': self.tracking_variables.get(v['name'], '')} for v in collected]
            except Exception as e:
                logging.debug(f"ë³€ìˆ˜ ìˆ˜ì§‘ ìŠ¤í‚µ: {e}")

        # JPA ë©”ì„œë“œ ìˆ˜ì§‘
        if self.query_method_list:
            try:
                used_queries = await extract_used_query_methods(
                    self.sp_start, self.sp_end or self.sp_start, self.query_method_list, {}
                )
            except Exception as e:
                logging.debug(f"JPA ìˆ˜ì§‘ ìŠ¤í‚µ: {e}")

        return used_vars, used_queries

    # ----- ë¶€ëª¨ ê´€ë¦¬ -----

    async def _finalize_parent(self) -> None:
        """í˜„ì¬ ë¶€ëª¨ ë§ˆë¬´ë¦¬"""
        if not self.current_parent:
            return
        
        logging.info(f"  â””â”€ í° ë…¸ë“œ ì™„ë£Œ [{self.current_parent['start']}~{self.current_parent['end']}]")

        # ë²„í¼ ì‚½ì…
        if self.java_buffer:
            self.current_parent['code'] = self.current_parent['code'].replace(
                CODE_PLACEHOLDER, f"\n{textwrap.indent(self.java_buffer.strip(), '    ')}", 1
            )

        # ë³‘í•© (TRY ëŒ€ê¸° ì¤‘ì´ë©´ ë³´ë¥˜)
        if not self.pending_try_mode:
            self.merged_java_code += f"\n{self.current_parent['code']}"
            logging.info(f"     âœ“ ë¶€ëª¨ ë…¸ë“œ ë³‘í•© ì™„ë£Œ")
        else:
            logging.info(f"     âœ“ TRY ë¶€ëª¨ ì™„ë£Œ (java_buffer ë³´ê´€, EXCEPTION ëŒ€ê¸°)")

        # ì´ˆê¸°í™”
        self.current_parent = None
        self.java_buffer = ""

    # ----- EXCEPTION ë…¸ë“œ ì „ìš© ì²˜ë¦¬ -----

    async def _handle_exception_node(self, node: dict, start_line: int, end_line: int) -> None:
        """EXCEPTION ë…¸ë“œ ì „ìš© ì²˜ë¦¬: ì „ì²´ ì½”ë“œë¥¼ try-catchë¡œ ê°ì‹¸ëŠ” ì˜ˆì™¸ì²˜ë¦¬ êµ¬ì¡° ìƒì„±
        
        ì²˜ë¦¬ íë¦„:
        1. TRY ë…¸ë“œ ì¡´ì¬: TRY ë¸”ë¡ ì½”ë“œë§Œ ì˜ˆì™¸ì²˜ë¦¬ë¡œ ê°ì‹¸ê¸°
        2. TRY ë…¸ë“œ ë¯¸ì¡´ì¬: ì „ì²´ ë©”ì„œë“œ ì½”ë“œë¥¼ ì˜ˆì™¸ì²˜ë¦¬ë¡œ ê°ì‹¸ê¸°
        
        Args:
            node: EXCEPTION ë…¸ë“œ ë°ì´í„°
            start_line: ì‹œì‘ ë¼ì¸
            end_line: ì¢…ë£Œ ë¼ì¸
        """
        logging.info(f"  âš¡ EXCEPTION ë…¸ë“œ ê°ì§€ â†’ ì˜ˆì™¸ì²˜ë¦¬ êµ¬ì¡° ìƒì„± ì‹œì‘")
        
        # 1. ìŒ“ì¸ ì½”ë“œ ë¨¼ì € ë¶„ì„
        if self.sp_code_parts:
            await self._analyze_and_merge()
        
        # 2. EXCEPTION ë¸”ë¡ì„ Java try-catch êµ¬ì¡°ë¡œ ë³€í™˜
        node_code = (node.get('node_code') or '').strip()
        if not node_code:
            logging.warning(f"     âš ï¸  EXCEPTION ë…¸ë“œ ì½”ë“œê°€ ë¹„ì–´ìˆìŒ")
            return
            
        result = convert_exception_code(node_code, self.api_key, self.locale)
        exception_java_code = result.get('code', '').strip()
        
        if 'CodePlaceHolder' not in exception_java_code:
            logging.warning(f"     âš ï¸  try-catch í…œí”Œë¦¿ì— CodePlaceHolderê°€ ì—†ìŒ")
            return
        
        # 3. ì „ì²´ ì½”ë“œë¥¼ ì˜ˆì™¸ì²˜ë¦¬ë¡œ ê°ì‹¸ê¸°
        if self.pending_try_mode:
            # Case 1: TRY ë…¸ë“œ ì¡´ì¬ â†’ TRY ë¸”ë¡ ì½”ë“œë§Œ ê°ì‹¸ê¸°
            try_block_code = self.java_buffer.strip()
            wrapped_code = exception_java_code.replace('CodePlaceHolder', try_block_code)
            self.merged_java_code += f"\n{wrapped_code}"
            logging.info(f"     âœ“ TRY ë¸”ë¡ ì½”ë“œë¥¼ ì˜ˆì™¸ì²˜ë¦¬ë¡œ ê°ìŒˆ (java_buffer ì‚¬ìš©)")
        else:
            # Case 2: TRY ë…¸ë“œ ë¯¸ì¡´ì¬ â†’ ì „ì²´ ë©”ì„œë“œ ì½”ë“œë¥¼ ê°ì‹¸ê¸°
            entire_code = self.merged_java_code.strip()
            wrapped_code = exception_java_code.replace('CodePlaceHolder', entire_code)
            self.merged_java_code = wrapped_code
            logging.info(f"     âœ“ ì „ì²´ ë©”ì„œë“œ ì½”ë“œë¥¼ ì˜ˆì™¸ì²˜ë¦¬ë¡œ ê°ìŒˆ (merged_java_code ì‚¬ìš©)")
        
        # 4. ìƒíƒœ ì´ˆê¸°í™”
        self.java_buffer = ""
        self.pending_try_mode = False
        logging.info(f"     âœ“ ì˜ˆì™¸ì²˜ë¦¬ ì™„ë£Œ ë° ìƒíƒœ ì´ˆê¸°í™”")

    # ----- ë¶„ì„ ë° ë³‘í•© -----

    async def _analyze_and_merge(self) -> None:
        """LLM ë¶„ì„ ë° ìë°” ì½”ë“œ ë³‘í•©"""
        if not self.sp_code_parts or self.sp_start is None:
            return

        # ë¬¸ìì—´ ì¡°ì¸
        sp_code = '\n'.join(self.sp_code_parts)
        target = "ë¶€ëª¨ë²„í¼" if self.current_parent else "ìµœì¢…ì½”ë“œ"
        logging.info(f"  ğŸ¤– LLM ë¶„ì„ ì‹œì‘: [{self.sp_start}~{self.sp_end}] {len(self.sp_code_parts)}ê°œ íŒŒíŠ¸ (í† í°: {self.total_tokens})")

        # ë³€ìˆ˜ ìˆ˜ì§‘
        used_variables = []
        try:
            collected = await collect_variables_in_range(self.variable_nodes, self.sp_start, self.sp_end)
            used_variables = [{**v, 'role': self.tracking_variables.get(v['name'], '')} for v in collected]
        except Exception as e:
            logging.debug(f"ë³€ìˆ˜ ìˆ˜ì§‘ ìŠ¤í‚µ: {e}")

        # JPA ë©”ì„œë“œ ìˆ˜ì§‘
        used_query_methods = {}
        try:
            used_query_methods = await extract_used_query_methods(
                self.sp_start, self.sp_end, self.query_method_list, {}
            )
        except Exception as e:
            logging.debug(f"JPA ìˆ˜ì§‘ ìŠ¤í‚µ: {e}")

        # LLM ë¶„ì„ (ì¼ë°˜ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©)
        result = convert_service_code(
            sp_code,
            self.service_skeleton,
            used_variables,
            self.command_class_variable,
            used_query_methods,
            self.sequence_methods,
            self.api_key,
            self.locale,
            self.current_parent['code'] if self.current_parent else ""
        )

        # ë³€ìˆ˜ ì¶”ì  ì—…ë°ì´íŠ¸
        self.tracking_variables.update(result['analysis'].get('variables', {}))

        # ìƒì„±ëœ ìë°” ì½”ë“œ ë³‘í•©
        java_code = (result.get('analysis', {}).get('code') or '').strip()
        if java_code:
            if self.current_parent:
                # í° ë…¸ë“œ â†’ java_bufferì— ì¶”ê°€
                self.java_buffer += f"\n{java_code}"
                logging.info(f"     âœ“ {target}ì— ì¶”ê°€")
            else:
                # ì‘ì€ ë…¸ë“œ ì²˜ë¦¬
                if self.pending_try_mode:
                    # TRY ë…¸ë“œ â†’ java_bufferì— ë³´ê´€ (merge ì•ˆ í•¨)
                    self.java_buffer += f"\n{java_code}"
                    logging.info(f"     âœ“ TRY ì½”ë“œ ë³´ê´€ â†’ EXCEPTION ëŒ€ê¸°")
                else:
                    # ì¼ë°˜ ë…¸ë“œ â†’ ë°”ë¡œ merge
                    self.merged_java_code += f"\n{java_code}"
                    logging.info(f"     âœ“ {target}ì— ì¶”ê°€")

        # ìƒíƒœ ì´ˆê¸°í™”
        self.total_tokens = int(0)  # ëª…ì‹œì  int íƒ€ì…
        self.sp_code_parts.clear()
        self.sp_start = None
        self.sp_end = None

    # ----- ë§ˆë¬´ë¦¬ -----

    async def _finalize_remaining(self) -> None:
        """ë‚¨ì€ ë°ì´í„° ì •ë¦¬"""
        if self.current_parent:
            if self.sp_code_parts:
                await self._analyze_and_merge()
            await self._finalize_parent()
        elif self.sp_code_parts:
            await self._analyze_and_merge()

    async def _save_service_file(self, service_class_name: str) -> str:
        """ì„±ëŠ¥ ìµœì í™”ëœ ì„œë¹„ìŠ¤ íŒŒì¼ ìë™ ì €ì¥"""
        try:
            # ë³‘í•©ëœ Java ì½”ë“œë¥¼ ì„œë¹„ìŠ¤ ìŠ¤ì¼ˆë ˆí†¤ì— ì‚½ì…
            completed_service_code = self.service_skeleton.replace("CodePlaceHolder", self.merged_java_code.strip())
            
            # ì €ì¥ ê²½ë¡œ ì„¤ì • (ìµœì í™”: í•œ ë²ˆë§Œ ê³„ì‚°)
            base_path = build_java_base_path(self.project_name, self.user_id, 'service')
            
            # íŒŒì¼ ì €ì¥ (ë¹„ë™ê¸° ìµœì í™”)
            await save_file(
                content=completed_service_code,
                filename=f"{service_class_name}.java",
                base_path=base_path
            )
            
            logging.info(f"âœ… [{service_class_name}] ì„œë¹„ìŠ¤ íŒŒì¼ ìë™ ì €ì¥ ì™„ë£Œ")
            logging.info(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {base_path}/{service_class_name}.java")
            
            return completed_service_code
            
        except Exception as e:
            logging.error(f"âŒ ì„œë¹„ìŠ¤ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            raise ConvertingError(f"ì„œë¹„ìŠ¤ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")


# ----- ì§„ì…ì  í•¨ìˆ˜ -----
async def start_service_preprocessing(
    service_skeleton: str,
    command_class_variable: dict,
    procedure_name: str,
    query_method_list: dict,
    folder_name: str,
    file_name: str,
    sequence_methods: list,
    project_name: str,
    user_id: str,
    api_key: str,
    locale: str
) -> tuple:
    """
    ì„œë¹„ìŠ¤ ì „ì²˜ë¦¬ ì‹œì‘
    
    Args:
        service_skeleton: ì„œë¹„ìŠ¤ ë©”ì„œë“œ ìŠ¤ì¼ˆë ˆí†¤ í…œí”Œë¦¿
        command_class_variable: ì»¤ë§¨ë“œ í´ë˜ìŠ¤ í•„ë“œ ì •ì˜
        procedure_name: í”„ë¡œì‹œì € ì´ë¦„
        query_method_list: JPA ì¿¼ë¦¬ ë©”ì„œë“œ ëª©ë¡
        folder_name: í´ë”ëª…
        file_name: íŒŒì¼ëª…
        sequence_methods: ì‹œí€€ìŠ¤ ë©”ì„œë“œ ëª©ë¡
        user_id: ì‚¬ìš©ì ID
        api_key: LLM API í‚¤
        locale: ë¡œì¼€ì¼
    
    Returns:
        None (íŒŒì¼ ë‚´ë¶€ì—ì„œ ìë™ ì €ì¥)
    
    Raises:
        ConvertingError: ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ
    """
    connection = Neo4jConnection()
    
    logging.info("\n" + "="*80)
    logging.info(f"âš™ï¸  STEP 4: Service ì½”ë“œ ìƒì„± - {procedure_name}")
    logging.info("="*80)
    logging.info(f"ğŸ“ íŒŒì¼: {folder_name}/{file_name}")

    try:
        # Neo4j ì¿¼ë¦¬
        service_nodes, variable_nodes = await connection.execute_queries([
            f"""
            MATCH (p:PROCEDURE {{
              folder_name: '{folder_name}',
              file_name: '{file_name}',
              procedure_name: '{procedure_name}',
              user_id: '{user_id}'
            }})
            
            CALL {{
              WITH p
              MATCH (p)-[:PARENT_OF]->(c)
              WHERE NOT c:DECLARE AND NOT c:Table AND NOT c:SPEC
                AND c.token < 1000
              WITH c, labels(c) AS cLabels, coalesce(toInteger(c.startLine), 0) AS sortKey
              RETURN c AS n, cLabels AS nodeLabels, NULL AS r, NULL AS m, sortKey
              
              UNION ALL
              
              // token >= 1000ì¸ í° ë…¸ë“œ â†’ ì‘ì€ ë…¸ë“œë¥¼ ë§Œë‚  ë•Œê¹Œì§€ ì¬ê·€ íƒìƒ‰
              WITH p
              MATCH (p)-[:PARENT_OF]->(c)
              WHERE NOT c:DECLARE AND NOT c:Table AND NOT c:SPEC
                AND coalesce(toInteger(c.token), 0) >= 1000
              // í° ë…¸ë“œë¶€í„° ìì† íƒìƒ‰
              WITH c
              MATCH path = (c)-[:PARENT_OF*0..]->(n)
              WHERE NOT n:DECLARE AND NOT n:Table AND NOT n:SPEC
              // ê²½ë¡œìƒ ëª¨ë“  ë…¸ë“œì˜ token ì²´í¬
              WITH n, path, nodes(path) AS pathNodes
              // í•µì‹¬: ê²½ë¡œì˜ ëª¨ë“  ë¶€ëª¨ê°€ í° ë…¸ë“œ(token >= 1000)ì´ê±°ë‚˜, 
              //       nì´ ì²« ë²ˆì§¸ ì‘ì€ ë…¸ë“œ(token < 1000)ì¸ ê²½ìš°ë§Œ ë°˜í™˜
              WHERE ALL(i IN range(0, size(pathNodes)-2) 
                        WHERE coalesce(toInteger(pathNodes[i].token), 0) >= 1000)
              OPTIONAL MATCH (n)-[r]->(m {{
                folder_name: '{folder_name}', file_name: '{file_name}', user_id: '{user_id}'
              }})
              WHERE r IS NULL
                 OR ( NOT (m:DECLARE OR m:Table OR m:SPEC)
                      AND none(x IN ['CALL','WRITES','FROM'] WHERE type(r) CONTAINS x) )
              WITH n, labels(n) AS nLabels, r, m, coalesce(toInteger(n.startLine), 0) AS sortKey
              RETURN DISTINCT n, nLabels AS nodeLabels, r, m, sortKey
            }}
            
            RETURN n, nodeLabels, r, m
            ORDER BY sortKey, coalesce(toInteger(n.token), 0), id(n)
            """,
            f"""
            MATCH (n {{folder_name: '{folder_name}', file_name: '{file_name}', 
                     procedure_name: '{procedure_name}', user_id: '{user_id}'}})
            WHERE n:DECLARE
            MATCH (n)-[:SCOPE]->(v:Variable)
            RETURN v
            """
        ])

        # ì „ì²˜ë¦¬ ìˆ˜í–‰
        generator = ServicePreprocessingGenerator(
            service_nodes,
            variable_nodes,
            command_class_variable,
            service_skeleton,
            query_method_list,
            folder_name,
            file_name,
            procedure_name,
            sequence_methods,
            user_id,
            api_key,
            locale,
            project_name
        )

        await generator.generate()
        
        # ğŸš€ ì„±ëŠ¥ ìµœì í™”ëœ ìë™ íŒŒì¼ ì €ì¥
        service_class_name = convert_to_pascal_case(procedure_name) + "Service"
        await generator._save_service_file(service_class_name)

        logging.info("\n" + "-"*80)
        logging.info(f"âœ… STEP 4 ì™„ë£Œ: {service_class_name} ìƒì„± ë° ì €ì¥ ì™„ë£Œ")
        logging.info("-"*80 + "\n")

    except ConvertingError:
        raise
    except Exception as e:
        err_msg = f"ì„œë¹„ìŠ¤ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        logging.error(err_msg)
        raise ConvertingError(err_msg)
    finally:
        await connection.close()
