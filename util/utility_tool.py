"""ROBO Analyzer ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ

í•µì‹¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜:
- í† í° ê³„ì‚°
- ë¬¸ìì—´ ì²˜ë¦¬ (Cypher ì´ìŠ¤ì¼€ì´í”„)
- User Story ë¬¸ì„œ ìƒì„±
- ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ (stream_utilsì—ì„œ re-export)
"""

import logging
import json
import uuid
import tiktoken
from typing import Optional, Dict, List, Any, Union

from util.exception import RoboAnalyzerError

# ìŠ¤íŠ¸ë¦¬ë° ìœ í‹¸ë¦¬í‹° (stream_utils.pyì—ì„œ import)
from util.stream_utils import (
    emit_bytes,
    emit_message,
    emit_error,
    emit_data,
    emit_node_event,
    emit_relationship_event,
    emit_complete,
    build_error_body,
    stream_with_error_boundary,
)


def log_process(context: str, stage: str, message: str, level: int = logging.INFO, exc: Exception | None = None) -> None:
    """
    ê³µí†µ íŒŒì´í”„ë¼ì¸ ë¡œê·¸ ì¶œë ¥ í—¬í¼.
    - context: 'DBMS', 'FRAMEWORK' ë“± ë¶„ì„ íƒ€ì…
    - stage: ë…¼ë¦¬ì  ë‹¨ê³„ ì´ë¦„
    - message: ì‚¬ìš©ì ì¹œí™”ì  ì„¤ëª…
    - level: logging ëª¨ë“ˆ ë ˆë²¨
    - exc: ì˜ˆì™¸ ê°ì²´ ì „ë‹¬ ì‹œ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ê¹Œì§€ ì¶œë ¥
    """
    ctx = (context or "APP").upper()
    stage_text = (stage or "STAGE").upper()
    logging.log(level, f"[{ctx}:{stage_text}] {message}", exc_info=exc)


# tiktoken ì¸ì½”ë” ì´ˆê¸°í™”
ENCODER = tiktoken.get_encoding("cl100k_base")


#==============================================================================
# ë¬¸ìì—´/JSON ìœ í‹¸ë¦¬í‹°
#==============================================================================

def escape_for_cypher(text: str) -> str:
    """Cypher ì¿¼ë¦¬ìš© ë¬¸ìì—´ ì´ìŠ¤ì¼€ì´í”„"""
    return str(text).replace("'", "\\'")


def parse_json_maybe(data):
    """JSON ë¬¸ìì—´ì„ íŒŒì‹±í•˜ê±°ë‚˜ ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬ëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜"""
    if isinstance(data, str):
        return json.loads(data)
    return data or []


#==============================================================================
# ìŠ¤í‚¤ë§ˆ/í…Œì´ë¸” íŒŒì‹± ìœ í‹¸ë¦¬í‹°
#==============================================================================

def parse_table_identifier(qualified_table_name: str) -> tuple[str, str, str | None]:
    """'SCHEMA.TABLE@DBLINK'ì—ì„œ (schema, table, dblink) ì¶”ì¶œ
    
    ë”°ì˜´í‘œ(", ', `, [])ë¥¼ ìë™ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤.
    ì›ë³¸ ëŒ€ì†Œë¬¸ìë¥¼ ìœ ì§€í•©ë‹ˆë‹¤ (name_case ì˜µì…˜ì—ì„œ ë³€í™˜ ì²˜ë¦¬).
    ì˜ˆ: "RWIS"."TABLE" â†’ (RWIS, TABLE, None)
    """
    if not qualified_table_name:
        return '', '', None
    
    def strip_quotes(s: str) -> str:
        """ë”°ì˜´í‘œ ì œê±°: "name", 'name', `name`, [name] í˜•ì‹ ì²˜ë¦¬"""
        s = s.strip()
        if len(s) >= 2:
            if (s[0] == '"' and s[-1] == '"') or \
               (s[0] == "'" and s[-1] == "'") or \
               (s[0] == '`' and s[-1] == '`'):
                return s[1:-1]
            if s[0] == '[' and s[-1] == ']':
                return s[1:-1]
        return s
    
    text = qualified_table_name.strip()
    left, _, link = text.partition('@')
    s, _, t = left.partition('.')
    
    schema_raw = strip_quotes(s.strip()) if t else ''
    table_raw = strip_quotes(t.strip()) if t else strip_quotes(left.strip())
    link_raw = strip_quotes(link.strip()) if link.strip() else None

    # ì›ë³¸ ëŒ€ì†Œë¬¸ì ìœ ì§€ (name_case ì˜µì…˜ì—ì„œ ë³€í™˜ ì²˜ë¦¬)
    schema = schema_raw or ''
    table = table_raw or ''
    db_link = link_raw if link_raw else None

    return schema, table, db_link


#==============================================================================
# ì½”ë“œ ë¶„ì„ ìœ í‹¸ë¦¬í‹°
#==============================================================================

def calculate_code_token(code: Union[str, Dict, List]) -> int:
    """ì½”ë“œ í† í° ê¸¸ì´ ê³„ì‚°"""
    try:
        if isinstance(code, str):
            text = code
        else:
            text = json.dumps(code, ensure_ascii=False)
        return len(ENCODER.encode(text))
    except Exception as e:
        err_msg = f"í† í° ê³„ì‚° ë„ì¤‘ ë¬¸ì œê°€ ë°œìƒ: {str(e)}"
        logging.error(err_msg)
        raise RoboAnalyzerError(err_msg)


#==============================================================================
# User Story ë¬¸ì„œ ìƒì„± ìœ í‹¸ë¦¬í‹°
#==============================================================================

def generate_user_story_document(
    results: List[Dict[str, Any]],
    source_name: str = "",
    source_type: str = "í”„ë¡œì‹œì €"
) -> str:
    """Summaryì™€ User Storyë¥¼ í¬í•¨í•œ ìƒì„¸í•œ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        results: Neo4j ì¿¼ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (name, summary, user_stories, type í¬í•¨)
        source_name: ì†ŒìŠ¤ ì´ë¦„ (í”„ë¡œì íŠ¸ëª… ë“±)
        source_type: ì†ŒìŠ¤ íƒ€ì… ("DBMS í”„ë¡œì‹œì €/í•¨ìˆ˜", "Java í´ë˜ìŠ¤/ì¸í„°í˜ì´ìŠ¤" ë“±)
    
    Returns:
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ìƒì„¸ ë¬¸ì„œ ë¬¸ìì—´
    """
    if not results:
        return ""
    
    lines = []
    
    # í—¤ë”
    if source_name:
        lines.append(f"# {source_name} - ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë¬¸ì„œ")
    else:
        lines.append("# ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë¬¸ì„œ")
    lines.append("")
    lines.append(f"> {source_type}ì—ì„œ ë„ì¶œëœ ìƒì„¸ ìš”ì•½, ì‚¬ìš©ì ìŠ¤í† ë¦¬ ë° ì¸ìˆ˜ ì¡°ê±´")
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append("## ğŸ“‹ ëª©ì°¨")
    lines.append("")
    lines.append("1. [í”„ë¡œì‹œì €/í´ë˜ìŠ¤ë³„ ìƒì„¸ ìš”ì•½](#í”„ë¡œì‹œì €í´ë˜ìŠ¤ë³„-ìƒì„¸-ìš”ì•½)")
    lines.append("2. [User Stories & Acceptance Criteria](#user-stories--acceptance-criteria)")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # 1. í”„ë¡œì‹œì €/í´ë˜ìŠ¤ë³„ ìƒì„¸ ìš”ì•½
    lines.append("## í”„ë¡œì‹œì €/í´ë˜ìŠ¤ë³„ ìƒì„¸ ìš”ì•½")
    lines.append("")
    
    for result in results:
        name = result.get("name", "")
        summary_raw = result.get("summary", "")
        result_type = result.get("type", "")
        
        if not name:
            continue
        
        # Summary íŒŒì‹± (JSON ë¬¸ìì—´ì¼ ìˆ˜ ìˆìŒ)
        summary = ""
        if summary_raw:
            if isinstance(summary_raw, str):
                # summaryê°€ JSON ë¬¸ìì—´ì´ë©´ íŒŒì‹±, ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                if summary_raw.startswith('{') or summary_raw.startswith('['):
                    try:
                        summary_parsed = json.loads(summary_raw)
                        if isinstance(summary_parsed, str):
                            summary = summary_parsed
                        else:
                            raise ValueError(f"Summary JSONì´ ë¬¸ìì—´ì´ ì•„ë‹™ë‹ˆë‹¤: {type(summary_parsed)}")
                    except (json.JSONDecodeError, TypeError) as e:
                        raise ValueError(f"Summary JSON íŒŒì‹± ì‹¤íŒ¨: {summary_raw[:100]}...") from e
                else:
                    summary = summary_raw
            else:
                summary = str(summary_raw)
        
        if summary:
            lines.append(f"### {name} ({result_type})")
            lines.append("")
            # Summaryë¥¼ ë¬¸ë‹¨ë³„ë¡œ ë‚˜ëˆ„ì–´ ê°€ë…ì„± í–¥ìƒ
            summary_paragraphs = summary.split('\n\n')
            for para in summary_paragraphs:
                para = para.strip()
                if para:
                    lines.append(para)
                    lines.append("")
            lines.append("---")
            lines.append("")
    
    # 2. User Stories & Acceptance Criteria
    lines.append("## User Stories & Acceptance Criteria")
    lines.append("")
    
    # ëª¨ë“  User Story ì§‘ê³„
    all_user_stories = aggregate_user_stories_from_results(results)
    
    if not all_user_stories:
        lines.append("> User Storyê°€ ë„ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        lines.append("")
        return "\n".join(lines)
    
    # í†µê³„ ì •ë³´
    total_stories = len(all_user_stories)
    total_ac = sum(len(us.get("acceptance_criteria", [])) for us in all_user_stories)
    lines.append(f"**ì´ {total_stories}ê°œì˜ User Story, {total_ac}ê°œì˜ Acceptance Criteriaê°€ ë„ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.**")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # User Stories ìƒì„¸ ë‚´ìš©
    for us_idx, us in enumerate(all_user_stories, 1):
        us_id = us.get("id", f"US-{us_idx}")
        role = us.get("role", "")
        goal = us.get("goal", "")
        benefit = us.get("benefit", "")
        
        lines.append(f"## {us_id}")
        lines.append("")
        lines.append(f"**As a** {role}")
        lines.append("")
        lines.append(f"**I want** {goal}")
        lines.append("")
        lines.append(f"**So that** {benefit}")
        lines.append("")
        
        # Acceptance Criteria
        acs = us.get("acceptance_criteria", [])
        if acs:
            lines.append("### Acceptance Criteria")
            lines.append("")
            
            for ac in acs:
                ac_id = ac.get("id", "")
                ac_title = ac.get("title", "")
                given = ac.get("given", [])
                when = ac.get("when", [])
                then = ac.get("then", [])
                
                if ac_id or ac_title:
                    title_text = f"{ac_id}. {ac_title}" if (ac_id and ac_title) else (ac_id or ac_title)
                    lines.append(f"#### {title_text}")
                    lines.append("")
                
                if given:
                    lines.append("**Given**")
                    for g in given:
                        lines.append(f"- {g}")
                    lines.append("")
                
                if when:
                    lines.append("**When**")
                    for w in when:
                        lines.append(f"- {w}")
                    lines.append("")
                
                if then:
                    lines.append("**Then**")
                    for t in then:
                        lines.append(f"- {t}")
                    lines.append("")
        
        lines.append("---")
        lines.append("")
    
    # í‘¸í„°
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append(f"*ì´ ë¬¸ì„œëŠ” {source_type} ì½”ë“œ ë¶„ì„ì„ í†µí•´ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*")
    lines.append("")
    
    return "\n".join(lines)


def aggregate_user_stories_from_results(results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ì—¬ëŸ¬ ë¶„ì„ ê²°ê³¼ì—ì„œ User Storyë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤."""
    all_stories = []
    story_id_counter = 1
    
    for result in results:
        user_stories_raw = result.get("user_stories")
        if not user_stories_raw:
            continue
        
        if isinstance(user_stories_raw, str):
            try:
                user_stories = json.loads(user_stories_raw)
            except (json.JSONDecodeError, TypeError) as e:
                raise ValueError(f"User Story JSON íŒŒì‹± ì‹¤íŒ¨: {user_stories_raw[:100]}...") from e
        else:
            user_stories = user_stories_raw
        
        if not isinstance(user_stories, list):
            raise ValueError(f"User Storyê°€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {type(user_stories)}")
        
        for us in user_stories:
            # Neo4j ì¿¼ë¦¬ ê²°ê³¼ì—ì„œ null ê°’ í•„í„°ë§
            if not us or not isinstance(us, dict) or not us.get("id"):
                continue
            
            us_copy = us.copy()
            # IDê°€ ì´ë¯¸ ìˆìœ¼ë©´ ìœ ì§€, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            if not us_copy.get("id"):
                us_copy["id"] = f"US-{story_id_counter}"
            
            # Acceptance Criteria ì²˜ë¦¬ (Neo4jì—ì„œ collectë¡œ ë¬¶ì¸ ë°°ì—´)
            acs = us_copy.get("acceptance_criteria", [])
            if acs:
                # null ê°’ í•„í„°ë§
                acs = [ac for ac in acs if ac and isinstance(ac, dict) and ac.get("id")]
                us_copy["acceptance_criteria"] = acs
                
                # AC ID ì¬í• ë‹¹ (í•„ìš”ì‹œ)
                for ac_idx, ac in enumerate(acs, 1):
                    if isinstance(ac, dict) and not ac.get("id"):
                        ac["id"] = f"AC-{story_id_counter}-{ac_idx}"
            
            all_stories.append(us_copy)
            story_id_counter += 1
    
    return all_stories


#==============================================================================
# DDL ì²­í¬ ë¶„í•  ìœ í‹¸ë¦¬í‹°
#==============================================================================

# DDL ì²­í¬ ë¶„í•  ì‹œ ìµœëŒ€ í† í° ìˆ˜
# LLM ì¶œë ¥ ì œí•œ(max_tokens=32768) ê³ ë ¤: í…Œì´ë¸”ë‹¹ ì•½ 700í† í° ì¶œë ¥
# ì²­í¬ë‹¹ ìµœëŒ€ 20ê°œ í…Œì´ë¸” â†’ ì¶œë ¥ 14K í† í° (ì¶©ë¶„í•œ ì•ˆì „ ë§ˆì§„)
# ì…ë ¥ 5K í† í° â†’ í‰ê·  15~25ê°œ í…Œì´ë¸” â†’ ì¶œë ¥ 10.5~17.5K í† í°
MAX_DDL_CHUNK_TOKENS = 5000


def split_ddl_into_chunks(ddl_content: str, max_tokens: int = MAX_DDL_CHUNK_TOKENS) -> List[str]:
    """ëŒ€ìš©ëŸ‰ DDLì„ CREATE TABLE ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì²­í¬ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    
    ê° CREATE TABLE ë¸”ë¡ê³¼ ê´€ë ¨ COMMENT ON êµ¬ë¬¸ì„ í•¨ê»˜ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.
    ALTER TABLE (PK/FK ì •ì˜)ë„ í•´ë‹¹ í…Œì´ë¸” ë¸”ë¡ì— í¬í•¨ì‹œí‚µë‹ˆë‹¤.
    
    Args:
        ddl_content: ì „ì²´ DDL ë¬¸ìì—´
        max_tokens: ì²­í¬ë‹¹ ìµœëŒ€ í† í° ìˆ˜
        
    Returns:
        DDL ì²­í¬ ë¦¬ìŠ¤íŠ¸ (ê° ì²­í¬ëŠ” ì—¬ëŸ¬ CREATE TABLE ë¸”ë¡ í¬í•¨ ê°€ëŠ¥)
    """
    import re
    
    # DDLì´ ì‘ìœ¼ë©´ ë¶„í• í•˜ì§€ ì•ŠìŒ
    total_tokens = calculate_code_token(ddl_content)
    if total_tokens <= max_tokens:
        return [ddl_content]
    
    # 1. CREATE TABLE/VIEW ë¸”ë¡ ì¶”ì¶œ (ì •ê·œì‹ìœ¼ë¡œ ë¶„í• )
    # CREATE TABLE ... ; íŒ¨í„´ ë§¤ì¹­
    create_pattern = re.compile(
        r'(CREATE\s+(?:TABLE|VIEW)\s+(?:IF\s+NOT\s+EXISTS\s+)?[\w\."]+\s*\([^;]+\);)',
        re.IGNORECASE | re.DOTALL
    )
    
    # 2. COMMENT ON êµ¬ë¬¸ ì¶”ì¶œ (ì—¬ëŸ¬ ì¤„ ì½”ë©˜íŠ¸ ì§€ì›, ì´ìŠ¤ì¼€ì´í”„ëœ ì‘ì€ë”°ì˜´í‘œ ì²˜ë¦¬)
    comment_pattern = re.compile(
        r"(COMMENT\s+ON\s+(?:TABLE|COLUMN)\s+[\w\.\"]+(?:\.[\w\.\"]+)*\s+IS\s+'(?:[^']|'')*';)",
        re.IGNORECASE | re.DOTALL
    )
    
    # 3. ALTER TABLE êµ¬ë¬¸ ì¶”ì¶œ (PK, FK, CONSTRAINT)
    alter_pattern = re.compile(
        r'(ALTER\s+TABLE\s+[\w\."]+\s+ADD\s+(?:PRIMARY\s+KEY|CONSTRAINT|FOREIGN\s+KEY)[^;]+;)',
        re.IGNORECASE | re.DOTALL
    )
    
    # í…Œì´ë¸”ë³„ë¡œ DDL ë¸”ë¡ ìˆ˜ì§‘
    table_blocks: Dict[str, List[str]] = {}
    
    # CREATE TABLE ë¸”ë¡ ìˆ˜ì§‘
    for match in create_pattern.finditer(ddl_content):
        stmt = match.group(1).strip()
        # í…Œì´ë¸”ëª… ì¶”ì¶œ (ìŠ¤í‚¤ë§ˆ.í…Œì´ë¸” ë˜ëŠ” í…Œì´ë¸”)
        table_name_match = re.search(
            r'CREATE\s+(?:TABLE|VIEW)\s+(?:IF\s+NOT\s+EXISTS\s+)?([\w\."]+)',
            stmt, re.IGNORECASE
        )
        if table_name_match:
            table_key = table_name_match.group(1).upper().replace('"', '').replace("'", '')
            if table_key not in table_blocks:
                table_blocks[table_key] = []
            table_blocks[table_key].append(stmt)
    
    # COMMENT ON êµ¬ë¬¸ ë§¤í•‘
    for match in comment_pattern.finditer(ddl_content):
        stmt = match.group(1).strip()
        # í…Œì´ë¸”ëª… ì¶”ì¶œ
        if 'COMMENT ON TABLE' in stmt.upper():
            # COMMENT ON TABLE SCHEMA."TABLE_NAME" IS '...';
            table_match = re.search(r'COMMENT\s+ON\s+TABLE\s+([\w\."]+)', stmt, re.IGNORECASE)
            if table_match:
                table_key = table_match.group(1).upper().replace('"', '').replace("'", '')
                if table_key in table_blocks:
                    table_blocks[table_key].append(stmt)
        else:  # COMMENT ON COLUMN
            # COMMENT ON COLUMN SCHEMA."TABLE_NAME"."COLUMN_NAME" IS '...';
            # ìŠ¤í‚¤ë§ˆ.í…Œì´ë¸”.ì»¬ëŸ¼ ë˜ëŠ” ìŠ¤í‚¤ë§ˆ.í…Œì´ë¸”.ì»¬ëŸ¼ í˜•íƒœì—ì„œ í…Œì´ë¸”ëª…ê¹Œì§€ ì¶”ì¶œ
            col_match = re.search(r'COMMENT\s+ON\s+COLUMN\s+([\w\."]+)\.([\w\."]+)\s+IS', stmt, re.IGNORECASE)
            if col_match:
                # ì²« ë²ˆì§¸ ê·¸ë£¹ì´ ìŠ¤í‚¤ë§ˆ.í…Œì´ë¸” ë˜ëŠ” í…Œì´ë¸”
                table_key = col_match.group(1).upper().replace('"', '').replace("'", '')
                if table_key in table_blocks:
                    table_blocks[table_key].append(stmt)
    
    # ALTER TABLE êµ¬ë¬¸ ë§¤í•‘
    for match in alter_pattern.finditer(ddl_content):
        stmt = match.group(1).strip()
        table_match = re.search(r'ALTER\s+TABLE\s+([\w\."]+)', stmt, re.IGNORECASE)
        if table_match:
            table_key = table_match.group(1).upper().replace('"', '').replace("'", '')
            if table_key in table_blocks:
                table_blocks[table_key].append(stmt)
    
    # 4. í…Œì´ë¸” ë¸”ë¡ë“¤ì„ í† í° í•œë„ ë‚´ì—ì„œ ì²­í¬ë¡œ ë¬¶ìŒ
    chunks: List[str] = []
    current_chunk_parts: List[str] = []
    current_tokens = 0
    
    for table_key, stmts in table_blocks.items():
        table_ddl = '\n'.join(stmts)
        table_tokens = calculate_code_token(table_ddl)
        
        # ë‹¨ì¼ í…Œì´ë¸”ì´ ë„ˆë¬´ í¬ë©´ ê·¸ëƒ¥ í•˜ë‚˜ì˜ ì²­í¬ë¡œ
        if table_tokens > max_tokens:
            if current_chunk_parts:
                chunks.append('\n\n'.join(current_chunk_parts))
                current_chunk_parts = []
                current_tokens = 0
            chunks.append(table_ddl)
            continue
        
        # í˜„ì¬ ì²­í¬ì— ì¶”ê°€ ê°€ëŠ¥í•œì§€ í™•ì¸
        if current_tokens + table_tokens > max_tokens:
            # í˜„ì¬ ì²­í¬ ì™„ë£Œ, ìƒˆ ì²­í¬ ì‹œì‘
            if current_chunk_parts:
                chunks.append('\n\n'.join(current_chunk_parts))
            current_chunk_parts = [table_ddl]
            current_tokens = table_tokens
        else:
            # í˜„ì¬ ì²­í¬ì— ì¶”ê°€
            current_chunk_parts.append(table_ddl)
            current_tokens += table_tokens
    
    # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬
    if current_chunk_parts:
        chunks.append('\n\n'.join(current_chunk_parts))
    
    # ì²­í¬ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜ (ë¶„í•  ì‹¤íŒ¨)
    if not chunks:
        return [ddl_content]
    
    log_process("DDL", "CHUNK", f"ğŸ“¦ DDL ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ({total_tokens:,} í† í° â†’ ê° ì²­í¬ ~{max_tokens:,} í† í°)")
    
    return chunks
